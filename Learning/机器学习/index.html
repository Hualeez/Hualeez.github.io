<!DOCTYPE html>
<html lang="en">

<!-- Head tag (contains Google-Analytics、Baidu-Tongji)-->
<head>
  <!-- Google Analytics -->
  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-xxxxxx-xx"></script>
    <script type="text/javascript">
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }
      gtag('js', new Date());

      gtag('config', 'UA-xxxxxx-xx');
    </script>
  

  <!-- Baidu Tongji -->
  
    <script type="text/javascript">
      // Originial
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  <!-- Baidu Push -->
  
    <script>
      (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
      })();
    </script>
  

  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge"/>

  <meta name="google-site-verification" content="lxDfCplOZbIzjhG34NuQBgu2gdyRlAtMB4utP5AgEBc"/>
  <meta name="baidu-site-verification" content="PpzM9WxOJU"/>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="description" content="这里是Hualingz，一个乐观主义者"/>
  <meta name="keyword" content="Hualingz,hualeez,hualingz,cyc"/>
  <link rel="shortcut icon" href="/img/avatar/fin_32.png"/>

  <!-- Place this tag in your head or just before your close body tag. -->
  <script async="async" defer="defer" src="https://buttons.github.io/buttons.js"></script>

  
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css"/>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/beantech.min.css"/>

    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css"/>
    <link rel="stylesheet" href="/css/widget.css"/>
    <link rel="stylesheet" href="/css/rocket.css"/>
    <link rel="stylesheet" href="/css/signature.css"/>
    <link rel="stylesheet" href="/css/catalog.css"/>
    <link rel="stylesheet" href="/css/livemylife.css"/>

    
      <!-- wave start -->
      <link rel="stylesheet" href="/css/wave.css"/>
      <!-- wave end -->
    

    
      <!-- top start (article top hot config) -->
      <link rel="stylesheet" href="/css/top.css"/>
      <!-- top end -->
    

    
      <!-- ThemeColor start -->
      <link rel="stylesheet" href="/css/scroll.css"/>
      <!-- ThemeColor end -->
    

    
      <!-- viewer start (Picture preview) -->
      <link rel="stylesheet" href="/css/viewer.min.css"/>
      <!-- viewer end -->
    

    
      <!-- Search start -->
      <link rel="stylesheet" href="/css/search.css"/>
      <!-- Search end -->
    

    
      <!-- ThemeColor start -->
      <link rel="stylesheet" href="/css/themecolor.css"/>
      <!-- ThemeColor end -->
    

    

    
      <!-- gitalk start -->
      <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"> -->
      <link rel="stylesheet" href="/css/gitalk.css"/>
      <!-- gitalk end -->
    
  

  <!-- Custom Fonts -->
  <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
  <!-- Hux change font-awesome CDN to qiniu -->
  <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" type="text/css">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <!-- Hux Delete, sad but pending in China <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'> <link
  href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/ css'> -->

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]> <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script> <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script> <![endif]-->

  <!-- ga & ba script hoook -->
  <link rel="canonical" href="http://Hualingz.cn/Learning/机器学习/">
  <title>
    
      机器学习 - Hualingz_Channel
    
  </title>
<meta name="generator" content="Hexo 5.4.2"></head>


<!-- hack iOS CSS :active style -->

	<body ontouchstart="" class="body--light body--dark">


		<!-- ThemeColor -->
		
		<!-- ThemeColor -->
<style type="text/css">
  .body--light {
    --light-mode: none;
    --dark-mode: block;
  }
  .body--dark {
    --light-mode: block;
    --dark-mode: none;
  }
  i.mdui-icon.material-icons.light-mode {
    display: var(--light-mode);
  }
  i.mdui-icon.material-icons.dark-mode {
    display: var(--dark-mode);
  }
</style>
<div class="toggle" onclick="document.body.classList.toggle('body--dark')">
  <i class="mdui-icon material-icons light-mode"></i>
  <i class="mdui-icon material-icons dark-mode"></i>
</div>
<script>
  //getCookieValue
  function getCookieValue(a) {
    var b = document.cookie.match('(^|[^;]+)\\s*' + a + '\\s*=\\s*([^;]+)');
    return b
      ? b.pop()
      : '';
  }
  let themeMode = 'dark';
  if (getCookieValue('sb-color-mode') && (getCookieValue('sb-color-mode') !== themeMode)) {
    let dbody = document.body.classList;
    themeMode === 'dark' ? dbody.remove('body--dark') : dbody.add('body--dark');
  }

  //setCookieValue
  var toggleBtn = document.querySelector(".toggle");
  toggleBtn.addEventListener("click", function () {
    var e = document.body.classList.contains("body--dark");
    var cookieString = e
      ? "dark"
      : "light";
    var exp = new Date();
    exp.setTime(exp.getTime() + 3 * 24 * 60 * 60 * 1000); //3天过期
    document.cookie = "sb-color-mode=" + cookieString + ";expires=" + exp.toGMTString() + ";path=/";
  });
</script>

		

		<!-- Gitter -->
		
		<!-- Gitter -->
<!-- Docs:https://gitter.im/?utm_source=left-menu-logo -->
<script>
  ((window.gitter = {}).chat = {}).options = {
    room: 'your-community/your-room'
  };
</script>
<script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>

		

		<!-- Navigation (contains search)-->
		<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header page-scroll">
      <button type="button" class="navbar-toggle">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Hualingz_Channel</a>
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <!-- Known Issue, found by Hux: <nav>'s height woule be hold on by its content. so, when navbar scale out, the <nav> will cover tags. also mask any touch event of tags, unfortunately. -->
    <div id="huxblog_navbar">
      <div class="navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a href="/">首页</a>
          </li>

          
          
          
          
          <li>
            <a href="/about/">
              
              关于
              
              
            </a>
          </li>
          
          
          
          
          
          <li>
            <a href="/categories/">
              
              分类
              
              
            </a>
          </li>
          
          
          
          <li>
            <a href="/tags/">
              
              标签
              
              
            </a>
          </li>
          
          

          
          <li>
            <a class="popup-trigger">
              <span class="search-icon"></span>搜索</a>
          </li>
          

          <!-- LangSelect -->
          
          
          
          
          
        </ul>
      </div>
    </div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container -->
</nav>
<!-- progress -->
<div id="progress">
  <div class="line" style="width: 0%;"></div>
</div>

<script>
  // Drop Bootstarp low-performance Navbar Use customize navbar with high-quality material design animation in high-perf jank-free CSS3 implementation
  var $body = document.body;
  var $toggle = document.querySelector('.navbar-toggle');
  var $navbar = document.querySelector('#huxblog_navbar');
  var $collapse = document.querySelector('.navbar-collapse');

  $toggle.addEventListener('click', handleMagic)

  function handleMagic(e) {
    if ($navbar.className.indexOf('in') > 0) {
      // CLOSE
      $navbar.className = " ";
      // wait until animation end.
      setTimeout(function() {
        // prevent frequently toggle
        if ($navbar.className.indexOf('in') < 0) {
          $collapse.style.height = "0px"
        }
      }, 400)
    } else {
      // OPEN
      $collapse.style.height = "auto"
      $navbar.className += " in";
    }
  }
</script>


		<!-- Post Header (contains intro-header、signature、wordcount、busuanzi、waveoverlay) -->
		<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->

  <style type="text/css">
    .body--light {
      /* intro-header */
      --intro-header-background-image-url-home: url('/img/header_img/newhome_bg.jpg');
      --intro-header-background-image-url-post: url('');
      --intro-header-background-image-url-page: url('/img/header_img/archive_bg2.jpg');
    }
    .body--dark {
      --intro-header-background-image-url-home: linear-gradient(rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.2)), url('/img/header_img/newhome_bg.jpg');
      --intro-header-background-image-url-post: linear-gradient(rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.2)), url('');
      --intro-header-background-image-url-page: linear-gradient(rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.2)), url('/img/header_img/archive_bg2.jpg');
    }

    header.intro-header {
       /*post*/
        background-image: var(--intro-header-background-image-url-post);
        /* background-image: url(''); */
      
    }

    
      #signature {/*signature*/
        background-image: url('/img/signature/vincent-white.png');
      }
    
  </style>





<header class="intro-header">
  <!-- Signature -->
  <div id="signature">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
          
          <div class="post-heading">
            <div class="tags">
              
              <a class="tag" href="/tags/#浙江大学" title="浙江大学">浙江大学</a>
              
              <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
              
            </div>
            <h1>机器学习</h1>
            <h2 class="subheading">Hualingz</h2>
            <span class="meta">
              Posted by Hualingz on
              2022-09-15
            </span>


            
            <!-- WordCount start -->
            <div class="blank_box"></div>
            <span class="meta">
              Estimated Reading Time <span class="post-count">127</span> Minutes
            </span>
            <div class="blank_box"></div>
            <span class="meta">
              Words <span class="post-count">30.2k</span> In Total
            </span>
            <div class="blank_box"></div>
            <!-- WordCount end -->
            
            
            <!-- 不蒜子统计 start -->
            <span class="meta" id="busuanzi_container_page_pv">
              Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
            </span>
            <!-- 不蒜子统计 end -->
            


          </div>
          
        </div>
      </div>
    </div>
  </div>

  
  <!-- waveoverlay start -->
  <div class="preview-overlay">
    <svg class="preview-waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
      <defs>
        <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path>
      </defs>
      <g class="preview-parallax">
        <use xlink:href="#gentle-wave" x="48" y="0" fill=var(--gentle-wave1)></use>
        <use xlink:href="#gentle-wave" x="48" y="3" fill=var(--gentle-wave2)></use>
        <use xlink:href="#gentle-wave" x="48" y="5" fill=var(--gentle-wave3)></use>
        <use xlink:href="#gentle-wave" x="48" y="7" fill=var(--gentle-wave)></use>
      </g>
    </svg>
  </div>
  <!-- waveoverlay end -->
  

</header>



		<!-- Main Content (Post contains
	Pager、
	tip、
	socialshare、
	gitalk、gitment、disqus-comment、
	Catalog、
	Sidebar、
	Featured-Tags、
	Friends Blog、
	anchorjs、
	) -->
		<!-- Modify by Yu-Hsuan Yen -->
<!-- Post Content -->
<article>
  <div class="container">
    <div class="row">
      <!-- Post Container -->
      <div class="col-lg-8 col-lg-offset-1 col-md-10 col-md-offset-1 post-container">

        <h1 id="机器学习">机器学习</h1>
<h2 id="lecture-1">Lecture 1</h2>
<p>赵洲，zhaozhou@zju.edu.cn，曹主415</p>
<h3 id="分数组成">1.1分数组成</h3>
<ul>
<li>大作业（图片分类）：70%
<ul>
<li>http://yann.lecun.com/exdb/mnist</li>
<li>思路PPT讲解：10</li>
<li>作业报告：30</li>
<li>编程代码：30</li>
<li>DDL：15周周五晚上12点</li>
</ul></li>
<li>小作业
<ul>
<li>阅读SVM开源算法报告：10
<ul>
<li>DDL：8周周五晚上12点</li>
</ul></li>
<li>阅读Transformer开源算法报告：10
<ul>
<li>DDL：15周周五晚上12点</li>
</ul></li>
</ul></li>
<li>课堂参与：10
<ul>
<li>签到20次，每次0.5%</li>
</ul></li>
</ul>
<h3 id="导论">1.2导论</h3>
<ul>
<li>Machine Learning：经验驱动的性能提升的计算机系统
<ul>
<li>Supervised监督学习：回归、分类</li>
<li>Unsupervised非监督学习：聚类</li>
<li>Reinforcement强化学习：游戏与控制</li>
</ul></li>
</ul>
<h3 id="监督学习">1.3监督学习</h3>
<ul>
<li>Goal： 学习一个映射从输入x到输出y</li>
<li>Training Data： labeled data有标签的输入输出对x，y</li>
<li>分类：离散的标签</li>
<li>回归：连续的标签</li>
</ul>
<h3 id="非监督学习">1.4非监督学习</h3>
<ul>
<li>只有输入，没有label</li>
<li>Goal： find “interesting pattern”</li>
<li>隐因子：
<ul>
<li>降维</li>
<li>矩阵分解</li>
<li>Topic Modeling</li>
</ul></li>
</ul>
<h3 id="强化学习">1.5强化学习</h3>
<ul>
<li>是延时的一个监督学习</li>
<li>这里的label是环境作用于机器的，是有延迟的reward</li>
</ul>
<h2 id="lecture-2">Lecture 2</h2>
<h3 id="监督学习-1">2.1监督学习</h3>
<p>【贝叶斯定理】<span class="math inline">\(P(A|B)=\frac{P(B|A)·P(A)}{P(B)}\)</span></p>
<ul>
<li><span class="math inline">\(P(A|B)\)</span>为后验概率，posterior</li>
<li><span class="math inline">\(P(B|A)\)</span>为似然度，likelihood来自于model</li>
<li><span class="math inline">\(P(A)\)</span>为先验Prior，来自label的比例</li>
</ul>
<p>【Example】</p>
<table>
<thead>
<tr class="header">
<th>A</th>
<th>0</th>
<th>0</th>
<th>1</th>
<th>1</th>
<th>1</th>
<th>0</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h4 id="先验">先验</h4>
<p>先验一般有两种情况：</p>
<ol type="1">
<li>Uniform的情况<span class="math inline">\(P(w_1)=P(w_2)\)</span></li>
<li><span class="math inline">\(P(w_1)+P(w_2)=1\)</span></li>
</ol>
<p>只根据先验的决策：</p>
<ul>
<li>如果池塘里A鱼多，B鱼少，我们就猜测为A鱼</li>
</ul>
<h4 id="似然度">似然度</h4>
<p>只根据likelihood的决策：</p>
<ul>
<li>likelihood从观测中的data中来</li>
<li>如果<span class="math inline">\(P(x|w_1)&gt;P(x|w_2)\)</span>，预测为w1，x为一个特征</li>
</ul>
<h4 id="后验">后验</h4>
<p>贝叶斯公式<span class="math inline">\(P(w_i|x)=\frac{P(x|w_i)·P(w_i)}{P(x)}\)</span></p>
<p>概率公式<span class="math inline">\(P(x)=\sum_{i=1}^{k}P(x|w_i)P(w_i)\)</span></p>
<p>可以看到后验和先验×似然度成正比<code>Posterior = likelihood×Prior</code></p>
<h4 id="策略">策略</h4>
<p>选择后验概率最高，意味着错误率最小，即有最小错误率分类</p>
<ul>
<li>Decide <span class="math inline">\(w_i\)</span>，if <span class="math inline">\(P(w_i|x)&gt;P(w_j|x)\)</span></li>
<li>在使用贝叶斯公式根据已知的先验和似然度来决策</li>
<li>可以加上ln便于计算</li>
</ul>
<h3 id="参数估计">2.2参数估计</h3>
<h4 id="极大似然估计一文搞懂极大似然估计---知乎-zhihu.com">极大似然估计[<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26614750">一文搞懂极大似然估计 - 知乎
(zhihu.com)</a>]</h4>
<ul>
<li><p>极大似然估计，通俗理解来说，<strong>就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！</strong></p></li>
<li><p><strong>换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。</strong></p></li>
<li><p>对于分类器只能做参数估计，不能做模型估计，在参数估计中主要估计参数，模型是假定好的，比如假定是一个高斯模型，我们做的是估计高斯模型的一个参数，一个参数是<span class="math inline">\(μ\)</span>一个是Σ，我们要估计的就是这两个参数。</p></li>
<li><p>似然函数<span class="math inline">\(p(x|\theta)\)</span>：</p>
<ul>
<li>输入x为一个具体的数据，θ是模型的参数，</li>
<li>如果θ是已知的，x是变量那么这个函数是一个概率函数，它描述对于不同的样本点x，其出现概率是多少。</li>
<li>如果x是已知确定的， θ是变量，这个函数叫做似然函数(likelihood
function), 它描述对于不同的模型参数，出现 x
这个样本点的概率是多少。</li>
</ul></li>
</ul>
<p><strong>Example</strong></p>
<p>假如有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。我
们想知道罐中白球和黑球的比例，但我们不能把罐中的球全部拿出来数。现在我们可以每次任意从已经摇匀的罐中拿一个球出来，记录球的颜色，然后把拿出来的球
再放回罐中。这个过程可以重复，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少？</p>
<p><strong>很多人马上就有答案了：70%。而其后的理论支撑是什么呢？</strong></p>
<p>我们假设罐中白球的比例是p，那么黑球的比例就是1-p。因为每抽一个球出来，在记录颜色之后，我们把抽出的球放回了罐中并摇匀，<strong>所以每次抽出来的球的颜
色服从同一独立分布。</strong></p>
<p>这里我们把一次抽出来球的颜色称为一次抽样。题目中在一百次抽样中，七十次是白球的,三十次为黑球事件的概率是P(样本结果|Model)。</p>
<p>如果第一次抽象的结果记为x1,第二次抽样的结果记为x2....那么样本结果为(x1,x2.....,x100)。这样，我们可以得到如下表达式：
<span class="math display">\[
p(x_1,x_2,...,x_{100}|Model)
\\=p(x_1|Model)p(x_2|Model)...p(x_{100}|Model)
\\=p^{70}(1-p)^{30}
\]</span>
我们已经有了观察样本结果出现的概率表达式了。那么我们要求的模型的参数，也就是求的式中的p。那么我们怎么来求这个p呢？不同的p，直接导致P（样本结果|Model）的不同。</p>
<p><strong>极大似然估计应该按照什么原则去选取这个分布呢？</strong></p>
<ul>
<li><strong>采取的方法是让这个样本结果出现的可能性最大，也就是使得<span class="math inline">\(p^{70}
(1-p)^{30}\)</span>值最大，那么我们就可以看成是p的方程，求导即可！</strong></li>
<li>求出p=70</li>
</ul>
<h4 id="mle方法">MLE方法</h4>
<ul>
<li>MLE即Maximum Likelihood Estimation</li>
<li>定义何为最优参数？观测到的sample出现的概率最大的参数
<ul>
<li>假设我们有c个training set，c个class</li>
<li>每一个class需要学习一个model，model参数为<span class="math inline">\(\theta_c\)</span></li>
<li>MLE就是估计这个参数θ，要估计likelihood</li>
</ul></li>
<li>就是说所有sample的概率乘起来最大，即似然函数
<ul>
<li><span class="math inline">\(P(D_c|\theta_c)=\prod_{x\in
D_c}P(x|\theta_c)\)</span></li>
<li>其中Dc为c类样本组成的集合，参数θc对于数据集Dc的最大似然估计，就是寻找使得这个表达式最大的参数θ值。</li>
</ul></li>
<li>假设我们模型是高斯模型，那么首先样本独立同分布
<ul>
<li><span class="math inline">\(p(x|w_i)=p(x|w_i,\theta_i)\)</span></li>
<li>likelihood服从高斯分布<span class="math inline">\(p(x|w_i)\)</span>~<span class="math inline">\(N(\mu_i,\Sigma_i)\)</span></li>
<li>似然函数<span class="math inline">\(P(D|\theta)=\prod_{k=1}^np(x_k|\theta)\)</span>
<ul>
<li><span class="math inline">\(\theta=(\theta_1,...,\theta_c)\)</span></li>
<li>评估的θ需要最大化这个似然值</li>
<li>乘法难以评估，求导困难，取log</li>
<li>对于单个θ就是<span class="math inline">\(P(D_c|\theta_c)=\prod_{x\in
D_c}P(x|\theta_c)\)</span></li>
</ul></li>
<li><span class="math inline">\(l(\theta)=lnP(D|\theta)=\sum_{k=1}^nln\
p(x_k|\theta)\)</span></li>
<li>最后所求<span class="math inline">\(\theta^*={argmax}_{\theta}\
l(\theta)\)</span></li>
<li><span class="math inline">\(\nabla_{\theta}l(\theta)=[\frac{\partial}{\partial
\theta_1},...,\frac{\partial}{\partial
\theta_c}]^T=\sum_{k=1}^n\nabla_{\theta}ln\ p(x_k|\theta)\)</span></li>
<li>其中的<span class="math inline">\(p(x_k|\theta)\)</span>是服从高斯分布的
<ul>
<li>Σ固定，评估θ
<ul>
<li><span class="math inline">\(P(x)=-\frac{1}{\sqrt{2\pi
\sigma}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}\)</span></li>
<li><span class="math inline">\(\mu=x的均值\)</span></li>
<li><span class="math inline">\(\sigma^2=x的方差\)</span></li>
</ul></li>
<li>高维的高斯
<ul>
<li><span class="math inline">\(P(x)=\frac{1}{(2\pi)^{\frac{d}{2}}
|\Sigma|^\frac{1}{2}}exp[{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}]\)</span></li>
<li>d是维度</li>
<li><span class="math inline">\(\mu=\frac{1}{|D_c|}\sum_{x\in
D_c}x\)</span></li>
<li><span class="math inline">\(\Sigma=\frac{1}{|D_c|}\sum_{x\in
D_c}(x-\mu)(x-\mu)^T\)</span></li>
</ul></li>
</ul></li>
<li>令<span class="math inline">\(\nabla_{\theta}l(\theta)=0\)</span></li>
</ul></li>
<li>【Example】固定Σ估计μ的高斯模型
<ul>
<li><span class="math inline">\(P(x|\mu)\)</span>~<span class="math inline">\(N(\mu,\Sigma)\)</span></li>
<li><span class="math inline">\(ln\
p(x_k|\mu)=-\frac{1}{2}ln[(2\pi)^d|\Sigma|]-\frac{1}{2}(x_k-\mu)^T\Sigma^{-1}(x_k-\mu)\)</span></li>
<li>对参数μ求导</li>
<li><span class="math inline">\(\nabla_{\mu}ln\
p(x_k|\mu)=\Sigma^{-1}(x_k-\mu)\)</span></li>
<li>则<span class="math inline">\(\sum_{k=1}^n\Sigma^{-1}(x_k-\mu)=0\)</span></li>
<li>解出μ即可<span class="math inline">\(\mu^*=\frac{1}{n}\sum_{k=1}^nx_k\)</span></li>
<li>可以看到这个μ其实就是sample的均值</li>
</ul></li>
<li>【Example】估计μ、Σ的高斯模型
<ul>
<li><span class="math inline">\(P(x|\theta)\)</span>~<span class="math inline">\(N(\mu,\sigma^2)\)</span></li>
<li><span class="math inline">\(ln\
p(x_k|\theta)=-\frac{1}{2}ln(2\pi\sigma^2)-\frac{1}{2\sigma^2}(x_k-\mu)^2\)</span></li>
<li>对参数θ求导</li>
<li><span class="math inline">\(\nabla_{\theta}ln\
p(x_k|\theta)=\begin{bmatrix}\frac{\partial ln\
p(x_k|\theta)}{\partial\mu}\\\frac{\partial ln\
p(x_k|\theta)}{\partial\sigma^2}\end{bmatrix}=\begin{bmatrix}\frac{1}{\sigma^2}(x_k-\mu)\\
-\frac{1}{2\sigma^2}+\frac{(x_k-\mu)^2}{2\sigma^4}\end{bmatrix}=0\)</span></li>
<li><span class="math inline">\(\mu=\frac{1}{n}\sum x_k\)</span></li>
<li><span class="math inline">\(\sigma^2=\frac{1}{n}\sum(x_k-\mu)^2\)</span></li>
<li>令<span class="math inline">\(\overline{X}=[x_1-\mu,...,x_n-\mu]\)</span></li>
<li>则一般形式如下
<ul>
<li><span class="math inline">\(\mu=\frac{1}{n}\sum x_k\)</span></li>
<li><span class="math inline">\(\Sigma=\frac{1}{n}\overline{X}\overline{X}^T\)</span></li>
</ul></li>
</ul></li>
<li>【Example】</li>
</ul>
<h4 id="be方法贝叶斯估计---知乎-zhihu.com">BE方法[<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/72506771">贝叶斯估计 - 知乎
(zhihu.com)</a>]</h4>
<ul>
<li><p>贝叶斯评估方法：</p>
<ul>
<li>在MLE中，<span class="math inline">\(\theta_i\)</span>是可以计算出一个固定的值的
<ul>
<li>极大似然估计是典型的频率学派观点，它的基本思想是：待估计参数 θ
是客观存在的，只是未知而已，当 <span class="math inline">\(θ^{mle}\)</span> 满足“ <span class="math inline">\(θ=θ^{mle}\)</span> 时，该组观测样本
(X1,X2,…,Xn)=(x1,x2,…,xn) 更容易被观测到“，我们就说 <span class="math inline">\(θ^{mle}\)</span> 是 θ
的极大似然估计值。也即，估计值 <span class="math inline">\(θ^{mle}\)</span> 使得事件发生的可能性最大。</li>
</ul></li>
<li>在BE中，<span class="math inline">\(\theta_i\)</span>是一个随机的变量
<ul>
<li>贝叶斯估计是典型的贝叶斯学派观点，它的基本思想是：待估计参数 θ
也是随机的，和一般随机变量没有本质区别，因此只能根据观测样本估计参数 θ
的分布。贝叶斯派的人认为，被估计的参数同样服从一种分布，即参数也为一个随机变量。他们在估计参数前会先带来先验知识，例如参数在
[0.5,0.6]
的区域内出现的概率最大，在引入了先验知识后在数据量小的情况下估计出来的结果往往会更合理。</li>
<li>我们需要计算<strong>后验概率分布</strong><span class="math inline">\(P(\theta|D)\)</span></li>
</ul></li>
</ul></li>
<li><p>为了计算后验概率分布，我们首先看到贝叶斯公式<span class="math inline">\(P(\theta|D)=\frac{P(D|\theta)P(\theta)}{P(D)}\)</span></p>
<ul>
<li>那么有<span class="math inline">\(P(\theta|D)与P(D|\theta)P(\theta)\)</span>成正比</li>
<li>其中<span class="math inline">\(P(\theta)\)</span>为参数服从分布，即先验知识</li>
<li><span class="math inline">\(p(x|D)=\int p(x,\theta|D)d\theta=\int
p(x|\theta,D)p(\theta|D)d\theta=\int
p(x|\theta)p(\theta|D)d\theta\)</span></li>
<li>为什么要求<span class="math inline">\(p(x|D)\)</span>?</li>
</ul></li>
<li><p>【Example】未知μ的高斯分布<strong>generate出x的分布</strong></p>
<ul>
<li><span class="math inline">\(p(x|\mu)\)</span>~<span class="math inline">\(N(\mu,\sigma^2)\)</span></li>
<li>假设<span class="math inline">\(p(u)\)</span>~<span class="math inline">\(N(\mu_0,\sigma_0^2)\)</span></li>
<li>先求<span class="math inline">\(p(\mu|D)\)</span>
<ul>
<li><span class="math inline">\(p(\mu|D)=\frac{p(D|\mu)p(\mu)}{\int
p(D|\mu)p(\mu)d\mu}=\alpha\prod
p(x_k|\mu)p(\mu)\\=\alpha&#39;exp[-\frac{1}{2}(\sum(\frac{\mu-x_k}{\sigma})^2+(\frac{\mu-\mu_0}{\sigma_0})^2)]\\=\alpha&#39;&#39;exp[-\frac{1}{2}[(\frac{n}{\sigma^2}+\frac{1}{\sigma_0^2})\mu^2-2(\frac{1}{\sigma^2}\sum
x_k+\frac{\mu_0}{\sigma_0^2})\mu]]\)</span></li>
<li>这就求出了后验概率分布</li>
<li>并且之前假设的
<ul>
<li><span class="math inline">\(\mu_n=(\frac{n\sigma_0^2}{n\sigma_0^2+\sigma^2})\hat{x_n}+\frac{\sigma^2}{n\sigma_0^2+\sigma^2}\mu_0\)</span></li>
<li><span class="math inline">\(\sigma_n^2=\frac{\sigma_0^2\sigma^2}{n\sigma_0^2+\sigma^2}\)</span></li>
</ul></li>
</ul></li>
<li>再求<span class="math inline">\(p(x|D)\)</span>后验密度即类条件概率密度
<ul>
<li>如上所述</li>
<li><span class="math inline">\(p(x|D)=\int
p(x|\mu)p(\mu|D)d\mu\\=\frac{1}{2\pi \sigma
\sigma_0}exp[-\frac{1}{2}\frac{(x-\mu_n)^2}{\sigma
^2+\sigma_0^2}]f(\sigma,\sigma_0)\)</span></li>
<li>其中<span class="math inline">\(f(\sigma,\sigma_0)=\int
exp[-\frac{1}{2}\frac{\sigma^2+\sigma_0^2}{\sigma^2\sigma_0^2}(\mu-\frac{\sigma_n^2x+\sigma^2\mu_n}{\sigma^2+\sigma_n^2})^2]d\mu\)</span></li>
<li>得出结论为<span class="math inline">\(p(x|D)\)</span>~<span class="math inline">\(N(\mu_n,\sigma^2+\sigma_0^2)\)</span></li>
</ul></li>
</ul></li>
</ul>
<h4 id="map方法">MAP方法</h4>
<ul>
<li><p>密度估计(Density Estimation)</p>
<p>怎么去给一个观测到的数据集估计出一个联合概率分布是比较常见的问题。比如说，给定一系列的观测值<span class="math inline">\(X=(x_1,x_2,...,x_n)\)</span> ,
每一个观测值都彼此独立的情况下，密度估计要选择一个概率分布模型，以及选择对应的最能够表达出X的联合概率的参数。最常见的两种方法有MAP和MLE（最大似然估计）。两种方法都要求找到并且优化一个模型以及它的参数来表达已知观测值。</p></li>
<li><p>在MAP中，在已知的概率分布模型和参数下，我们希望能够最大化观测到数据的可能性:<span class="math inline">\(P(X;\theta)=P(x_1,x_2,...,x_n;\theta)\)</span>
所以我们要找到一组参数<span class="math inline">\(\theta\)</span>，让上面的式子的结果最大。</p></li>
<li><p>那么我们只需要<span class="math inline">\(max(P(X|\theta)P(\theta))\)</span></p></li>
</ul>
<h4 id="discriminant-functions-for-the-normal-density判别函数">Discriminant
Functions for the Normal Density判别函数</h4>
<p>在分类器中，我们需要依据概率分类，而这个判断的一句就是根据判别函数获得的</p>
<ul>
<li>一般形式
<ul>
<li>假设有c个类<span class="math inline">\(w_1,w_2,...,w_c\)</span></li>
<li>那么根据一个特征x，来查看<span class="math inline">\(p(w_i|x)\)</span>的大小，取最大的为最后预测的类
<ul>
<li>即判别函数<span class="math inline">\(g(x)=p(w_i|x)\)</span></li>
</ul></li>
<li>由贝叶斯公式知，<span class="math inline">\(p(w_i|x)\)</span>~<span class="math inline">\(p(x|w_i)p(w_i)\)</span>
<ul>
<li><span class="math inline">\(g(x)=p(x|w_i)p(w_i)\)</span></li>
</ul></li>
<li>取对数
<ul>
<li><span class="math inline">\(g(x)=ln\ p(x|w_i)+ln\
p(w_i)\)</span></li>
</ul></li>
</ul></li>
<li>一般而言只要<span class="math inline">\(g(x)\)</span>能够正确分类都可以作为判别函数
<ul>
<li>g(x)不一定要计算出来，只要能够纵向比较大小即可</li>
</ul></li>
<li>【Example】高斯分布下的一般形式的g(x)
<ul>
<li>判别函数<span class="math inline">\(g_i(x)=ln\ p(x|w_i)+ln\
p(w_i)\)</span></li>
<li><span class="math inline">\(p(x|w_i)=\frac{1}{(2\pi)^{\frac{d}{2}}|\Sigma_i|^\frac{1}{2}}exp[-\frac{1}{2}(x-\mu_i)^T\Sigma_i^{-1}(x-\mu_i)]\)</span></li>
<li><span class="math inline">\(g_i(x)=-\frac{1}{2}(x-\mu_i)^T\Sigma_i^{-1}(x-\mu_i)-\frac{d}{2}ln\
2\pi-\frac{1}{2}ln|\Sigma_i|+ln\ p(w_i)\)</span>
<ul>
<li>Case1：<span class="math inline">\(\Sigma_i=\sigma^2I\)</span>
<ul>
<li><span class="math inline">\(g_i(x)=-\frac{(x-\mu_i)^T(x-\mu_i)}{2\sigma^2}+ln\
p(w_i)\)</span></li>
<li><span class="math inline">\(=-\frac{1}{2\sigma^2}(x^Tx-2\mu_i^Tx+\mu_i^T\mu_i)+ln\
p(w_i)\)</span></li>
<li>因为<span class="math inline">\(x^Tx\)</span>对于所有的class都是相等的，等价于<span class="math inline">\(g(x)=w_i^Tx+w_{i0}\)</span>
<ul>
<li><span class="math inline">\(w_i=\frac{\mu_i}{\sigma^2}\)</span></li>
<li><span class="math inline">\(w_{i0}=-\frac{\mu_i^T\mu_i}{2\sigma^2}+ln\
p(w_i)\)</span></li>
</ul></li>
<li>这是一个线性的函数</li>
<li>最后来查看两个类的输出相等的情况
<ul>
<li><span class="math inline">\(g_i(x)=g_j(x)\)</span></li>
<li><span class="math inline">\(0=(\frac{\mu_i-\mu_j}{\sigma^2})^Tx-\frac{\mu_i^T\mu_i-\mu_j^T\mu_j}{2\sigma^2}+ln\frac{p(w_i)}{p(w_j)}\)</span></li>
<li>假设<span class="math inline">\(p(w_i)=p(w_j)\)</span></li>
<li><span class="math inline">\(x_0=\frac{1}{2}(\mu_i+\mu_j)\)</span></li>
</ul></li>
</ul></li>
<li>Case2：<span class="math inline">\(\Sigma_i=\Sigma\)</span>
<ul>
<li><span class="math inline">\(g(x)=-\frac{1}{2}(x^T\Sigma^{-1}x-2\mu_i^T\Sigma^{-1}x+\mu_i^T\Sigma^{-1}\mu_i)+ln\
p(w_i)\)</span></li>
<li>因为<span class="math inline">\(x^T\Sigma^{-1}x\)</span>对所有的类都是一样的，等价于<span class="math inline">\(g_i(x)=\mu_i^T\Sigma^{-1}x-\frac{1}{2}\mu_i^T\Sigma^{-1}\mu_i+ln\
p(w_i)\)</span>
<ul>
<li><span class="math inline">\(g_i(x)=w_i^Tx+w_{i0}\)</span></li>
</ul></li>
<li>分界线
<ul>
<li><span class="math inline">\(g_i(x)=g_j(x)\)</span></li>
<li><span class="math inline">\(0=(\mu_i-\mu_j)^T\Sigma^{-1}x-\frac{\mu_i^T\Sigma^{-1}\mu_i-\mu_j^T\Sigma^{-1}\mu_j}{2}+ln\
\frac{p(w_i)}{p(w_j)}\)</span></li>
</ul></li>
<li>参数估计
<ul>
<li><span class="math inline">\(\mu_i=\frac{1}{N_i}\sum_{j\in
w_i}x_j\)</span></li>
<li><span class="math inline">\(P(w_i)=\frac{N_i}{N}\)</span></li>
<li><span class="math inline">\(\Sigma=\sum_{i=1}^c\sum_{j\in
w_i}\frac{(x_j-\mu_i)(x_j-u_i)^T}{N_i}\)</span></li>
</ul></li>
</ul></li>
<li>Case3：<span class="math inline">\(\Sigma_i=Arbitrary\)</span>
<ul>
<li><span class="math inline">\(g_i(x)=-\frac{1}{2}(x^T\Sigma_i^{-1}x-2\mu_i^T\Sigma_i^{-1}x+\mu_i^T\Sigma_i^{-1}\mu_i)-\frac{1}{2}ln\
|\Sigma_i|+ln\ P(w_i)\)</span></li>
<li><span class="math inline">\(g_i(x)=x^TW_ix+w_i^Tx+w_{i0}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="naive-bayes-classifier朴素贝叶斯">2.3 Naive Bayes
Classifier朴素贝叶斯</h3>
<p>给出<span class="math inline">\(x=(x_1,x_2,...,x_p)^T\)</span></p>
<ul>
<li><p>给出一系列特征，我们希望找到这些特征最可能出现的类</p></li>
<li><p>即<span class="math inline">\(P(w|x)=P(w|x_1,...,x_p)\)</span></p>
<ul>
<li>又<span class="math inline">\(P(w|x)\)</span>~<span class="math inline">\(P(x_1,...,x_p|w)P(w)\)</span></li>
<li><strong>特征独立</strong></li>
<li><span class="math inline">\(P(x_1,...,x_p|w)=P(x_1|w)...P(x_p|w)\)</span></li>
<li>那么我们只需要找到最大的概率进行预测即可</li>
</ul></li>
<li><p>【Example】</p>
<ul>
<li><p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20220915095523325.png" alt="image-20220915095523325" style="zoom:50%;"></p></li>
<li><p>现在我们给出一个记录X=(Refund=No,Married,Income=120K)，使用朴素贝叶斯预测其类别</p></li>
<li><p>首先，类别只有两个：Yes，No</p>
<ul>
<li><p><span class="math inline">\(P(w_k)=\frac{N_k}{N}\)</span>每个类别的先验概率</p>
<ul>
<li><span class="math inline">\(P(NO)=\frac{7}{10}\)</span></li>
<li><span class="math inline">\(P(YES)=\frac{3}{10}\)</span></li>
</ul></li>
<li><p><span class="math inline">\(P(x_i|w_k)=\frac{|x_i|}{N_k}\)</span>每个类别中特征出现的概率</p>
<ul>
<li><p><span class="math display">\[
P(Refund=YES|NO)=\frac{3}{7}\\
P(Refund=NO|NO)=\frac{4}{7}\\
P(Refund=YES|YES)=0\\
P(Refund=NO|YES)=1
\]</span></p></li>
<li></li>
<li><p>$$ P(Married|YES)=0\ P(Divorced|YES)=\ P(Single|YES)=\</p>
<p>P(Married|NO)=\ P(Divorced|YES)=\ P(Single|YES)=\ $$</p></li>
<li><p>工资是高斯分布的，我们首先估计参数</p>
<ul>
<li><span class="math inline">\(P(x|w_i)\)</span>~<span class="math inline">\(N(\mu,\sigma^2)\)</span></li>
<li><span class="math inline">\(\mu=\frac{1}{n_x}\sum
x_i=110\)</span></li>
<li><span class="math inline">\(\sigma^2=\frac{1}{n_x}\sum(x_i-\mu)^2=2975\)</span></li>
</ul></li>
<li><p><span class="math inline">\(P(X|NO)=P(x_1|NO)P(x_2|NO)P(x_3|NO)=0.0024\)</span></p></li>
<li><p><span class="math inline">\(P(X|YES)=0\)</span></p></li>
<li><p><span class="math inline">\(P(X|NO)P(NO)&gt;P(X|YES)P(YES)\)</span></p></li>
<li><p>Class=NO</p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Laplace smoothing</p>
<ul>
<li><span class="math inline">\(P(x_i|w_k)=\frac{|x_{ik}|+1}{N_{w_k}+K}\)</span></li>
</ul></li>
</ul>
<h2 id="lecture-3">Lecture 3</h2>
<h3 id="linear-method-for-regression">3.1 Linear Method for
Regression</h3>
<h4 id="linear-model">Linear Model</h4>
<ul>
<li>目标是学习一个从输入x到输出y的一个映射
<ul>
<li>y是离散的，分类</li>
<li>y是实数值，回归</li>
</ul></li>
<li>【Example】
<ul>
<li>设<span class="math inline">\(x\in
R^d,x=[x_1,...,x_d]^T\)</span></li>
<li>参数<span class="math inline">\(w=[w_1,...,w_d]^T\in
R^d,b\)</span></li>
<li>那么我们可以写出方程<span class="math inline">\(f(x)=w^Tx+b\)</span>
<ul>
<li>进一步令<span class="math inline">\(x=[x_1,..,x_d,1]^T\)</span></li>
<li><span class="math inline">\(w=[w_1,...,w_d,b]^T\)</span></li>
</ul></li>
<li><span class="math inline">\(f(x)=w^Tx\)</span></li>
</ul></li>
</ul>
<h4 id="polynomial-curve-fitting">Polynomial Curve Fitting</h4>
<ul>
<li>用多项式拟合数据参数为<span class="math inline">\(a=(a_0,a_1,...,a_m)\)</span>
<ul>
<li><span class="math inline">\(f(x,a)=a_0+a_1x_1+...+a_mx^m\)</span></li>
</ul></li>
<li>Zero Order Polynomial
<ul>
<li>是一个constant</li>
<li>其实就是均值</li>
</ul></li>
<li>First Order Polynomial
<ul>
<li>用一条直线拟合</li>
</ul></li>
<li>Third Order Polynomial
<ul>
<li>用三次函数的拟合</li>
</ul></li>
<li>次数越高越复杂，精度高，容易过拟合</li>
</ul>
<h4 id="mse-criterion均方误差判据">MSE Criterion均方误差判据</h4>
<ul>
<li>考察一个函数拟合是否好，我们用误差函数来判断
<ul>
<li>需要拟合的训练数据为<span class="math inline">\((x_1,y_1),...,(x_n,y_n)\)</span></li>
<li>学习到的函数为<span class="math inline">\(f(x,a)\)</span></li>
</ul></li>
<li><span class="math inline">\(MSE(a)=\frac{1}{n}\sum_{i=1}^n(y_i-f(x_i,a))^2\)</span></li>
<li>最小化MSE，即最小化标签<span class="math inline">\(y_i\)</span>和输出预期<span class="math inline">\(f(x_i)\)</span>方差，这里的f被参数a决定
<ul>
<li><span class="math inline">\(J_n(a)=\sum_{i=1}^n(y_i-a^Tx_i)^2\)</span></li>
<li>最小化<span class="math inline">\(a^Tx_i\)</span>和<span class="math inline">\(y_i\)</span>的均方误差</li>
<li>使用矩阵表示
<ul>
<li><span class="math inline">\(X=[x_1,x_2,...,x_n]\)</span></li>
<li><span class="math inline">\(y=[y_1,y_2,...,y_n]^T\)</span></li>
<li><span class="math inline">\(J_n(a)=(y-X^Ta)^T(y-X^Ta)\)</span></li>
</ul></li>
</ul></li>
</ul>
<h3 id="linear-regression-model">3.2Linear Regression Model</h3>
<ul>
<li>训练数据为<span class="math inline">\((x_i,y_i)\)</span>，标签为<span class="math inline">\(y_i\)</span></li>
<li>学得的模型为<span class="math inline">\(f(x)=a_0+\sum_{i=1}^pa_ix_i=a_0+a^Tx\)</span></li>
<li><span class="math inline">\(a=[a_1,...,a_p]^T,x\)</span>为特征向量</li>
<li>接下来我们要最小化误差
<ul>
<li>MSE均方误差
<ul>
<li><span class="math inline">\(J_n=\frac{1}{n}\sum_{i=1}^n(y_i-f(x_i))^2\)</span></li>
</ul></li>
<li>RSS残差平方和
<ul>
<li><span class="math inline">\(RSS(f)=\sum_{i=1}^n(y_i-f(x_i))^2\)</span></li>
</ul></li>
</ul></li>
<li>以MSE均方误差为例，如何最小化？
<ul>
<li>使用矩阵表示
<ul>
<li><span class="math inline">\(X=[x_1,x_2,...,x_n]\)</span></li>
<li><span class="math inline">\(y=[y_1,y_2,...,y_n]^T\)</span></li>
<li><span class="math inline">\(J_n(a)=(y-X^Ta)^T(y-X^Ta)\)</span></li>
<li>对a求导
<ul>
<li><span class="math inline">\(\frac{dAX}{dX}=A^T\)</span></li>
<li><span class="math inline">\(\frac{dx^Tx}{dx}=2x\)</span></li>
</ul></li>
<li><span class="math inline">\(\nabla J_n=-2X(y-X^Ta)\)</span></li>
<li><span class="math inline">\(a=(XX^T)^{-1}Xy\)</span></li>
</ul></li>
</ul></li>
<li>则我们就求出了使得MSE最小化的a
<ul>
<li><span class="math inline">\(\hat
y=X^Ta=X^T(XX^T)^{-1}Xy\)</span></li>
</ul></li>
</ul>
<h3 id="statistical-model-of-regression">3.3 Statistical Model of
Regression</h3>
<ul>
<li>生成的模型：<span class="math inline">\(y=f(x,a)+\epsilon\)</span>
<ul>
<li><span class="math inline">\(f(x,a)\)</span>是一个确定性函数</li>
<li><span class="math inline">\(\epsilon\)</span>是一个随机的噪声，它可以有一个概率分布，比如<span class="math inline">\(\epsilon\)</span>~<span class="math inline">\(N(0,\sigma^2)\)</span></li>
</ul></li>
<li>【Example】
<ul>
<li><span class="math inline">\(y=f(x,a)+\epsilon\)</span></li>
<li><span class="math inline">\(\epsilon\)</span>~<span class="math inline">\(N(0,\sigma^2)\)</span></li>
<li>给定<span class="math inline">\(a,X,\sigma\)</span>的条件下，输出y的概率</li>
<li>即<span class="math inline">\(y-f(x,a)\)</span>的概率，因为<span class="math inline">\(f(x,a)\)</span>是给定的</li>
<li><span class="math inline">\(p(y|x,a,\sigma)=\frac{1}{\sigma
\sqrt{2\pi}}exp[-\frac{1}{2\sigma^2}(y-f(x,a))^2]\)</span></li>
<li>接下来使用最大似然估计MLE求a</li>
<li><span class="math inline">\(L(D,a,\sigma)=\prod_{i=1}^n
p(y_i|x_1,a,\sigma)\)</span></li>
<li><span class="math inline">\(a^*=argmax\prod_{i=1}^np(y_i|x_i,a,\sigma)\)</span></li>
<li>使用对数似然函数</li>
<li><span class="math inline">\(l(D,a,\sigma)=log(L(D,a,\sigma))=log\prod
p(y_i|x_i,a,\sigma)=\sum_{i=1}^nlog\ p(y_i|x_i,a,\sigma)\)</span></li>
<li><span class="math inline">\(l(D,a,\sigma)=-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-f(x_i,a))^2+c(\sigma)\)</span></li>
<li>到最后还是最小化<span class="math inline">\(RSS(f)\)</span></li>
</ul></li>
</ul>
<h4 id="overfitting">Overfitting</h4>
<ul>
<li>model不能过于简单也不能过于复杂，即参数的复杂度
<ul>
<li>过简单，欠拟合，在训练集上就表现不好</li>
<li>过复杂，过拟合，在训练集上良好，在测试集上表现差</li>
<li>我们可以对参数的限制放入损失函数中，作为正则函数项</li>
</ul></li>
</ul>
<h4 id="ridge-regression">Ridge Regression</h4>
<ul>
<li>使用损失函数+正则项</li>
<li><span class="math inline">\(a^*=argmin_{a}\sum_{i=1}^n(y_i-x_i^Ta)^2+\lambda\sum_{j=1}^p
a_j^2\)</span></li>
<li>需要挑选合适的<span class="math inline">\(\lambda\)</span></li>
<li>等价形式
<ul>
<li><span class="math inline">\(a^*=argmin_{a}\sum(y_i-x_i^Ta)^2\)</span></li>
<li>Subject to <span class="math inline">\(\sum_{i=1}^n
a_j^2≤t\)</span></li>
</ul></li>
<li>L2正则化
<ul>
<li><span class="math inline">\(C=C_0+\frac{\lambda}{2n}\sum_ww^2\)</span></li>
</ul></li>
<li>L1正则化
<ul>
<li><span class="math inline">\(C=C_0+\frac{\lambda}{n}\sum|w|\)</span></li>
<li>L1比L2更加sparse</li>
</ul></li>
<li>求解以<span class="math inline">\(a^*=argmin_{a}\sum_{i=1}^n(y_i-x_i^Ta)^2+\lambda\sum_{j=1}^p
a_j^2\)</span>为例
<ul>
<li>矩阵表示<span class="math inline">\((y-X^Ta)^T(y-X^Ta)+\lambda
a^Ta\)</span></li>
<li>求导<span class="math inline">\(-2X(y-X^Ta)+2\lambda a\)</span></li>
<li>求解<span class="math inline">\(a^*=(XX^T+\lambda
I)^{-1}Xy\)</span></li>
</ul></li>
</ul>
<h4 id="bayesian-linear-regression">Bayesian Linear Regression</h4>
<ul>
<li><span class="math inline">\(P(a|D)=\frac{P(D|a)P(a)}{P(D)}\)</span></li>
<li>假设a是高斯分布
<ul>
<li><span class="math inline">\(p(a)=N(a|0,\lambda^{-1}I)\)</span></li>
<li><span class="math inline">\(ln(p(a))=-\frac{\lambda}{2}a^Ta+c\)</span></li>
<li>那么计算Posterior时我们可以先计算出likelihood
<ul>
<li><span class="math inline">\(l(D,a,\sigma)=-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-f(x_i,a))^2+c(\sigma)\)</span></li>
<li><span class="math inline">\(ln(p(a))=-\frac{\lambda}{2}a^Ta+c\)</span></li>
</ul></li>
<li>那么后验是正比于likelihood×prior的，在log下就是相加</li>
<li>相当于多了一个正则项</li>
</ul></li>
</ul>
<h3 id="lasso">3.3 LASSO</h3>
<ul>
<li>Least Absolute Selection and Shrinkage Operator</li>
<li><span class="math inline">\(\hat \beta=argmin\frac{1}{2n}\sum
(y_i-x_i^T\beta)^2\)</span>
<ul>
<li>subject to <span class="math inline">\(\sum_{j=1}^p|\beta_j|≤t\)</span>【L1】</li>
<li>subject to <span class="math inline">\(\sum_{j=1}^p\beta_j^2≤t\)</span>【L2】</li>
</ul></li>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20220920112506418.png" alt="image-20220920112506418">
<figcaption aria-hidden="true">image-20220920112506418</figcaption>
</figure></li>
</ul>
<h4 id="lasso-solution">LASSO Solution</h4>
<ul>
<li><span class="math inline">\(\hat \beta=argmin\frac{1}{2n}\sum
(y_i-z_i\beta)^2\)</span></li>
<li>这里的z是x经过归一化的，y也是归一化的
<ul>
<li><span class="math inline">\(\sum y_i=0\)</span></li>
<li><span class="math inline">\(\sum z_i=0\)</span></li>
<li><span class="math inline">\(\frac{1}{n}\sum_iz_{ij}^2=1\)</span></li>
</ul></li>
<li><span class="math inline">\(f(\beta)=\frac{1}{2n}(y-\beta
z)^T(y-\beta z)+\lambda|\beta|\)</span></li>
<li><span class="math inline">\(f(\beta)=\frac{1}{2n}z^Tz\beta^2-\frac{1}{n}&lt;z,y&gt;\beta+\frac{1}{2n}y^Ty+\lambda
|\beta|\)</span></li>
<li><span class="math inline">\(2&lt;z,y&gt;=y^Tz+z^Ty\)</span></li>
<li>且<span class="math inline">\(\hat \beta=argmin\frac{1}{2n}\sum
(y_i-x_i^T\beta)^2\)</span></li>
<li>去除与<span class="math inline">\(\beta\)</span>无关项，<span class="math inline">\(f(\beta)=\frac{1}{2}\beta^2-\frac{1}{n}&lt;z,y&gt;\beta+\lambda
|\beta|\)</span></li>
<li><span class="math display">\[ f(\beta)= \begin{cases}
\frac{1}{2}\beta^2-(\frac{1}{n}&lt;z,y&gt;-\lambda)\beta,\quad \beta\geq
0\\ \frac{1}{2}\beta^2-(\frac{1}{n}&lt;z,y&gt;+\lambda)\beta, \quad
\beta\lt 0 \end{cases} \tag{1} \]</span></li>
<li><span class="math inline">\(\beta^*=\begin{cases}\frac{1}{n}&lt;z,y&gt;-\lambda,\quad
\frac{1}{n}&lt;z,y&gt;\gt \lambda\\
0,\quad|\frac{1}{n}&lt;z,y&gt;|\leq\lambda\\\frac{1}{n}&lt;z,y&gt;+\lambda,\quad
\frac{1}{n}&lt;z,y&gt;&lt;-\lambda\end{cases}\)</span></li>
</ul>
<h3 id="model-assessment-and-selection">3.4 Model Assessment and
Selection</h3>
<ul>
<li>模型的评估和模型的选择：
<ul>
<li>泛化性、准确度</li>
<li>在新的data上测试集上进行测试</li>
</ul></li>
</ul>
<h3 id="bias-variance-decomposition">3.5 Bias-variance
Decomposition</h3>
<ul>
<li>偏差-方差分解(Bias-Variance
Decomposition)是统计学派看待模型复杂度的观点。Bias-variance分解是机器学习中一种重要的分析技术。给定学习目标和训练集规模，它可以把一种学习算法的期望误差分解为三个非负项的和，即样本真实噪音noise、bias和
variance。</li>
<li>noise 样本真实噪音是任何学习算法在该学习目标上的期望误差的下界；(
任何方法都克服不了的误差)</li>
<li>bias
度量了某种学习算法的平均估计结果所能逼近学习目标的程度；（独立于训练样本的误差，刻画了匹配的准确性和质量：一个高的偏差意味着一个坏的匹配）</li>
<li>variance
则度量了在面对同样规模的不同训练集时，学习算法的估计结果发生变动的程度。（相关于观测样本的误差，刻画了一个学习算法的精确性和特定性：一个高的方差意味着一个不稳定的匹配）。</li>
</ul>
<p>【Example】</p>
<ul>
<li>给出标签数据<span class="math inline">\((x_i,y_i)\)</span></li>
<li>学到一个函数<span class="math inline">\(f(x)=y\)</span></li>
<li>Loss：<span class="math inline">\(L(y,f(x))\)</span></li>
<li>期望误差：
<ul>
<li><span class="math inline">\(E(L)=\int\int
L(y,f(x))p(x,y)dxdy\)</span></li>
</ul></li>
<li>若将平方误差用于Loss
<ul>
<li><span class="math inline">\(L(y,f(x))=(y-f(x))^2\)</span></li>
<li>获得EPE（Expected Prediction Error）
<ul>
<li><span class="math inline">\(EPE(f)=\int \int
(y-f(x))^2p(x,y)dxdy\)</span></li>
</ul></li>
</ul></li>
<li>那么我们获得了平方误差下的期望误差即EPE
<ul>
<li>又<span class="math inline">\((y-f(x))^2=(y-E(y|x)+E(y|x)-f(x))^2\)</span></li>
<li><span class="math inline">\(=(y-E(y|x))^2+(E(y|x)-f(x))^2+2(y-E(y|x))(E(y|x)-f(x))\)</span>**&lt;*&gt;**</li>
<li>则<span class="math inline">\(\int\int
(y-E(y|x))^2p(x,y)dxdy=\int_x\int_y(y-E(y|x))^2p(y|x)\ dy\
p(x)dx=\int_xvar(y|x)p(x)dx\)</span>
<ul>
<li>运用公式<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/e4c0a6db8a86">01
条件期望与条件方差 - 简书 (jianshu.com)</a>：
<ul>
<li><span class="math inline">\(E(y|x)=\int y\ p(y|x)dy\)</span></li>
<li><span class="math inline">\(var(y|x)=\int
(y-E(y|x))p(y|x)dy\)</span></li>
</ul></li>
</ul></li>
<li>则<span class="math inline">\(\int \int
(E(y|x)-f(x))^2p(x,y)dxdy=\int_yp(y|x)dy\int_x(E(y|x)-f(x))^2p(x)dx=\int(E(y|x)-f(x))^2p(x)dx\)</span>
<ul>
<li>运用公式
<ul>
<li><span class="math inline">\(\int p(y|x)dy=1\)</span></li>
<li><span class="math inline">\(E(y|x)\)</span>与y无关</li>
</ul></li>
</ul></li>
<li>则<span class="math inline">\(\int \int
(y-E(y|x))(E(y|x)-f(x))p(x,y)dxdy=0\)</span>
<ul>
<li><span class="math inline">\(\int \int
yE(y|x)p(x,y)dxdy=\int_x\int_yy\ p(y|x)dy\
E(y|x)p(x)dx=\int_xE(y|x)^2p(x)dx\)</span></li>
<li><span class="math inline">\(\int \int yf(x)p(x,y)dxdy\)</span></li>
<li><span class="math inline">\(\int \int
E(y|x)^2p(x,y)dxdy=\int_yp(y|x)dy\int_xE(y|x)^2p(x)dx=\int_xE(y|x)^2p(x)dx\)</span></li>
<li><span class="math inline">\(\int\int
E(y|x)f(x)p(x,y)dxdy=\int_yp(y|x)dy\int
_xE(y|x)f(x)p(x)dx=\int_x\int_yy\ p(y|x)dyf(x)p(x)dx=\int \int
yf(x)p(x,y)dxdy\)</span></li>
</ul></li>
</ul></li>
<li><span class="math inline">\(EPE(f)=\int(E(y|x)-f(x))^2p(x)dx+\int
var(y|x)p(x)dx\)</span></li>
<li>在实际中，往往会给数据集D
<ul>
<li><span class="math inline">\(f(x)=f(x;D)\)</span></li>
<li><span class="math inline">\(EPE(f)=\int(f(x;D)-E(y|x))^2p(x)dx+\int
var(y|x)p(x)dx\)</span></li>
<li>其中的<span class="math inline">\((f(x;D)-E(y|x))^2\)</span>可以如上一样分解
<ul>
<li><span class="math inline">\((f(x;D)-E(y|x))^2=E_D\{[f(x;D)-E_D(f(x;D))]^2\}+\{E_D(f(x;D))-E(y|x)\}^2\)</span></li>
</ul></li>
<li><span class="math inline">\(bias^2=\int\{E_D(f(x;D))-E(y|x)\}^2p(x)dx\)</span></li>
<li><span class="math inline">\(variance=\int
E_D\{[f(x;D)-E_D(f(x;D))]^2\}p(x)dx\)</span></li>
<li><span class="math inline">\(noise=\int var(y|x)p(x)dx\)</span></li>
</ul></li>
</ul>
<h2 id="lecture-4">Lecture 4</h2>
<h3 id="discriminant-functions-and-classifiers">4.1 Discriminant
Functions and Classifiers</h3>
<ul>
<li>对于判别函数<span class="math inline">\(g_i(x)\)</span>，分类器会把特征x归入<span class="math inline">\(w_i\)</span>类，如果满足<span class="math inline">\(g_i(x)&gt;g_j(x)\)</span>，对所有的<span class="math inline">\(i\neq j\)</span>成立</li>
</ul>
<h4 id="sigmoid-functionlogistic-function">Sigmoid Function(Logistic
Function)</h4>
<ul>
<li><span class="math inline">\(\sigma(t)=\frac{1}{1+e^{-t}}\)</span></li>
<li>输入的值可以在正无穷和负无穷之间，但是输出在0，1之间，可以看作一个概率</li>
<li>即<span class="math inline">\(\sigma:R\rarr(0,1)\)</span></li>
</ul>
<h3 id="logistic-regression">4.2 Logistic Regression</h3>
<ul>
<li>逻辑回归LR是一种用sigmoid函数估计概率来描述一类因变量与一个或几个自变量之间关系的分类模型。</li>
<li>假设二分类问题
<ul>
<li><span class="math inline">\(y_i\)</span>是第i个label，a是参数</li>
<li><span class="math inline">\(P(y_i=1|x_i,a)=\sigma(a^Tx_i)=\frac{1}{1+e^{-a^Tx_i}}\)</span></li>
<li><span class="math inline">\(P(y_i=-1|x_i,a)=1-\sigma(a^Tx_i)=\frac{1}{1+e^{a^Tx_i}}\)</span></li>
<li><span class="math inline">\(P(y_i|x_i,a)=\sigma(y_ia^Tx_i)=\frac{1}{1+e^{-y_ia^Tx_i}}\)</span></li>
</ul></li>
<li>使用最大似然估计去估计a
<ul>
<li><span class="math inline">\(P(D)=\prod_{i\in
I}\sigma(y_ia^Tx_i)\)</span></li>
<li><span class="math inline">\(l(P(D))=\sum_{i=I}log(\sigma(y_ia^Tx_i))=-\sum_{i\in
I}log(1+e^-{y_ia^Tx_i})\)</span></li>
<li>则<span class="math inline">\(E(a)=\sum_{i\in
I}log(1+e^{-y_ia^Tx_i})\)</span></li>
<li>最小化误差函数
<ul>
<li>Logistic Regression
<ul>
<li><span class="math inline">\(E(a)=\sum_{i\in
I}log(1+e^{-y_ia^Tx_i})\)</span></li>
<li><span class="math inline">\(E(a)\)</span>是上凸还是下凸？</li>
</ul></li>
<li>Linear Regression
<ul>
<li><span class="math inline">\(E(a)=\sum_{i\in
I}(y_i-a^Tx_i)^2\)</span></li>
</ul></li>
</ul></li>
<li>使用梯度下降法</li>
</ul></li>
</ul>
<h3 id="gradient-descent">4.3 Gradient Descent</h3>
<ul>
<li>一般采用一阶的优化方法，即使用一阶导数</li>
<li>一般只能找到局部最优解</li>
</ul>
<h4 id="一般的步骤">一般的步骤</h4>
<ol type="1">
<li>目标函数<span class="math inline">\(J(w)\)</span>，可以是多变量也可以是多变量的，<strong>可微的</strong></li>
<li>下降最快的方向是a处梯度的反方向，即<span class="math inline">\(-\nabla J(a)\)</span></li>
<li>更新a，<span class="math inline">\(b=a-\gamma \nabla
J(a)\)</span>，γ为学习率或者步长，要足够小</li>
<li>我们一开始猜一个权重参数<span class="math inline">\(w_0\)</span>
<ul>
<li><span class="math inline">\(w_{n+1}=w_n-\gamma \nabla
J(w_n)\)</span></li>
<li>更新参数</li>
</ul></li>
<li>那么<span class="math inline">\(J(w_i)\)</span>就会不断下降</li>
</ol>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">begin initialize <span class="keyword">a</span>,theta,eta,k=<span class="number">0</span></span><br><span class="line">	<span class="built_in">do</span> k=k+<span class="number">1</span></span><br><span class="line">	   <span class="keyword">a</span>=<span class="keyword">a</span>-eta(k)*grad(J,<span class="keyword">a</span>)</span><br><span class="line">	<span class="keyword">until</span> eta(k)*grad(J,<span class="keyword">a</span>)&lt;theta</span><br><span class="line"><span class="literal">return</span> <span class="keyword">a</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h4 id="线性近似">线性近似</h4>
<ul>
<li><span class="math inline">\(E(a+\Delta a)=E(a)+E&#39;(a)\Delta
a+E&#39;&#39;(a)\frac{\Delta a^2}{2!}+...\)</span></li>
<li>Gradient Decent
<ul>
<li><span class="math inline">\(\Delta a=-\eta E&#39;(a)\)</span></li>
</ul></li>
<li>Newton Method
<ul>
<li>二阶的方法</li>
<li>让<span class="math inline">\(E&#39;(a)\Delta
a+E&#39;&#39;(a)\frac{\Delta a^2}{2!}\)</span>最小</li>
<li><span class="math inline">\(\Delta
a=-\frac{E&#39;(a)}{E&#39;&#39;(a)}\)</span></li>
</ul></li>
</ul>
<h3 id="支持向量机">4.4 支持向量机</h3>
<ul>
<li>线性可分的数据，我们需要分开
<ul>
<li>正类：<span class="math inline">\(w^Tx+b\leq0\)</span></li>
<li>负类：<span class="math inline">\(w^Tx+b\geq 0\)</span></li>
<li>正好在边界：<span class="math inline">\(w^Tx+b=0\)</span></li>
</ul></li>
<li>怎么分类比较好？如何定义这个好？
<ul>
<li>边际使得离两种类别的点都比较远</li>
</ul></li>
</ul>
<h4 id="几何边缘">几何边缘</h4>
<ul>
<li>假设<span class="math inline">\(\gamma\)</span>是x到边界线的距离</li>
<li>设<span class="math inline">\(x_0\)</span>是x在边界线上的投影
<ul>
<li><span class="math inline">\(x=x_0+y\gamma
\frac{w}{||w||}\)</span></li>
<li><span class="math inline">\(x_0\)</span>在分界线上</li>
<li><span class="math inline">\(\gamma =
y\frac{w^Tx+b}{||w||}\)</span>，这里的y是区分正负类的</li>
<li>那么支持向量的<span class="math inline">\(y(w^Tx+b)=1\)</span></li>
<li>其他数据点的<span class="math inline">\(y(w^Tx+b)\geq1\)</span></li>
<li>我们最大化两个支持向量的距离<span class="math inline">\(D=\frac{y(w^Tx+b)}{||w||}\)</span></li>
<li>则最大化<span class="math inline">\(\frac{2}{||w||}\)</span>
<ul>
<li>即最小化<span class="math inline">\(\frac{1}{2}||w||\)</span></li>
<li>去掉根号</li>
</ul></li>
<li>得到优化问题<span class="math inline">\(min\frac{1}{2}||w||^2,y_i(w^Tx_i+b)≥1\)</span></li>
</ul></li>
</ul>
<h4 id="松弛变量">松弛变量</h4>
<ul>
<li>允许数据值离开支持向量一段距离</li>
<li><span class="math inline">\(min_{w,b}\frac{1}{2}||w||^2+C\sum_{i=1}^n\xi_i\)</span></li>
<li><span class="math inline">\(y(w^Tx_i+b)\geq1-\xi_i\)</span></li>
<li><span class="math inline">\(\xi_i\geq0\)</span></li>
</ul>
<h4 id="求解">求解</h4>
<ul>
<li><span class="math inline">\(\xi_i\geq1-y(w^Tw_i+b)\)</span>则<span class="math inline">\(\xi_i=max[1-y(w^Tx_i+b),0]\)</span>，即是损失函数</li>
<li><span class="math inline">\(min\{\sum_{i=1}^nmax[1-y(w^Tx_i+b),0]+\frac{1}{2C}||w||^2\}\)</span></li>
<li><span class="math inline">\(l (f)=max[1-f,0]\)</span>，Hinge
Loss</li>
<li>SVM就是一个HingeLoss作为损失函数，正则为L2Norm的优化
<ul>
<li>Linear Regression：Square Loss <span class="math inline">\(l(f)=(y-f)^2=(1-yf)^2\)</span></li>
<li>Logistic Regression：Logistic Loss <span class="math inline">\(l(f)=log(1+e^{-yf})\)</span></li>
</ul></li>
</ul>
<h4 id="general-formulation-of-classifiers分类范式">General Formulation
of Classifiers分类范式</h4>
<ul>
<li><span class="math inline">\(min_f\{\sum_{i=1}^nl(f)+\lambda
R(f)\}\)</span></li>
<li>Loss Function
<ul>
<li>Square、Logistic、Hinge</li>
</ul></li>
<li>Regularizer
<ul>
<li>L1、L2</li>
</ul></li>
</ul>
<h2 id="lecture-5">Lecture 5</h2>
<h3 id="deep-learning-概述">5.1 Deep Learning 概述</h3>
<ul>
<li>深度学习是机器学习的一个分支</li>
<li>基于representations学习，表征学习，使用多层神经网络的非线性转换来学习</li>
<li>与Supervised Learning区别
<ul>
<li>Collect training samples</li>
<li>Define feature(更重要)</li>
<li>Design and Train Model</li>
<li>Predict</li>
</ul></li>
</ul>
<h3 id="neural-network">5.2 Neural Network</h3>
<h4 id="linear-modelclassifier">Linear Model(Classifier)</h4>
<h4 id="perceptron">Perceptron</h4>
<ul>
<li>是Linear的，加上一个激活函数</li>
<li>Sample：<span class="math inline">\(x\in
R^d,x=[x_1,...,x_d]^T\)</span></li>
<li>DrawBack，只能学习线性可分的函数</li>
</ul>
<h4 id="backpropagation-algorithm反向传播算法">Backpropagation
Algorithm反向传播算法</h4>
<h4 id="activation-function激活函数">Activation Function激活函数</h4>
<ul>
<li>Sigmoid
<ul>
<li><span class="math inline">\(\sigma(s)=\frac{1}{1+e^{-s}}\)</span></li>
<li><span class="math inline">\(\frac{d\sigma(s)}{ds}=\sigma(s)(1-\sigma(s))\)</span></li>
</ul></li>
<li>Tanh</li>
<li>ReLU
<ul>
<li><span class="math inline">\(ReLU(z)=\begin{cases}z,\quad
z\geq0\\0,\quad otherwise\end{cases}\)</span></li>
<li><span class="math inline">\(ReLU(z)=max(0,z)\)</span></li>
<li>缓解梯度消失问题</li>
</ul></li>
<li>Leaky ReLU</li>
<li>ELU</li>
<li>PReLU</li>
</ul>
<h3 id="convolution卷积">5.3 Convolution卷积</h3>
<h4 id="图像的输入">图像的输入</h4>
<ul>
<li>对于200*200的图像，用全连接输入，第一层需要200*200个units，则输入参数有200*200*200*200个</li>
<li>卷积神经网络
<ul>
<li>权重共享</li>
<li>一个unit不再覆盖全部的图像，而是部分图像local feature</li>
</ul></li>
</ul>
<h4 id="何为卷积">何为卷积</h4>
<ul>
<li>输入：一个图像</li>
<li>卷积核：一个可学习的参数w</li>
<li>Feature Map：即输出的特征图</li>
<li>卷积操作：
<ul>
<li><span class="math inline">\(s[i,j]=(x*w)[i,j]\)</span></li>
</ul></li>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20220920171644874.png" alt="image-20220920171644874">
<figcaption aria-hidden="true">image-20220920171644874</figcaption>
</figure></li>
</ul>
<h4 id="卷积层">卷积层</h4>
<ul>
<li>输入图像：height*width*depth
<ul>
<li>32*32*3</li>
</ul></li>
<li>filter滤波器：height*width*depth
<ul>
<li>5*5*3，卷积生成28*28*1的特征图</li>
<li>可以有多个滤波器进行卷积</li>
<li>用6个5*5*3的filter进行卷积，生成28*28*6的特征图</li>
</ul></li>
<li><strong>卷积后需要进行输入激活函数</strong></li>
</ul>
<h4 id="池化层">池化层</h4>
<ul>
<li>Pooling用于降维
<ul>
<li>MaxPooling：取最大的</li>
<li>AveragePooling：取平均</li>
</ul></li>
</ul>
<h2 id="lecture-6">Lecture 6</h2>
<h3 id="clustering">6.1 Clustering</h3>
<ul>
<li>无监督学习
<ul>
<li>我们只有输入没有label，即只有x，没有y，不能使用MLE来评估</li>
<li>目标是找到interesting patterns</li>
<li>引入伪标签概念，不是真的label，只是把一群data聚在一起给他们一个label</li>
<li>先打伪标签，再训练再打伪标签</li>
</ul></li>
<li>EM：专门为无监督学习的</li>
</ul>
<h4 id="clustering-1">Clustering</h4>
<ul>
<li>做的事情是把空间中的data分为两处，分为两个pattern</li>
<li>聚类不一定要知道聚类个数K</li>
<li>Cluster
<ul>
<li>在Group中相似</li>
<li>在Group外不相似</li>
</ul></li>
</ul>
<h3 id="k-means">6.2 K-Means</h3>
<ul>
<li>假设有K个聚类，随机选择K个data points作为种子点<span class="math inline">\(\mu_k\)</span></li>
<li>递归进行以下过程，直到收敛
<ul>
<li>Assign each point to the cluster with the nearest seed
point，给每一个data打上伪标签，根据是目前的model中的<span class="math inline">\(\mu_k\)</span>
<ul>
<li><span class="math inline">\(z_i=argmin_k||x_i-\mu_k||^2\)</span></li>
</ul></li>
<li>Update the seed point for each cluster，第k类的中心更新
<ul>
<li><span class="math inline">\(\mu_k=\frac{1}{N_k}\sum_{i=1}^{N_k}x_i^{(k)}\)</span></li>
</ul></li>
</ul></li>
<li>复杂度分析
<ul>
<li>N个point，d为维度，K为聚类数，t是迭代数</li>
<li>时间复杂度<span class="math inline">\(O(tNKd)\)</span></li>
</ul></li>
<li>Centroid是聚类的中心，可以上是空间上的任意一点。</li>
<li>Medoid是聚类的中心，但是是point上的一个</li>
</ul>
<h4 id="k-medoids">K-Medoids</h4>
<p>给出K和D，D为pairwise distance matrix。</p>
<ul>
<li>随机选取K个数据点作为种子点</li>
<li>递归进行以下步骤
<ul>
<li>Assign每一个点，离种子点最近的。伪标签</li>
<li>更新种子点，种子点要保持为data中的一点。update</li>
</ul></li>
<li>How to find the medoid
<ul>
<li>计算中心点<span class="math inline">\(\mu\)</span></li>
<li>找到离<span class="math inline">\(\mu\)</span>最近的点</li>
</ul></li>
<li>复杂度：<span class="math inline">\(O(tN(k+1)d)\)</span></li>
</ul>
<h3 id="gaussian-mixture-model">6.3 Gaussian Mixture Model</h3>
<ul>
<li>假设model是有K个高斯分布，我们要估计参数</li>
<li><span class="math inline">\(\mu_k,\Sigma_k,\pi_k\)</span>分别是高斯分布的两个参数，和第k个模型产生这个data的先验概率</li>
<li>在之前的MLE中，我们已经知道了data是由哪个分布生成的，在这里我们并不知道</li>
<li><span class="math inline">\(p(x;\Theta)=\sum_{k=1}^K\pi_kp_k(x;\theta_k)\)</span>这里就是Mixture，每个数据点都是由一个模型生成的，但是我们不知道具体是哪个，因此需要一个概率参数进行估计</li>
<li><span class="math inline">\(\Theta=\{\pi_1,...,\pi_k,\theta_1,...,\theta_k\},\sum_{k=1}^K\pi_k=1\)</span></li>
<li><span class="math inline">\(p_k(x;\theta_k)=N(x;\mu_k,\Sigma_k)\)</span></li>
<li>用log-likelihood解会非常难解
<ul>
<li><span class="math inline">\(log\prod
p(x^{(i)};\Theta)=\sum_{i=1}^Nlog(\sum_{k=1}^K\pi_kN(x^{(i)};\mu_k,\Sigma_k))\)</span></li>
<li>我们可以用琴生不等式解出下界</li>
</ul></li>
</ul>
<h4 id="参数估计-1">参数估计</h4>
<ul>
<li>引入伪标签变量<span class="math inline">\(z_k\)</span></li>
<li><span class="math inline">\(P(z_k)=\pi_k\)</span></li>
<li><span class="math inline">\(P(x_i,z_i)=P(x_i|z_i)P(z_i)\)</span></li>
<li><span class="math inline">\(P(x_i|z_i=k)\)</span>是高斯的<span class="math inline">\(N(\mu_k,\Sigma_k)\)</span></li>
<li>初始的<span class="math inline">\(\pi_k,\mu_k,\Sigma_k\)</span>是随机的</li>
</ul>
<h5 id="e-step-打伪标签">E Step 打伪标签</h5>
<ul>
<li>算后验，<span class="math inline">\(Q_k^{(i)}=P(z^{(i)}=k|x^{(i)})\)</span></li>
<li><span class="math inline">\(=\frac{p(x^{(i)}|z^{(i)}=k)P(z^{(i)}=k)}{p(x^{(i)})}\)</span></li>
<li>其中<span class="math inline">\(p(x^{(i)}|z^{(i)}=k)\)</span>是服从高斯分布的</li>
<li>其中<span class="math inline">\(P(z^{(i)}=k)=\pi_k\)</span></li>
<li>其中<span class="math inline">\(p(x^{(i)})=\sum_k
p(x^{(i)}|z^{(i)}=k)p(z^{(i)}=k)\)</span></li>
</ul>
<h5 id="m-step-更新参数">M Step 更新参数</h5>
<ul>
<li>多了<span class="math inline">\(Q_k\)</span>，MLE是没有<span class="math inline">\(Q_k\)</span>直接更新的</li>
<li><span class="math inline">\(\mu_k=\frac{\sum_i
Q_k^{(i)}x^{(i)}}{\sum_i Q_k^{(i)}}\)</span></li>
<li><span class="math inline">\(\Sigma_k=\frac{\sum_i
Q_k^{(i)}(x^{(i)}-\mu_k)(x^{(i)}-\mu_k)^T}{\sum_i
Q_k^{(i)}}\)</span></li>
<li><span class="math inline">\(\pi_k=\frac{\sum_iQ_k^{(i)}}{n}\)</span></li>
</ul>
<h3 id="em">6.4 EM</h3>
<ul>
<li>Convex Set：一个集合是Convex的，仅当集合两点中的任一点都在集合中
<ul>
<li><span class="math inline">\(any \ x_1,x_2\in C,\ \theta
x_1+(1-\theta)x_2\in C,\ \theta\in(0,1)\)</span></li>
</ul></li>
<li>Convex Function：凸函数，下凸
<ul>
<li><span class="math inline">\(f(\theta x_1+(1-\theta)x_2)\leq\theta
f(x_1)+(1-\theta)f(x_2)\)</span></li>
</ul></li>
<li>Concave Function：凹函数，上凸
<ul>
<li>与凸函数相反</li>
</ul></li>
</ul>
<h4 id="jensen不等式">Jensen不等式</h4>
<ul>
<li>若f为凸函数，则满足</li>
<li><span class="math inline">\(f(\sum_{i=1}^n\lambda_ix_i)\leq\sum_{i=1}^n\lambda_if(x_i)\)</span></li>
<li>其中<span class="math inline">\(\lambda_i\geq0,\sum\lambda_i=1\)</span></li>
<li>即<span class="math inline">\(f(E[x])\leq E[f(x)]\)</span></li>
<li>那么我们就可以解之前的最大似然函数
<ul>
<li><span class="math inline">\(log\prod
p(x^{(i)};\Theta)=\sum_{i=1}^Nlog(\sum_{k=1}^K\pi_kN(x^{(i)};\mu_k,\Sigma_k))\)</span></li>
<li>可以不断计算它的<strong>low bound</strong>，因为log是凹的！</li>
</ul></li>
</ul>
<h3 id="problem-description">6.5 Problem Description</h3>
<ul>
<li>我们的模型是<span class="math inline">\(P(x,z,\theta)\)</span>但是我们只观测到x</li>
<li>log似然函数
<ul>
<li><span class="math inline">\(l(\theta)=\sum_{i=1}^nlog\sum_zP(x_i,z;\theta)\)</span></li>
</ul></li>
<li>设<span class="math inline">\(Q(z_k)\)</span>是后验概率即<span class="math inline">\(Q(z_k)=P(z_k|x_i,\theta)\)</span>
<ul>
<li><span class="math inline">\(\sum_z Q(z)=1\)</span></li>
</ul></li>
<li><span class="math inline">\(L(\theta)=\sum_{i=1}^n log \sum_z
P(x_i,z;\theta)=\sum_{i=1}^nlog\sum_zQ(z)\frac{P(x_i,z;\theta)}{Q(z)}\)</span></li>
<li><span class="math inline">\(\geq\sum_{i=1}^n\sum_zQ(z)log\frac{P(x_i,z;\theta)}{Q(z)}=l(\theta)\)</span></li>
<li>其中<span class="math inline">\(P(x_i,z,\theta)/Q(z)\)</span>是一个constant</li>
<li><span class="math inline">\(P(x_i,z,\theta)/Q(z)=P(x_i,\theta)\)</span></li>
</ul>
<h3 id="em算法总结">6.6 EM算法总结</h3>
<ul>
<li>E :<span class="math inline">\(Q(z)=P(z|x^{(i)};\theta)\)</span></li>
<li>M：<span class="math inline">\(\theta=argmax_{\theta}\sum_{i=1}^m\sum_zQ(z)log\frac{p(x^{(i)},z^{(i)};\theta)}{Q(z)}\)</span></li>
</ul>
<h3 id="density-based-clustering-method">6.7 Density-Based Clustering
Method</h3>
<h2 id="lecture-7">Lecture 7</h2>
<p>降维技巧</p>
<ul>
<li>什么是降维？
<ul>
<li>从x到z的特征映射</li>
<li>x是原始representation，通常是高维的</li>
<li>z的维度更低，从而进行降维</li>
</ul></li>
</ul>
<h3 id="linear-and-nonlinear">Linear and Nonlinear</h3>
<h5 id="linear-transformation">Linear Transformation</h5>
<ul>
<li><span class="math inline">\(\mathcal{F}(x\in R^n)=z\in
R^d\)</span></li>
<li>z是d维的，每一个维度的值都是有一个projection函数决定的
<ul>
<li><span class="math inline">\(f_1(x)=z_1,...,f_d(x)=z_d\)</span></li>
<li>f是线性的，<span class="math inline">\(a_i^Tx=z_i\)</span></li>
<li><span class="math inline">\(A=[a_1,...,a_d],A^Tx=z\)</span></li>
</ul></li>
<li><span class="math inline">\(A^T\in R^{d\times p}:x\in R^p\rarr
z=A^Tx\in R^d\)</span></li>
<li>A怎么学习？无监督学习，有监督学习</li>
</ul>
<h4 id="feature-extraction-vs-feature-selection">Feature Extraction VS
Feature Selection</h4>
<ul>
<li>Selection：选择最好的subset</li>
</ul>
<h3 id="pca主成分分析">PCA主成分分析</h3>
<p>这是一种无监督学习的降维，核心思想点是降维的表示的信息不要丢弃，保持信息，因为没有信息，因此我们需要保留信息。</p>
<p>variance要尽量大，从而进行特征信息的保存。用于Compression和classification。</p>
<p>Retain most of the sample's information：定义什么是sample's
information？是variation。</p>
<h4 id="将二维降到一维的任务">将二维降到一维的任务</h4>
<p>对n个data做降维，我们假设有p维的n个数据<span class="math inline">\(\{x_1,...,x_n\}\)</span></p>
<p>假设线性transformation：<span class="math inline">\(z_i^{(1)}=a_1^Tx_i\)</span>，这里的1？</p>
<p>我们要优化a，让var(z)最大</p>
<p><span class="math inline">\(var(z^{(1)})=E((z^{(1)}-\overline{z}^{(1)})^2)\)</span></p>
<p><span class="math inline">\(=\frac{1}{n}\sum(a^T_1x_i-a^T_1\overline
x)^2\)</span></p>
<p><span class="math inline">\(=\frac{1}{n}\sum a^T_{1}(x_i-\overline
x)(x_i-\overline x)^Ta_1=a_1^TSa_1\)</span></p>
<p><span class="math inline">\(S=\frac{1}{n}\sum(x_i-\overline
x)(x_i-\overline x)^T\)</span></p>
<p>我们要做的就是<span class="math inline">\(max_{a_1}a_1^TSa_1\)</span></p>
<p>假设<span class="math inline">\(a_1^Ta_1=1\)</span></p>
<p><span class="math inline">\(L=a_1^TSa_1+\lambda(a_1^Ta_1-1)\)</span></p>
<p>求导<span class="math inline">\(Sa_1=\lambda a_1\)</span></p>
<p>那么<span class="math inline">\(a_1\)</span>就是特征向量</p>
<h3 id="lda-linear-discriminant-analysis">LDA Linear Discriminant
Analysis</h3>
<p>监督降维，并且需要分类，有标签的类，在降维后还是要分类</p>
<p>类内距离小，类间距离大，就是目标函数，假设有两个类</p>
<p><span class="math inline">\(z=a^Tx\)</span></p>
<p><span class="math inline">\(\overline \mu_i=\frac{1}{n}\sum_{z\in
w_i}z\)</span></p>
<p><span class="math inline">\(\mu_i=\frac{1}{n}\sum_{x\in
w_i}x\)</span></p>
<p><span class="math inline">\(\overline \mu_i=a^T\mu_i\)</span></p>
<p>我们的目标函数<span class="math inline">\(\frac{(\overline
\mu_1-\overline\mu_2)^2}{S_1^2+S_2^2}\)</span></p>
<p><span class="math inline">\(s_i^2=\sum_{y\in w_i}(y-\overline
\mu_i)^2=\sum_{x\in w_i}(a^Tx-a^T\mu_i)^2=\sum_{x\in
w_i}(a^Tx-a^T\mu_i)(a^Tx-a^T\mu_i)^T\)</span></p>
<p><span class="math inline">\(=\sum_{x\in
w_i}a^T(x-\mu_i)(x-\mu_i)^Ta=a^TS_ia\)</span></p>
<p>within-class sactter matrix：<span class="math inline">\(S_w=S_1+S_2,s_1^2+s_2^2=a^TS_wa\)</span></p>
<p>between-class sactter matrix：<span class="math inline">\(S_B=a^TS_Ba\)</span></p>
<p>那么最大化<span class="math inline">\(J(a)=\frac{a^TS_Ba}{a^TS_wa}\)</span></p>
<h3 id="lpp-locality-preserving-projection">LPP Locality Preserving
Projection</h3>
<p>局部保持，只定义两个data point是不是邻居</p>
<p><span class="math inline">\(x\in R^p \rarr a^Tx=z\)</span></p>
<p><span class="math inline">\(W\in
R^{n*n},w_{ij}=\begin{cases}1,x_i和x_j是邻居\\0\end{cases}\)</span></p>
<p><span class="math inline">\(min\sum_{ij}w_{ij}(z_i-z_j)^2=min\sum_{ij}w_{ij}(a^Tx_i-a^Tx_j)^2\)</span></p>
<p>我们只需要最小化原始空间中为邻居的点的距离</p>
<p><span class="math inline">\(=min\sum_{ij}w_{ij}a^T(x_i-x_j)(x_i-x_j)^Ta=min\
a^T\sum_{ij}w_{ij}(x_ix_i^T-x_ix_j^T-x_jx_i^T+x_jx_j^T)a\)</span></p>
<p><span class="math inline">\(=min\ a^TXLX^Ta\)</span></p>
<p><span class="math inline">\(L=D-W\)</span></p>
<p><span class="math inline">\(\sum_{ij}w_{ij}()()^T=XWX^T\)</span></p>
<h2 id="lecture-8">Lecture 8</h2>
<h3 id="非监督学习-1">非监督学习</h3>
<p>传统的技术，隐因子发掘的技术</p>
<ul>
<li>主题建模</li>
<li>矩阵分解</li>
</ul>
<h3 id="主题建模">主题建模</h3>
<ul>
<li>是一个统计模型，发现隐主题</li>
<li>应用：
<ul>
<li>文本生成</li>
<li>信息检索</li>
</ul></li>
</ul>
<h4 id="词袋模型">词袋模型</h4>
<ul>
<li>我们简化了词的顺序信息，没有顺序信息</li>
<li>只考虑这个词是否出现在文档中</li>
<li>可以考虑频率等统计信息</li>
</ul>
<p>定义</p>
<ul>
<li>词：<span class="math inline">\(w\)</span>，词的集合</li>
<li>文本：<span class="math inline">\(d=\{w_1,...,w_n\}\)</span>，一系列词构成的集合</li>
<li>一系列文本：<span class="math inline">\(D=\{d_1,...,d_N\}\)</span>，一系列文本</li>
<li>每个词的产生是独立的
<ul>
<li><span class="math inline">\(p(w)=\theta_w=\frac{n_w}{\sum_v^V
n_v}\)</span>词的频率就是概率，相当于先验，<span class="math inline">\(n_v\)</span>是第v个词出现在文本中的频数
<ul>
<li><span class="math inline">\(\sum_v^V \theta_w=1\)</span></li>
</ul></li>
<li><span class="math inline">\(p(D;\theta)=\prod_{i=1}^Np(d;\theta)=\prod_{i=1}^N\prod_{j=1}^np(w_j)=\prod_{w}^V\theta_w^{n_w}\)</span></li>
<li>最大似然</li>
<li><span class="math inline">\(l(\theta)=\sum_{w}^V
n_wlog\theta_w\)</span></li>
</ul></li>
</ul>
<h4 id="document-term-matrix">Document-Term Matrix</h4>
<p>传统的文档词汇的建模</p>
<p>D是所有文档的集合，<span class="math inline">\(d_i\)</span>是文档，<span class="math inline">\(w_j\)</span>是每一个词，W为词的集合</p>
<p>矩阵维度<span class="math inline">\(|D\times W|\)</span></p>
<p>在矩阵的(i,j)上存了一个频率，即第j个词在第i个文档的出现的频率，<strong>一般来说这个矩阵会比较稀疏</strong></p>
<p>对文档进行降维，我们想让他从<strong>词汇的空间到一个主题的空间</strong></p>
<ul>
<li>Polysemy：一词多义
<ul>
<li>vector space model不能区分一词多义</li>
</ul></li>
<li>Synonymy：同义词
<ul>
<li>同义词在vector space model中没有联系</li>
</ul></li>
<li>topic和words，topic是低维的，words是高维的</li>
</ul>
<h4 id="language-model-paradigm-in-ir">Language Model Paradigm in
IR</h4>
<p>模型做什么？后验概率</p>
<p>定义</p>
<ul>
<li><span class="math inline">\(R_d\in\{0,1\}\)</span> d是否相关</li>
<li><span class="math inline">\(q\subseteq
\Sigma\)</span>：查询一系列的查询关键词</li>
<li><span class="math inline">\(P(R_d=1|q)=\frac{P(q|R_d=1)P(R_d=1)}{P(q)}\)</span></li>
<li><span class="math inline">\(P(R_d=1|q)\)</span>
<ul>
<li>给定一个查询q，第d个文档相关的概率</li>
</ul></li>
<li>对于词是离散的不是连续的不能用高斯模型</li>
<li><span class="math inline">\(P(q|R_d=1)\)</span>为了搜索相关文档d而生成搜索关键词q的概率
<ul>
<li>之前的似然度是从高斯模型中计算的，是连续的</li>
<li>查询的似然度，从文本中进行采样，确定了文章的主题，一些词汇的频率会比较高</li>
<li>实际中如何获得？</li>
<li><span class="math inline">\(P(q|R_d=1)=P(q|d)\)</span></li>
<li><span class="math inline">\(q=\{w_1,...,w_q\}\)</span></li>
<li><span class="math inline">\(P(q|d)=\prod P(w_i|d)\)</span></li>
<li><span class="math inline">\(\hat
P(w_i|d)=\frac{n(d,w)}{\sum_{w&#39;}n(d,w&#39;)}\)</span></li>
</ul></li>
<li><span class="math inline">\(P(R_d=1)\)</span>文档中的先验
<ul>
<li>实际中使用流行度，即文章被搜索到的概率，对一个网站来说，如果说许多重要的网站链接到了用这个网站，那么这个网站是流行的</li>
<li>与查询无关，与流行度有关</li>
</ul></li>
</ul>
<h4 id="plsa">PLSA</h4>
<p>Probabilistic Latent Semantic Analysis 无监督降维，用隐因子表示</p>
<p>Documents<span class="math inline">\(\rarr\)</span>Latent
Concepts<span class="math inline">\(\rarr\)</span>Terms</p>
<p><span class="math inline">\(\hat
P(w|d)=\sum_zP(w|z)P(z|d)\)</span></p>
<p>文档是很难产生词的。我们引入隐变量z，我们先预估文档是关于什么主题的，对于每个主题，产生词的概率是怎么样的。</p>
<ul>
<li>给出一个文档，它的主题概率分布如何？<span class="math inline">\(P(z|d;\theta)\)</span></li>
<li>给出一个主题，它的词的概率分布如何？<span class="math inline">\(P(w|z;\pi)\)</span></li>
</ul>
<p><span class="math inline">\(l(\theta,\pi;N)=\sum_{d,w}n(d,w)log(\sum_zP(w|z;\theta)P(z|d;\pi))\)</span></p>
<h2 id="lecture-9">Lecture 9</h2>
<h3 id="svd奇异值分解">SVD奇异值分解</h3>
<ul>
<li>求法
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/keshuaiChen/article/details/109371314">(13条消息)
如何求矩阵的特征值和特征向量_是可帅鸭的博客-CSDN博客_求矩阵特征向量</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/tyzttzzz/article/details/50285317">(13条消息)
奇异值分解习题_MC_Zealot的博客-CSDN博客_奇异值分解例题详解</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/zpalyq110/article/details/86751064">(13条消息)
奇异值分解(SVD)原理及实例分析_Freeman_zxp的博客-CSDN博客_奇异值分析法</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/399547902">奇异值分解（SVD）的定义、证明、求法（矩阵分解——3.
奇异值分解（SVD）） - 知乎 (zhihu.com)</a></li>
</ul></li>
</ul>
<p>PCA：奇异值分解SVD，复杂度很大，没有并行算法。</p>
<p>对于任意一个矩阵<span class="math inline">\(X\in R^{m\times
n}\)</span>，存在一个分解</p>
<p><span class="math inline">\(X=U\Sigma V^T\)</span></p>
<p><span class="math inline">\(U\in R^{m\times m},V\in R^{n\times
n},U^TU=UU^T=1,V^TV=VV^T=1\)</span></p>
<p><span class="math inline">\(\Sigma\in R^{m\times
n}\)</span>为对角阵</p>
<p><span class="math inline">\(U\)</span>为<span class="math inline">\(AA^T\)</span>的特征向量构成的，<span class="math inline">\(V\)</span>是<span class="math inline">\(A^TA\)</span>特征向量构成的</p>
<p><span class="math inline">\(\Sigma^2=\Sigma^T\Sigma=\Lambda\)</span></p>
<p>其中<span class="math inline">\(A^TA=V\Lambda V^T,AA^T=U\Lambda
U^T\)</span></p>
<p><span class="math inline">\(\sigma_i\)</span>是<span class="math inline">\(XX^T\)</span>的按照递减次序排列的非零特征值的算术平方根</p>
<p><strong>SVD可以计算最优近似解，即低秩的近似运算</strong></p>
<ul>
<li><p><span class="math inline">\(X^*=argmin_{rank(\overline
X)=k}||X-\overline X||_F^2\)</span></p></li>
<li><p>SVD的解：</p></li>
<li><p><span class="math inline">\(X^*=Udiag\{\sigma_1,..,,\sigma_k,0,...,0\}V\)</span></p>
<ul>
<li>近似的原理是，奇异值会越来越小，我们将小的值作为0、</li>
<li>这里的k我们可以自己选择</li>
</ul></li>
<li><p>当k=d时，<span class="math inline">\(\Sigma =
diag\{\sigma_1,...,\sigma_d\}\)</span></p>
<p><span class="math inline">\(\sigma_1\geq \sigma_2\geq...\geq
\sigma_d\gt 0\)</span></p></li>
</ul>
<h3 id="矩阵分解">矩阵分解</h3>
<p><span class="math inline">\(X\in R^{m\times n}\)</span>,<span class="math inline">\(X=UV\)</span></p>
<p><span class="math inline">\(\begin{bmatrix}x_{11}\ x_{21}\ ...\
x_{n1}\\x_{12}\ x_{22}\ ...\ x_{n2}\\...\\x_{1m}\ x_{2m}\ ...\
x_{nm}\end{bmatrix}_{m*n}=\begin{bmatrix}u_{11}\ u_{21}\ ...\
u_{k1}\\u_{12}\ u_{22}\ ...\ u_{k2}\\...\\u_{1m}\ u_{2m}\ ...\
u_{km}\end{bmatrix}_{m*k}\times \begin{bmatrix}v_{11}\ v_{21}\ ...\
v_{n1}\\v_{12}\ v_{22}\ ...\ v_{n2}\\...\\v_{1k}\ v_{2k}\ ...\
v_{nk}\end{bmatrix}_{k,n}\)</span></p>
<ul>
<li><p><span class="math inline">\(U\in R^{m\times k}\)</span></p></li>
<li><p><span class="math inline">\(V\in R^{k\times n}\)</span></p></li>
<li><p>分解后，X中的每一列，即列向量<span class="math inline">\(x_i\)</span>都能表示为U中列向量<span class="math inline">\(u_1,...,u_k\)</span>的线性组合</p>
<ul>
<li><span class="math inline">\(x_i=v_{i1}u_1+...+v_{ik}u_k\)</span></li>
<li><span class="math inline">\(X=[x_1,...,x_n]=UV=U[v_1,...,v_n]\)</span>
<ul>
<li><span class="math inline">\(x_i\in R^m,v_i\in R^k\)</span></li>
<li><span class="math inline">\(x_i=Uv_i\)</span></li>
</ul></li>
</ul></li>
<li><p>每一个V中的列向量，可以看作X的低维的表示，将m维降维k维</p></li>
<li><p>如果存在一个矩阵<span class="math inline">\(A\in R^{k\times
m}\)</span>，满足</p>
<ul>
<li><span class="math inline">\(AU=I\)</span></li>
<li>那么<span class="math inline">\(Ax_i=v_i\)</span></li>
</ul></li>
</ul>
<p><strong>【主题建模】</strong></p>
<p>在主题建模中也可以使用矩阵分解</p>
<p><span class="math inline">\(P(w|d)=\frac{n(d,w)}{\sum_{w&#39;}n(d,w&#39;)}\)</span>，在文档d中词w的出现概率等于文档中w的个数除以文档中词的总个数。条件概率，对d文档，我们多大概率采样w这个词</p>
<p><span class="math inline">\(\sum_i P(w_i|d)=1\)</span></p>
<p>放入矩阵</p>
<p><span class="math inline">\(X=\begin{bmatrix}P(w_1|d_1)\ ...
P(w_1|d_n)\\...\\P(w_m|d_1)\ ...\ P(w_m|d_n)\end{bmatrix}\)</span></p>
<p>进行分解，原先文档的特征是文档的词的分布，即我们用一个向量表示了文档，第<span class="math inline">\(i\)</span>个文档的各个词的出现的概率在<span class="math inline">\(x_i\)</span>中被体现。用词表示太过于稀疏，我们使用矩阵分解，用主题表示。</p>
<p><span class="math inline">\(\hat P(w|d)=\sum_z
P(w|z)P(z|d)\)</span></p>
<p><span class="math inline">\(\hat X=\begin{bmatrix}\hat P(w_1|d_1)\
... \hat P(w_1|d_n)\\...\\\hat P(w_m|d_1)\ ...\ \hat
P(w_m|d_n)\end{bmatrix}\)</span></p>
<p><span class="math inline">\(U=\begin{bmatrix}\hat P(w_1|z_1)\ ...
\hat P(w_1|z_k)\\...\\\hat P(w_m|z_1)\ ...\ \hat
P(w_m|z_k)\end{bmatrix}\)</span></p>
<p><span class="math inline">\(V=\begin{bmatrix}\hat P(z_1|d_1)\ ...
\hat P(w_1|z_k)\\...\\\hat P(w_m|z_1)\ ...\ \hat
P(w_m|z_k)\end{bmatrix}\)</span></p>
<p>用k维的主题进行表示：</p>
<ul>
<li>对于一个文档，主题分布如何<span class="math inline">\(P(z|d)\)</span>的矩阵</li>
<li>对于一个主题来说，词的分布如何<span class="math inline">\(P(w|z)\)</span>的矩阵</li>
</ul>
<p><span class="math inline">\(X≈\hat X=UV\)</span></p>
<h3 id="nmf非负矩阵分解">NMF非负矩阵分解</h3>
<ul>
<li>Assumption
<ul>
<li>Low rank</li>
<li>Nonnegative</li>
</ul></li>
<li><span class="math inline">\(X\in R^{m\times n}\)</span>,<span class="math inline">\(\hat X=UV^T≈X\)</span></li>
</ul>
<h4 id="cost-function">Cost Function</h4>
<ul>
<li>欧几里得距离
<ul>
<li><span class="math inline">\(||A-B||^2=\sum_{i,j}(a_{ij}-b_{ij})^2\)</span></li>
</ul></li>
<li>Divergence
<ul>
<li><span class="math inline">\(D(A||B)=\sum_{ij}(A
_{ij}log\frac{A_{ij}}{B_{ij}}-A_{ij}+B_{ij})\)</span></li>
<li>一般是逼近概率值，而不是数据点</li>
</ul></li>
</ul>
<h4 id="nmf-optimization">NMF Optimization</h4>
<p><span class="math inline">\(min||X-UV^T||^2,s.t. u_{ij}\geq
0,v_{ij}\geq 0\)</span></p>
<p><span class="math inline">\(J=||X-UV^T||^2=tr((X-UV^T)^T(X-UV^T))\)</span></p>
<p><span class="math inline">\(J=tr(X^T-X^TUV^T-VU^TX+VU^TUV^T)\)</span></p>
<p><span class="math inline">\(L=tr(X^TX)-2tr(X^TUV^T)+tr(VU^TUV^T)+tr(\Gamma
U^T)+tr(\Phi V^T)\)</span></p>
<p><span class="math inline">\(\frac{\partial L}{\partial
U}=-2XV+2UV^TV+\Gamma\)</span></p>
<p><span class="math inline">\((UV^TV)_{ik}u_{ik}-(XV)_{ik}u_{ik}=0\)</span></p>
<p><span class="math inline">\(u_{ik}\leftarrow
\frac{(XV)_{ik}}{(UV^TV)_{ik}}u_{ik}\)</span></p>
<p>同理</p>
<p><span class="math inline">\(v_{jk}\leftarrow
\frac{(X^TU)_{jk}}{(VU^TU)_{jk}}u_{jk}\)</span></p>
<h2 id="lecture-10">Lecture 10</h2>
<h3 id="transformer">Transformer</h3>
<p>性能比CNN、RNN等都要好，而且能够统一空间特征和时间特征到同一个网络。既可以做时间序列的特征抽取也可以做空间数据的特征抽取。</p>
<h3 id="transformer的架构图">Transformer的架构图：</h3>
<ul>
<li>目前大部分人们的神经序列转换模型都有Encoder-Decoder结构。Encoder将输入序列映射到一个连续表示序列。编码和解码的网络。</li>
<li>对于编码得到的，Decoder每次解码生成一个符号，直到生成完整的输出序列
<ul>
<li>RNN有一个问题：我们会有遗忘问题，对于编码的越长的数据，我们会遗忘之前的信息，解码时只能使用近几个信息，前面的信息被遗忘了</li>
<li>对于一词多义现象：
<ul>
<li>聚焦模型：解码一个信息不仅仅要根据编码对应位置的信息，还要周围的信息，即判断环境。</li>
</ul></li>
</ul></li>
<li>对于每一步解码，模型信息都是自回归的，即在<strong>生成下一个符号时将先前生成的符号作为附加输入</strong>。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/5fd5d5bb151e4d729d8acd27baf98ad5.png" alt="img" style="zoom:80%;"></p>
<h4 id="模型结构">模型结构</h4>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/48508221">详解Transformer
（Attention Is All You Need） - 知乎 (zhihu.com)</a></p>
<p><strong>输入和输出</strong></p>
<p>之前的RNN和CNN都是编码解码架构，Transformer也是这么一个架构，有编码器和解码器</p>
<p>词袋模型的机制是：词的顺序不影响对句子的理解，但是实际中是影响的</p>
<p><strong>传统机器学习都是词袋模型</strong>，但是这不符合我们的预期，因此我们需要有序列</p>
<p>例如<strong>翻译问题</strong>，输入“Why do we work？”进入编码器</p>
<p>得到隐藏层输出到解码器，输入开始信号，输出“为”</p>
<p>再输入“为”，再输出“什”，即要依赖于<strong>原序列的数据</strong>、<strong>同时依赖于已解码的数据</strong>，就是说我们这里是自回归的。因为前后的解码结果有一定的关联性，因此我们依赖解码的词来进行下一步解码有助于提高准确度。</p>
<h3 id="attention机制">Attention机制</h3>
<p>这是transformer的灵魂，有很多种Attention机制</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/68823523">你需要知道Attention -
知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/69111029">Self-Attention和Transformer
- 知乎 (zhihu.com)</a></p>
<h3 id="qkv模型">QKV模型</h3>
<p>最简单的是QKV模型，Qurey，Key，Value。</p>
<p>假设输入是q，在memory中我们以<code>(key,value)</code>的形式存储上下文</p>
<ul>
<li>例如K是一个question，V是一个answer，Q是一个新的question，那么我们就会<strong>检索</strong>memory中的哪个<strong>K</strong>更与Q相似，再输出相似的K的V就是答案。给出一个新的问题，并不是检索Value和Q的相似度，而是K和Q的相似度。
<ul>
<li>在Memory中找相似<code>score function</code>：<span class="math inline">\(e_i=a(q,k_i)\)</span>
<ul>
<li>对每一个K，计算相似度</li>
</ul></li>
<li>归一化：<span class="math inline">\(\alpha_i=softmax(e_i)\)</span>，映射到概率
<ul>
<li>相似度大的，概率大</li>
</ul></li>
<li>读取内容：<span class="math inline">\(c=\sum_{i}\alpha_i
v_i\)</span>
<ul>
<li>输出对Value加权求和</li>
</ul></li>
</ul></li>
</ul>
<p><strong>Attention机制是用来干嘛的</strong></p>
<ul>
<li>借鉴了生物在观察和学习行为过程中，建立起对事物的需要重点观察或学习的区域，来获取全局信息</li>
<li>我们没有办法同时处理所有事情，会有<strong>优先级</strong>，<strong>注意力就会有一个权重值</strong>，从而更专注的聚焦到某些关键信息上。</li>
</ul>
<h3 id="self-attention自聚焦机制">Self-Attention自聚焦机制</h3>
<p>之前的RNN等序列编码，只解决了前面一项的数据的影响，未考虑后向的编码的影响，解决方法双向的RNN、LSTM等，即解决了<strong>前项依赖和后项依赖</strong>，但是遗忘问题仍未解决。</p>
<p>Self-Attention本质上是一种特殊的Attention，要解决传统算法的问题。依赖较远的问题，在一句话中可以很好地学习场景表达。<strong>只考虑一个序列内部的聚焦机制。</strong></p>
<p>权重w并不是一个需要神经网络学习的参与，假设有两个element，不一定挨在一起，有距离，来源于<span class="math inline">\(x_i,x_j\)</span>的计算结果</p>
<p><span class="math inline">\(w_{ij}&#39;=x_i^Tx_j\)</span>关联度，即重要程度</p>
<p><span class="math inline">\(w_{ij}=\frac{exp(w_{ij}&#39;)}{\sum_jexp(w_{ij}&#39;)}\)</span>根据关联度生成权重</p>
<h5 id="at和sa的不同之处">AT和SA的不同之处</h5>
<ul>
<li>AT经常被应用于从编码器到解码器</li>
<li>SA比较擅长在一个序列中，寻找不同部分的关系</li>
<li>AT可以连接两种不同的模态，如图片和文字；SA更多应用在统一模态上</li>
<li>SA可以在一个模型中被多次独立使用。</li>
</ul>
<h3 id="qkv聚焦机制">QKV聚焦机制</h3>
<p>Attention函数可以将Query和一组Key-Value对映射到输出，其中QKV和输出都是向量。输出是值的加权和，其中分配给每个Value的权重由Query与相应的Key兼容函数计算。</p>
<p>这种机制称为Scaled Dot</p>
<p><span class="math inline">\(Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt
d_k})V\)</span></p>
<p>获得一个加权的特征向量。</p>
<p><span class="math inline">\(d_k\)</span>为维度</p>
<p>Trick1 ：对于SA可以加入学习参数<span class="math inline">\(W_q,W_k,W_v\)</span></p>
<ul>
<li><p><span class="math inline">\(q_i=W_qx_i\)</span></p></li>
<li><p><span class="math inline">\(k_i=W_kx_i\)</span></p></li>
<li><p><span class="math inline">\(v_i=W_v x_i\)</span></p></li>
<li><p><span class="math inline">\(x_i是raw\_data\)</span>，即输入的数据</p></li>
<li><p><span class="math inline">\(w_{ij}&#39;=q_ik_j^T\)</span>计算score</p></li>
<li><p>归一化，除以<span class="math inline">\(\sqrt
d_k\)</span></p></li>
<li><p>对score使用softmax激活函数</p></li>
<li><p>softmax点乘value值v，得到加权的每个输入向量的评分<span class="math inline">\(v\)</span></p></li>
<li><p>相加之后得到<span class="math inline">\(z=\sum
v\)</span></p></li>
</ul>
<p>Trick 2：为什么有根号？</p>
<ul>
<li>Softmax函数对非常大的输入很敏感，梯度传播出现问题，导致学习速度下降，导致学习停止</li>
<li>用<span class="math inline">\(\sqrt
d_k\)</span>来对输入的向量进行缩放，放置softmax的函数增长过大</li>
</ul>
<p>Trick 3：Multi-Head Attention</p>
<ul>
<li>相当于h个不同的self-attention的集成</li>
<li>将输入的X输入到h个self-attention中，得到h个加权后的特征矩阵</li>
<li>特征矩阵经过全连接得到输出Z</li>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221024190627366.png" alt="image-20221024190627366">
<figcaption aria-hidden="true">image-20221024190627366</figcaption>
</figure></li>
<li><span class="math inline">\(Multihead(Q,K,V)=Concat(head_1,...,head_h)W\)</span></li>
<li><span class="math inline">\(head_i=Attention(QW_i^Q,KW_i^K,VW_i^V)\)</span></li>
</ul>
<h2 id="lecture-11">Lecture 11</h2>
<h3 id="tokenize">Tokenize</h3>
<p>第一步就是tokenize函数</p>
<p>定义一个正则，输入一个句子，输出一些列词语。</p>
<h3 id="input-embeddinghttpswww.jianshu.compe6b5b463cf7b">[Input
Embedding][https://www.jianshu.com/p/e6b5b463cf7b]</h3>
<p>输入编码，输入是</p>
<ul>
<li>词的大小vocab_size</li>
<li>模型维度d_model：对于词，计算机难以看懂，用向量和数值表达词语</li>
</ul>
<p>定义一个矩阵，矩阵大小是vocab_size行，一行d_model个值，词语转化为向量的一个矩阵。</p>
<p>如何考虑到词的顺序？</p>
<h3 id="position-encoder">Position Encoder</h3>
<p>使用PE来表示词的顺序，即对词语的位置进行编码。</p>
<p>输入编码矩阵：embedding vector*input
words的矩阵，词的嵌入矩阵，词的表示的局长那你</p>
<p>位置编码矩阵：不同的位置用不同的向量表示embedding
vector*max_seq_len的矩阵</p>
<p><strong>带有位置信息的输入编码 =
输入编码+位置编码矩阵对应位置的向量</strong></p>
<ul>
<li>如何赋予其位置</li>
<li>i是编码维度，pos为位置</li>
<li>对<code>pos in range(max_seq_len)</code>每一个位置
<ul>
<li><span class="math inline">\(PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})\)</span></li>
<li><span class="math inline">\(PE_{(pos,2i+1)}=cos(pos/10000^{2i+1/d_{model}})\)</span></li>
</ul></li>
</ul>
<h3 id="transformer-block">Transformer Block</h3>
<ul>
<li><p>self-attention layer</p>
<ul>
<li>对于attention函数
<ul>
<li>首先获得<span class="math inline">\(score=\frac{QK^T}{\sqrt
d_k}\)</span></li>
<li>softmax函数激活</li>
<li>返回softmax(score)*V</li>
</ul></li>
<li>多头聚焦机制
<ul>
<li>定义三个投射矩阵</li>
<li>使用多头机制</li>
</ul></li>
</ul></li>
<li><p>normalization layer</p>
<ul>
<li><p>如何做layer norm</p></li>
<li><p>使得梯度更加平稳</p></li>
<li><p>```pseudocode input X in R^{B<em>d} output y in R^{B</em>d} mu_B
= 1/B sum(X) sigma_B^2 = 1/B sum((X-mu_B)^2) X' = (X-mu_B)/sigma_B Y =
gamma·X'+beta //gamma beta是要学习的 <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- feed forward layer</span><br><span class="line"></span><br><span class="line">  - 选择<span class="number">4</span>倍大小作为我们feedforward层的维度，这个值使用的越小就越节省内存，但是相应的表示性也会变差。</span><br><span class="line"></span><br><span class="line">    ```python</span><br><span class="line">    self<span class="selector-class">.ff</span> = nn<span class="selector-class">.Sequential</span>(</span><br><span class="line">    	nn<span class="selector-class">.Linear</span>(k,<span class="number">4</span>*k),</span><br><span class="line">    	nn<span class="selector-class">.ReLU</span>(),</span><br><span class="line">    	nn<span class="selector-class">.Linear</span>(<span class="number">4</span>*k,k)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure></p></li>
<li><p>Transformer Block的forward</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forawrd</span>(<span class="params">self,x</span>):</span><br><span class="line">attended = self.attention(x)</span><br><span class="line">x = self.norm1(attended+x)//残差</span><br><span class="line">fedforward = self.ff(x)</span><br><span class="line"><span class="keyword">return</span> self.norm1(fedforward+x)//残差</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>another normalization layer</p></li>
</ul>
<h2 id="lecture-12">Lecture 12</h2>
<p>解码时使用编码的结果，不能使用自聚焦机制。</p>
<p>解码器的输入是上一轮的输出，因此解码器不能并行，只能串行。</p>
<h3 id="encoder">Encoder</h3>
<p><strong>输入：</strong></p>
<ul>
<li>vocab_size词的个数</li>
<li>d_model模型的维度</li>
<li>N编码有多少的Transformer Block</li>
<li>heads多头注意力机制的多少个头</li>
<li>dropout防止过拟合</li>
</ul>
<ol type="1">
<li>获得编码矩阵</li>
<li>初始化位置编码</li>
<li>堆砌N个Encoder Layer，即N个Block
<ul>
<li>Encoder Layer
<ul>
<li>normalization</li>
<li>attention</li>
<li>dropout&amp;normalization</li>
<li>feed forward</li>
<li>normalization</li>
</ul></li>
</ul></li>
<li>最后进行Normalization</li>
</ol>
<h3 id="decoder">Decoder</h3>
<p>结构和Encoder差不多，多了一个attention和sub-layer</p>
<p>输出：对应i位置的输出词的概率分布</p>
<p>输入：encoder输出和对应的i-1位置的decoder输出。中间的attention不是self-attention，它的K，V来自于Encoder，Q来自于</p>
<ol type="1">
<li>normalization</li>
<li>mask attention，mask未解码的部分，解码部分使用自注意力机制学习</li>
<li>dropout&amp;normalization</li>
<li>attention：利用编码信息</li>
<li>dropout&amp;normalization</li>
</ol>
<h3 id="masked-multi-head-attention">Masked Multi-Head Attention</h3>
<p>只希望前侧的上下文对注意有影响，不希望后侧的上下文对注意的影响。因为说话时，我们不能通过没有说的话对现在说的进行推理。</p>
<p>只使用已经输出的词对其进行理解聚焦。如何让后面的词对现在的此没有影响？我们让相似度足够小，即权重小，那么对应的元素对我们的影响小。</p>
<p>自注意力机制SA</p>
<ul>
<li>在Encoder中使用</li>
<li>对于一个元素来说，我们可以从其前后的上下文来理解，帮助解码K=V=Q</li>
</ul>
<p>掩码注意力机制MSA</p>
<ul>
<li>在Decoder中使用</li>
<li>对于一个元素来说，我们只从其<strong>前</strong>的上下文来理解，帮助解码K=V=Q</li>
</ul>
<p>Attention</p>
<ul>
<li>将Decoder进行Attention到Encoder的结果</li>
</ul>
<h3 id="cnn-in-transformer">CNN in Transformer</h3>
<p>输入图片<span class="math inline">\(H*W*C\)</span>，对图片分块，每个块长度<span class="math inline">\(P*P\)</span>，有<span class="math inline">\(N=H*W/(P*P)\)</span>块</p>
<p>每一块展成一维向量，长度为<span class="math inline">\(P*P*C\)</span></p>
<p>总输入变换<span class="math inline">\(N*(P^2*C)\)</span></p>
<h4 id="patch-embedding">Patch Embedding</h4>
<p>线性变化，全连接层，压缩维度从patch_dim到dim</p>
<h4 id="position-embedding">Position Embedding</h4>
<p>位置编码没有用传统的cos和sin编码，而是采用随机初始化，之后训练出来。</p>
<h4 id="cls-token">Cls Token</h4>
<p>分类任务，对于图片分类或者句子分类，需要学习的是全局表征。</p>
<p>ViT只用了Encoder编码器结构，缺少解码过程，因此给了额外的一个用于分类的向量，与输入进行拼接。</p>
<h2 id="lecture-13">Lecture 13</h2>
<h3 id="dropout">Dropout</h3>
<p>为什么会有Dropout？</p>
<p>overfitting一种现象</p>
<ol type="1">
<li>训练集和测试集分布不同；</li>
<li>训练集并没有真多"训练"，而是记忆到了网络中</li>
</ol>
<p>不希望所有的神经元一起学习，希望删掉一些神经元后还是可以进行学习。解决两个神经元耦合的问题，<strong>避免两个神经元协同学习</strong>，某种程度上对神经网络进行解耦。</p>
<p>dropout网络，在参数传入前进行一个randam mask，从而进行dropout。</p>
<p><span class="math inline">\(r_j^{(l)}\)</span>~<span class="math inline">\(Bernoulli(p)\)</span></p>
<p><span class="math inline">\(\hat y^{(l)}=r^{(l)}*y^{(l)}\)</span></p>
<p><span class="math inline">\(z_i^{(l+1)}=w_i^{(l+1)}\hat
y^{(l)}+b_i^{(l+1)}\)</span></p>
<p><span class="math inline">\(y^{(l+1)}=f(z_i^{(l+1)})\)</span></p>
<p>本质上是机器学习的方法。数据太少，用dropout会欠拟合，数据太多，dropout没有作用。</p>
<p>模型平局：Dropout是模型平均的一种</p>
<ul>
<li>对于每次输入的样本，其对应的网络结构都是不同的，取平均会让过拟合和欠拟合结果相互抵消。</li>
<li>Dropout策略使得网络共享权重，因此训练测试时间代价低。</li>
</ul>
<p>减少单元共适应：Dropout策略使得每个单元不一定每次训练都在同一个网络中，从而可以解耦原先单元们之间的依赖关系，提高网络的鲁棒性。</p>
<h2 id="lecture-14">Lecture 14</h2>
<h3 id="batch-normalization-and-layer-normalization">Batch Normalization
and Layer Normalization</h3>
<h4 id="批归一化batch-normalization-bn">批归一化<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34879333">Batch Normalization</a>
BN</h4>
<p>解决神经网络内部协变量偏移的问题，加速网络收敛速度。</p>
<h5 id="internal-covariate-shift">Internal Covariate Shift</h5>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221101164121443.png" alt="image-20221101164121443" style="zoom: 80%;"></p>
<p>每次用一个mini-batch来优化网络，每一个p都会学到一个分布，容易学到带方差的。</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221101164156653.png" alt="image-20221101164156653" style="zoom:80%;"></p>
<ul>
<li>通过规范化手段，把每层神经网络输入值的分布（每个特征）强行拉回均值为0，方差为1的标准正态分布</li>
<li>使得激活函数的输入值落到敏感区域内，使得梯度变大，避免梯度消失问题。</li>
<li>一般Batch Normalization操作是在激活函数之前的。</li>
</ul>
<h5 id="如何实现批归一化">如何实现批归一化？</h5>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221101165034824.png" alt="image-20221101165034824" style="zoom:80%;"></p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221101165340680.png" alt="image-20221101165340680" style="zoom:80%;"></p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221101165606838.png" alt="image-20221101165606838" style="zoom:80%;"></p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221101165616427.png" alt="image-20221101165616427" style="zoom:80%;"></p>
<p>批处理可学习。</p>
<p>如同上面提到的，Normalization操作我们虽然缓解了ICS问题，让每一层网络的输入数据分布都变得稳定，但却导致了数据表达能力的缺失。也就是我们通过变换操作改变了原有数据的信息表达（representation
ability of the
network），使得底层网络学习到的参数信息丢失。另一方面，通过让每一层的输入分布均值为0，方差为1，会使得输入在经过sigmoid或tanh激活函数时，容易陷入非线性激活函数的线性区域。</p>
<p>因此，BN又引入了两个可学习（learnable）的参数 γ 与 β
，这两个参数的引入是为了恢复数据本身的表达能力，对规范化后的数据进行线性变换，即
<span class="math inline">\(Z_j=γ_jZ_j+β_j\)</span> 。特别地，当 <span class="math inline">\(γ^2=σ^2\)</span>,β=μ
时，可以实现等价变换（identity
transform）并且保留了原始输入特征的分布信息。</p>
<p>加上拉伸和偏移的参数，可以学习。归一化导致数据表达能力的遗失，因此我们使用两个参数进行学习。使用反向传播和梯度下降求<span class="math inline">\(\beta,\gamma\)</span>。</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221101165730297.png" alt="image-20221101165730297" style="zoom:67%;"></p>
<p>类比为一摞书，这摞书总共有 N 本，每本有 C 页，每页有 H 行，每行 W
个字符。BN
求均值时，相当于把这些书按页码一一对应地加起来（例如第1本书第36页，第2本书第36页…），再除以每个页码下的字符总数：N×H×W，因此可以把
BN
看成求“平均书”的操作（注意这个“平均书”每页只有一个字），求标准差时也是同理。</p>
<h4 id="层归一化ln">层归一化LN</h4>
<p>如果batchsize比较小，均值和方差估计有偏，效果较差。</p>
<p>把一个 batch 的 feature 类比为一摞书。LN
求均值时，相当于把每一本书的所有字加起来，再除以这本书的字符总数：C×H×W，即求整本书的“平均字”，求标准差时也是同理。</p>
<figure>
<img src="https://pic3.zhimg.com/v2-e7f1abe50ff1bf498023a39e99be3aa2_r.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>与BN不同的是，LN对每一层的所有神经元进行归一化，与BN不同的是：</p>
<p>LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；</p>
<p>BN中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。</p>
<p>LN不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。</p>
<p>一般情况，LN常常用于RNN网络！</p>
<h4 id="总结">总结</h4>
<ul>
<li><p>Batch Normalization 批规范化</p>
<ul>
<li><p>Feature-Map：<span class="math inline">\(x\in
R^{N*C*H*W}\)</span>，有N个样本，样本是C通道的，高为H，宽为W</p></li>
<li><p>对其求均值和方差时，将在 N、H、W上操作，而保留通道 C
的维度。具体来说，就是把第1个样本的第1个通道，加上第2个样本第1个通道
...... 加上第 N 个样本第1个通道，求平均，得到通道 1 的均值（注意是除以
N×H×W 而不是单纯除以 N，最后得到的是一个代表这个 batch
第1个通道平均值的数字，而不是一个 H×W 的矩阵）。求通道 1
的方差也是同理。对所有通道都施加一遍这个操作，就得到了所有通道的均值和方差。</p>
<ul>
<li><span class="math inline">\(\mu_c(x)=\frac{1}{NHW}\sum_{n=1}^{N}\sum_{h=1}^{H}\sum_{w=1}^Wx_{nchw}\)</span></li>
<li><span class="math inline">\(\sigma_c(x)=\sqrt{\frac{1}{NHW}\sum_n\sum_h\sum_{w}(x_{nchw}-\mu_c(x))^2+ε}\)</span></li>
<li>接下来要把数据进行规范化</li>
<li><span class="math inline">\(\hat{x_i}=\frac{x_i-\mu_c(x_i)}{\sqrt{\sigma_c(x)^2+\epsilon}}\)</span></li>
<li>可以加上扩展和平移参数</li>
<li><span class="math inline">\(y_i=\lambda\hat{x_i}+\beta\)</span></li>
</ul></li>
<li><p><strong>类比为一摞书，这摞书总共有 N 本，每本有 C 页，每页有 H
行，每行 W 个字符。BN
求均值时，相当于把这些书按页码一一对应地加起来（例如第1本书第36页，第2本书第36页......），再除以每个页码下的字符总数：N×H×W，因此可以把
BN
看成求“平均书”的操作（注意这个“平均书”每页只有一个字），求标准差时也是同理。</strong></p></li>
<li><p>一般来说，BN层要放在全连接层或者卷积层后面和非线性映射函数的前面</p></li>
<li><p>pytorch实现</p>
<ul>
<li><p>```python torch.nn.BatchNorm1d(num_features, eps=1e-05,
momentum=0.1, affine=True, track_running_stats=True)
torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True,
track_running_stats=True) torch.nn.BatchNorm3d(num_features, eps=1e-05,
momentum=0.1, affine=True, track_running_stats=True)
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    - num_features：一般输入参数为batch_sizenum_features的height*width，即为其中特征的数量，即为输入BN层的通道数；</span><br><span class="line"></span><br><span class="line">    - eps：分母中添加的一个值，目的是为了计算的稳定性，默认为：1e-5,避免分母为0；</span><br><span class="line"></span><br><span class="line">    - momentum：一个用于运行过程中均值和方差的一个估计参数（我的理解是一个稳定系数，类似于SGD中的momentum的系数）；</span><br><span class="line"></span><br><span class="line">    - affine：当设为<span class="literal">true</span>时，会给定可以学习的系数矩阵gamma和beta</span><br><span class="line"></span><br><span class="line">    - <span class="attribute">track_running_stats</span>=<span class="literal">True</span>表示跟踪整个训练过程中的batch的统计特性，得到方差和均值，而不只是仅仅依赖与当前输入的batch的统计特性。相反的，如果track_running_stats=False那么就只是计算当前输入的batch的统计特性中的均值和方差了。当在推理阶段的时候，如果track_running_stats=False，此时如果batch_size比较小，那么其统计特性就会和全局统计特性有着较大偏差，可能导致糟糕的效果。</span><br><span class="line"></span><br><span class="line">- Layer Normalization</span><br><span class="line"></span><br><span class="line">  - BN 的一个缺点是需要较大的 batchsize 才能合理估训练数据的均值和方差，这导致内存很可能不够用，同时它也很难应用在训练数据长度不同的 RNN 模型上。Layer Normalization (LN) 的一个优势是不需要批训练，在单条数据内部就能归一化。</span><br><span class="line"></span><br><span class="line">  - Feature-Map：<span class="variable">$x</span>\<span class="keyword">in</span> R^&#123;N<span class="number">*C</span>*H*W&#125;$</span><br><span class="line"></span><br><span class="line">  - LN保留了N维度，在每一条数据上进行求平均</span><br><span class="line"></span><br><span class="line">    - $\mu_n(x)=\frac&#123;1&#125;&#123;CHW&#125;\sum_&#123;<span class="attribute">c</span>=1&#125;^&#123;C&#125;\sum_&#123;<span class="attribute">h</span>=1&#125;^&#123;H&#125;\sum_&#123;<span class="attribute">w</span>=1&#125;^Wx_&#123;nchw&#125;$</span><br><span class="line">    - $\sigma_n(x)=\sqrt&#123;\frac&#123;1&#125;&#123;CHW&#125;\sum_c\sum_h\sum_&#123;w&#125;(x_&#123;nchw&#125;-\mu_n(x))^2+ε&#125;$</span><br><span class="line"></span><br><span class="line">  - 继续采用上一节的类比，把一个 batch 的 feature 类比为一摞书。**LN 求均值时，相当于把每一本书的所有字加起来，再除以这本书的字符总数：C×H×W，即求整本书的“平均字”，求标准差时也是同理**</span><br><span class="line"></span><br><span class="line">  - pytorch实现</span><br><span class="line"></span><br><span class="line">    - ```python</span><br><span class="line">      torch.nn.LayerNorm(normalized_shape, <span class="attribute">eps</span>=1e-05, <span class="attribute">elementwise_affine</span>=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>normalized_shape： 输入尺寸</p>
<figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">[∗×normalized_shape<span class="comment">[0]</span>×normalized_shape<span class="comment">[1]</span>×…×normalized_shape<span class="comment">[−1]</span>]</span></span><br></pre></td></tr></table></figure></li>
<li><p>eps：
为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</p></li>
<li><p>elementwise_affine：
布尔值，当设为true，给该层添加可学习的仿射变换参数。</p></li>
</ul></li>
</ul></li>
<li><p>Instance Normalization</p>
<ul>
<li><p>Instance Normalization (IN)
最初用于图像的风格迁移。作者发现，在生成模型中， feature map 的各个
channel 的均值和方差会影响到最终生成图像的风格，因此可以先把图像在
channel 层面归一化，然后再用目标风格图片对应 channel
的均值和标准差“去归一化”，以期获得目标图片的风格。IN
操作也在<strong>单个样本内部进行，不依赖 batch</strong>。</p></li>
<li><p>Feature-Map：<span class="math inline">\(x\in
R^{N*C*H*W}\)</span></p></li>
<li><p>IN保留了N、C维度，在每一条数据上进行求平均</p>
<ul>
<li><span class="math inline">\(\mu_{nc}(x)=\frac{1}{HW}\sum_{h=1}^{H}\sum_{w=1}^Wx_{nchw}\)</span></li>
<li><span class="math inline">\(\sigma_{nc}(x)=\sqrt{\frac{1}{HW}\sum_h\sum_{w}(x_{nchw}-\mu_{nc}(x))^2+ε}\)</span></li>
</ul></li>
<li><p><strong>IN
求均值时，相当于把一页书中所有字加起来，再除以该页的总字数：H×W，即求每页书的“平均字”，求标准差时也是同理。</strong></p></li>
<li><p>pytorch实现</p>
<ul>
<li><p>```python torch.nn.InstanceNorm1d(num_features, eps=1e-05,
momentum=0.1, affine=False, track_running_stats=False)
torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1,
affine=False, track_running_stats=False)
torch.nn.InstanceNorm3d(num_features, eps=1e-05, momentum=0.1,
affine=False, track_running_stats=False) <figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    - num_features： 来自期望输入的特征数，该期望输入的大小为’batch_size x num_features [x width]’</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    - eps： 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    - momentum： 动态均值和动态方差所使用的动量。默认为0.1。</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    - affine： 布尔值，当设为true，给该层添加可学习的仿射变换参数。</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    - track_running_stats：布尔值，当设为true，记录训练过程中的均值和方差；</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">- Group Normalization</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  - Group Normalization (GN) 适用于占用显存比较大的任务，例如图像分割。对这类任务，可能 batchsize 只能是个位数，再大显存就不够用了。而当 batchsize 是个位数时，BN 的表现很差，因为没办法通过几个样本的数据量，来近似总体的均值和标准差。GN 也是独立于 batch 的，它是 LN 和 IN 的折中。![Image](https://imgbed.momodel.cn/20201104114145.png)</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  - GN 计算均值和标准差时，把每一个样本 feature map 的 channel 分成 G 组，每组将有$\frac</span><span class="template-variable">&#123;C&#125;</span><span class="template-variable">&#123;G&#125;</span><span class="language-xml">$个channel，然后将这些 channel 中的元素求均值和标准差。各组 channel 用其对应的归一化参数独立地归一化。</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  - Feature-Map：$x\in R^</span><span class="template-variable">&#123;N*C*H*W&#125;</span><span class="language-xml">$</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    - $\mu_</span><span class="template-variable">&#123;ng&#125;</span><span class="language-xml">(x)=\frac</span><span class="template-variable">&#123;1&#125;</span><span class="template-variable">&#123;(C/G)HW&#125;</span><span class="language-xml">\sum_</span><span class="template-variable">&#123;gC/G&#125;</span><span class="language-xml">^</span><span class="template-variable">&#123;(g+1)C/G&#125;</span><span class="language-xml">\sum_</span><span class="template-variable">&#123;h=1&#125;</span><span class="language-xml">^</span><span class="template-variable">&#123;H&#125;</span><span class="language-xml">\sum_</span><span class="template-variable">&#123;w=1&#125;</span><span class="language-xml">^Wx_</span><span class="template-variable">&#123;nchw&#125;</span><span class="language-xml">$</span></span><br><span class="line"><span class="language-xml">    - $\sigma_</span><span class="template-variable">&#123;ng&#125;</span><span class="language-xml">(x)=\sqrt</span><span class="template-variable">&#123;\frac&#123;1&#125;</span><span class="template-variable">&#123;(C/G)HW&#125;</span><span class="language-xml">\sum_</span><span class="template-variable">&#123;gC/G&#125;</span><span class="language-xml">^</span><span class="template-variable">&#123;(g+1)C/G&#125;</span><span class="language-xml">\sum_h\sum_</span><span class="template-variable">&#123;w&#125;</span><span class="language-xml">(x_</span><span class="template-variable">&#123;nchw&#125;</span><span class="language-xml">-\mu_</span><span class="template-variable">&#123;ng&#125;</span><span class="language-xml">(x))^2+ε&#125;$</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  - **GN 相当于把一本 C 页的书平均分成 G 份，每份成为有 C/G 页的小册子，求每个小册子的“平均字”和字的“标准差”**</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">  - pytorch实现</span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    - ```python</span></span><br><span class="line"><span class="language-xml">      torch.nn.GroupNorm(num_groups, num_features, num_channels, eps=1e-05, affine=True)</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>num_groups：需要划分为的groups</li>
<li>num_features： 来自期望输入的特征数，该期望输入的大小为’batch_size x
num_features [x width]’</li>
<li>eps：
为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</li>
<li>momentum： 动态均值和动态方差所使用的动量。默认为0.1。</li>
<li>affine： 布尔值，当设为true，给该层添加可学习的仿射变换参数。</li>
</ul></li>
</ul></li>
<li><p>如果把<span class="math inline">\(x\in \mathbb{R}^{N \times C
\times H \times W}\)</span>类比为一摞书，这摞书总共有 N 本，每本有 C
页，每页有 H 行，每行 W 个字符。计算均值时，</p>
<ul>
<li>BN
相当于把这些书按页码一一对应地加起来（例如：第1本书第36页，加第2本书第36页......），再除以每个页码下的字符总数：N×H×W，因此可以把
BN 看成求“平均书”的操作（注意这个“平均书”每页只有一个字）</li>
<li>LN
相当于把每一本书的所有字加起来，再除以这本书的字符总数：C×H×W，即求整本书的“平均字”</li>
<li>IN
相当于把一页书中所有字加起来，再除以该页的总字数：H×W，即求每页书的“平均字”</li>
<li>GN 相当于把一本 C 页的书平均分成 G 份，每份成为有 <span class="math inline">\(\frac{C}{G}\)</span> 页的小册子，对这个 <span class="math inline">\(\frac{C}{G}\)</span>
页的小册子，求每个小册子的“平均字”</li>
</ul></li>
<li><p>计算方差同理。 此外，还需要注意它们的映射参数<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\beta\)</span> 的区别：对于 BN，IN，GN， 其<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\beta\)</span>都是维度等于通道数 C 的向量。而对于
LN，其<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\beta\)</span>都是维度等于 normalized_shape
的矩阵。最后，BN 和 IN 可以设置参数： <code>momentum</code> 和
<code>track_running_stats</code> 来获得在全局数据上更准确的 running mean
和 running std。而 LN 和 GN 只能计算当前 batch
内数据的真实均值和标准差。</p></li>
</ul></li>
</ul>
<h2 id="lecture-15">Lecture 15</h2>
<h3 id="hwn高速神经网络的研究动机">HWN高速神经网络的研究动机：</h3>
<p>深度学习网络梯度消失/爆炸问题（Vanishing/Exploding Gradient）</p>
<p>连训练集都无法拟合，当神经网络的深度达到一定程度，用反向传播带来梯度无法传播，参数无法更新。</p>
<h4 id="hwn网络架构">HWN网络架构：</h4>
<p><span class="math inline">\(y=H(x,W_H)T(x,W_T)+xC(x,W_C)\)</span></p>
<p>绕过这个非线性的激活函数，直接把x加权到y</p>
<p>传统网络：</p>
<p><span class="math inline">\(y=H(x,W_H)\)</span></p>
<p>残差的精髓：</p>
<ul>
<li>让网络更加适合模型，一些层如果起负面作用，那么直接使用残差绕开，更容易train。</li>
<li>T是传输参数，C是Carry参数，我们可以简化C为<span class="math inline">\(C(x,W_T)=1-T(x,W_T)\)</span></li>
<li><span class="math inline">\(y=\begin{cases}x,\ if\
T(x,W_T)=0\\H(x,W_H),\ if\ T(w,W_T)=1\end{cases}\)</span></li>
<li><span class="math inline">\(T(x)=\sigma(W_T \ ^Tx+b_T)\)</span></li>
</ul>
<h3 id="drn残差神经网络的研究动机">DRN残差神经网络的研究动机：</h3>
<p>解决网络退化问题，加层数，拟合能力和泛化能力都变差了，这是因为网络退化了。</p>
<p>可能网络只是记住了训练集，并没有学习。浅层神经网络比高层神经网络更好的训练效果。那么我们将低层的特征传到高层，那么效果不会比浅层的差。</p>
<p>Identify Mapping by Shortcut</p>
<p><span class="math inline">\(y=\mathcal{F}(x,\{W_i\})+x\)</span></p>
<h4 id="drn解决梯度消失问题">DRN解决梯度消失问题</h4>
<p>DRN和之前的HWN一样也可以解决梯度消失问题，因为有一个x加过来了。</p>
<p>数学证明：通过改变模型输出值的构成在梯度计算时融入加法，使得当个别梯度计算即使部分项过小，信息传播也不会消失，解决体度消失问题。</p>
<h3 id="densenet">DenseNet</h3>
<p>HWN和DRN通过恒等映射，缓解梯度消失和模型退化问题</p>
<p>Dense
Net采用的思路是"与其多次学习冗余特征，特征复用，每一层的输入来自前面所有层的输出"</p>
<p>多尺度映射：</p>
<ul>
<li><span class="math inline">\(x_l=H_l([x_0,x_1,...,x_{l-1}])\)</span></li>
</ul>
<p>比较：</p>
<ul>
<li>普通网络：<span class="math inline">\(x_l=H_l(x_{l-1})\)</span></li>
<li>残差网络：<span class="math inline">\(x_l=H_l(x_{l-1})+x_{l-1}\)</span></li>
</ul>
<h2 id="lecture-16">Lecture 16</h2>
<h3 id="berthttpszhuanlan.zhihu.comp98855346">[BERT][https://zhuanlan.zhihu.com/p/98855346]</h3>
<h4 id="预训练模型">预训练模型</h4>
<p>什么是预训练模型：预训练模型主要基于迁移学习，通过从多个原任务中获取重要的知识，再应用到目标任务中</p>
<p>BERT是transformer的一个encoder</p>
<ul>
<li>Pre-train：无监督学习
<ul>
<li>重构：使用表征重构词</li>
</ul></li>
<li>Fine-tuned：有监督训练任务层</li>
</ul>
<h5 id="pre-trainfine-tuned">Pre-Train+Fine-tuned：</h5>
<p>使用Model1-BERT作为黑箱，从token开始输入，输出我们只取token的输出(global)，作为Model2的输入。</p>
<p>如何得到BERT模型？</p>
<h3 id="pre-train">Pre-Train</h3>
<p>Bert中使用的技巧，Bert和Transformer的Encoder类似。</p>
<p>BERT：双向Transformer的Encoder，通过给定的预料生成每个词语对应的Embedding向量。</p>
<h4 id="bert的思想">BERT的思想</h4>
<p>BERT如此成功的一个原因之一是它是基于上下文(context-based)的嵌入模型，不像其他流行的嵌入模型，比如word2vec，是上下文无关的(context-free)。</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108165545654.png" alt="image-20221108165545654" style="zoom:80%;"></p>
<h3 id="bert的原理">BERT的原理</h3>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108165713849.png" alt="image-20221108165713849" style="zoom:80%;"></p>
<h3 id="bert输入">BERT输入</h3>
<ul>
<li>Token Embedding</li>
<li>Position Embedding</li>
<li>Segment Embedding：表示输入词是第几个句子的</li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108164859904.png" alt="image-20221108164859904" style="zoom:67%;"></li>
<li>我们增加一个新的标记，叫作<code>[CLS]</code>标记，到第一个句子前面</li>
<li>增加一个新的标记，叫作<code>[SEP]</code>标记，到每个句子的结尾</li>
<li>注意<code>[CLS]</code>标记只加在<strong>第一个句子前面</strong>，而<code>[SEP]</code>标记加到每个句子末尾。</li>
<li><code>[CLS]</code>标记用于分类任务，而<code>[SEP]</code>标记用于表示每个句子的结尾。</li>
</ul>
<h4 id="fine-tunning">Fine-Tunning</h4>
<p>对于Sequence-level的分类任务，BERT可以直接取第一个[CLS]token的final
hidden state <span class="math inline">\(C\in
R^H\)</span>，加一层权重<span class="math inline">\(W\in
R^{K*H}\)</span>，softmax预测<span class="math inline">\(P=softmax(CW^T)\)</span></p>
<h3 id="bert预训练">BERT预训练</h3>
<ul>
<li><p>屏蔽语言建模</p>
<ul>
<li><p>语言建模：训练模型给定一系列单词来预测下一个单词</p>
<ul>
<li><p>自回归语言建模</p>
<ul>
<li>前向预测(左到右)</li>
<li>反向预测(右到左)</li>
</ul>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108170244514.png" alt="image-20221108170244514" style="zoom:90%;"></p></li>
<li><p>自编码语言建模</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108170500572.png" alt="image-20221108170500572" style="zoom:80%;"></p></li>
</ul></li>
<li><p>BERT是一个<strong>自编码语言</strong>模型，对于给定的输入序列我们随机屏蔽15%的单词，训练模型去预测这些屏蔽的单词，我们的模型以两个方向读入序列然后尝试预测屏蔽的单词。</p></li>
<li><p>掩码序列构建：</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108170714983.png" alt="image-20221108170714983" style="zoom:80%;"></p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108170930438.png" alt="image-20221108170930438" style="zoom:80%;"></p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108171029857.png" alt="image-20221108171029857" style="zoom:80%;"></p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/384ac0f044d2f6403a0c178d9910fa27.png" alt="384ac0f044d2f6403a0c178d9910fa27">
<figcaption aria-hidden="true">384ac0f044d2f6403a0c178d9910fa27</figcaption>
</figure>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108171252241.png" alt="image-20221108171252241" style="zoom:80%;"></p></li>
</ul></li>
<li><p>下一句预测NSP</p>
<p>下一句预测(next sentence
prediction,NSP)是另一个用于训练BERT模型的任务。NSP是二分类任务，在此任务中，我们输入两个句子两个BERT，然后BERT需要判断第二个句子是否为第一个句子的下一句。</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108171819606.png" alt="image-20221108171819606" style="zoom:80%;"></p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108171940646.png" alt="image-20221108171940646">
<figcaption aria-hidden="true">image-20221108171940646</figcaption>
</figure>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/cf58ba232b27f6e16f835ceea1af4e4b.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221108172235316.png" alt="image-20221108172235316">
<figcaption aria-hidden="true">image-20221108172235316</figcaption>
</figure>
<figure>
<img src="https://img-blog.csdnimg.cn/img_convert/d0248bf1912649ca1dae30516bdc4435.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure></li>
</ul>
<p>【引用】[原文][https://blog.csdn.net/yjw123456/article/details/120211601]</p>
<h2 id="lecture-17">Lecture 17</h2>
<h3 id="预训练模型ⅱ">预训练模型Ⅱ</h3>
<h3 id="clip的研究动机">CLIP的研究动机</h3>
<ul>
<li>CLIP解决传统监督与训练模型的<strong>高标注</strong>和<strong>泛化弱</strong>的问题。
<ul>
<li>高标注：需要人给数据打标签。</li>
<li>泛化弱：不仅要求在训练集上拟合，在测试数据集也要好。</li>
</ul></li>
<li>互联网上存在大量图像文本对，且样本本身差异性大，不仅解决数据高标注，且容易获得泛化能力强模型。</li>
</ul>
<h3 id="clip模型训练">CLIP模型训练</h3>
<ul>
<li>load到GPU只能是一个batch的图片和文本对，比如我们load了n个图像文本对</li>
<li><span class="math inline">\(I_i·T_i\)</span>进行关联，大部分的图片和文本是相关联的
<ul>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114190612317.png" alt="image-20221114190612317" style="zoom:80%;"></li>
<li>我们获得了<strong>对角线</strong>的<strong>正样本</strong>。<strong>不在对角线</strong>的就是<strong>负样本</strong>。</li>
</ul></li>
<li>优化目标：<span class="math inline">\(min(\sum_{i=1}^N\sum_{j=1}^N(I_i·T_j)_{i\neq
j}-\sum_{i=1}^N (I_i·T_i))\)</span>
<ul>
<li>即最大化对角线的值，最小化其他值</li>
</ul></li>
</ul>
<h3 id="clip模型分类">CLIP模型分类</h3>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114191319253.png" alt="image-20221114191319253" style="zoom:67%;"></p>
<p>输出的是一个cosine
similarity，输入中的文本的黑体部分不仅仅是输入也是分类的一个类。我们可以把CLIP用作分类。将CLIP模型迁移到分类</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114191750562.png" alt="image-20221114191750562" style="zoom:80%;"></p>
<p>模板模式：输入文本是一个模板，输入的object可以是标签，将待分类的标签转化为句子，进入CLIP，与图片进行比较计算，从标签中获得相似度最大的标签，就是分类。</p>
<h3 id="clip模型分类例子">CLIP模型分类例子</h3>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114193348159.png" alt="image-20221114193348159">
<figcaption aria-hidden="true">image-20221114193348159</figcaption>
</figure>
<h3 id="align的研究动机">ALIGN的研究动机</h3>
<p>示例图像-文本对从ALIGN的训练数据集中随机抽样。一个明显有噪声的文本注释用斜体标记。</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114193618045.png" alt="image-20221114193618045" style="zoom:67%;"></p>
<ul>
<li>多模态检索
<ul>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114193657287.png" alt="image-20221114193657287">
<figcaption aria-hidden="true">image-20221114193657287</figcaption>
</figure></li>
</ul></li>
<li>细粒度检索
<ul>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114193711751.png" alt="image-20221114193711751">
<figcaption aria-hidden="true">image-20221114193711751</figcaption>
</figure></li>
</ul></li>
</ul>
<h3 id="filip的研究动机">FILIP的研究动机</h3>
<p>CLIP是基于个模态的全局特征间的相似度进行建模的。但是文本和句子距离近是因为有局部特征相似度很高，而不是句子和图片很近。即文本和句子很相似，是因为有局部的特征高度匹配。</p>
<h3 id="filip模型">FILIP模型</h3>
<p>输入：使用transformer得到图像的patch编码和文本的编码</p>
<ul>
<li>全局特征在第0位，但是我们不用，我们用剩余的n位</li>
<li>从数据相似度到了token的相似度。</li>
<li>一个句子和一个图片是有关联的：某个patch和某个单词匹配</li>
</ul>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114194708834.png" alt="image-20221114194708834" style="zoom:80%;"></p>
<p>获得：</p>
<ul>
<li>每一对文本图像对获得一个Token-wise
Similarity矩阵，这个矩阵可以获得两个矩阵</li>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114195307126.png" alt="image-20221114195307126">
<figcaption aria-hidden="true">image-20221114195307126</figcaption>
</figure></li>
<li>19.51</li>
</ul>
<h3 id="数据增强httpswww.zhihu.comquestion319291048">[数据增强][https://www.zhihu.com/question/319291048]</h3>
<p>数据增强也叫数据扩增，意思是在不实质性的增加数据的情况下，让有限的数据产生等价于更多数据的价值。</p>
<p>对数据进行扰动获得新的数据正例。</p>
<h4 id="declip的研究动机">DECLIP的研究动机</h4>
<p>CLIP使用了4亿图像文本对，是否存在较少数据下依旧可以取得不错效果的方法。</p>
<p>能不能使用小的数据集？拉开数据集里面样本的差异性。</p>
<h4 id="最近邻监督nns">最近邻监督NNS</h4>
<p>将最近邻的文本和图片进行重新配对，获得新的文本图片对</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114201548564.png" alt="image-20221114201548564">
<figcaption aria-hidden="true">image-20221114201548564</figcaption>
</figure>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114201646380.png" alt="image-20221114201646380" style="zoom:80%;"></p>
<h4 id="自监督学习">自监督学习</h4>
<p>依靠自己创造新的文本图片对，创造正例</p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221114201612335.png" alt="image-20221114201612335" style="zoom:80%;"></p>
<h2 id="lecture-18">Lecture 18</h2>
<h3 id="知识蒸馏distilling-knowledge">知识蒸馏Distilling Knowledge</h3>
<p>知识蒸馏（knowledge
distillation）是模型压缩的一种常用的方法，不同于模型压缩中的剪枝和量化，知识蒸馏是通过构建一个轻量化的小模型，利用性能更好的大模型的监督信息，来训练这个小模型，以期达到更好的性能和精度。最早是由Hinton在2015年首次提出并应用在分类任务上面，这个大模型我们称之为teacher（教师模型），小模型我们称之为Student（学生模型）。来自Teacher模型输出的监督信息称之为knowledge(知识)，而student学习迁移来自teacher的监督信息的过程称之为Distillation(蒸馏)。</p>
<h3 id="模型背景">模型背景</h3>
<p>训练模型过程中，需要复杂模型和计算资源，从大量与冗余数据中提取信息，因此训练好的模型存在<strong>推理速度慢</strong>、<strong>推理所需资源高</strong>的问题。</p>
<p>在模型部署中，对模型推理延迟和计算资源有严格限制。</p>
<p>压缩模型成为机器学习领域的一个问题：在保证性能的前提下减少模型的参数量。</p>
<ul>
<li><strong>一个模型的参数量基本决定了其所能捕获到的数据内蕴含的“知识”量</strong></li>
<li>模型参数量与捕获“知识”量之间为边际收益递减的增长。</li>
<li>相同模型架构和参数量，训练方法不同，捕获的知识量也不同</li>
</ul>
<h3 id="基本框架">基本框架</h3>
<p><strong>模型是“teacher-student”模型。</strong></p>
<p>Teacher模型：原始模型训练，模型复杂，由多个分别训练的模型集成，输出知识。模型参数数量大于学生模型参数数量，可能有多个模型</p>
<p>Student模型：精炼模型训练，参数量少，模型简单的单模型，学习知识</p>
<ul>
<li>传统的学习是直接从数据进行学习，通过数据对，不断减小loss，学习到X到Y的一个映射。</li>
<li>知识蒸馏是从教师模型进行学习，教师模型输出知识，学生从知识中学习。</li>
<li>“Teacher”和“Student”模型满足：对于输入X, 其都能输出Y,
Y经过Softmax映射后输出对应类别的概率值</li>
<li>学习能力强的“teacher”模型将学习的知识迁移给学习能力弱的“student”模型，增强其泛化能力</li>
<li>“Teacher”模型扮演导师角色，“student”部署上线</li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221115162956590.png" alt="image-20221115162956590" style="zoom:80%;"></li>
</ul>
<p>教师模型是已经训练好的，是在云端已经训练好了。并不是让教师学习知识。数据分别进入学生和教师，学生给出答案，校对答案和方法。教师只给一个答案给学生，和直接学习没区别。</p>
<h3 id="目标蒸馏">目标蒸馏</h3>
<ul>
<li>分类问题中模型最后有一个softmax层，其输出值对应相应类别的概率值。</li>
<li>传统训练方法通过定义一个损失函数，目标使神经网络预测值
尽可能接近真实值(Hard-target)。</li>
<li>与传统训练方法不同，知识蒸馏使用“Teacher”模型的类别概
率作为Soft-target来训练“Student”</li>
<li>教师给出的是一个答案的概率（Soft-target）而不是直接一个答案（Hard-target）</li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221115165812817.png" alt="image-20221115165812817" style="zoom:67%;"></li>
</ul>
<h4 id="soft-target训练优势">Soft-target训练优势</h4>
<ul>
<li>除了正例，负标签也带有“Teacher”模型归纳推理的大量信息
（某负标签对应概率大于其它负标签，代表“Teacher”模型推
理时认为该样本与负标签有一定相似性）。</li>
<li>知识蒸馏使得每个样本给“Student”模型带来的信息大于Hard-target的训练方式。</li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221115170327838.png" alt="image-20221115170327838" style="zoom:80%;"></li>
</ul>
<h4 id="dark-knowledge暗知识">Dark Knowledge暗知识</h4>
<p>暗知识：隐藏在深度网络下的网络结构，节点之间的连接权重，以及网络的输出这些看得到的数据下的知识，如上述负标签信息（类别之间关联性的先验信息）。</p>
<p>Training data→big ensemble of learned models→small production
model</p>
<p>本质是不仅仅传授明信息，也传授暗知识。</p>
<h3 id="知识如何传授">知识如何传授？</h3>
<p><span class="math inline">\(q_i=\frac{exp(z_i/T)}{\sum_iexp(z_j/T)}\)</span>，zi为标签i输出的概率，教师模型输出分布由T控制</p>
<p>这是一个softmax函数，我们加了一个T，这个T用来控制“温度”。</p>
<p>T越大越陡峭，T越接近0，越平缓。</p>
<h4 id="组合目标优化">组合目标优化</h4>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221115172356672.png" alt="image-20221115172356672" style="zoom:80%;"></p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221115172616486.png" alt="image-20221115172616486">
<figcaption aria-hidden="true">image-20221115172616486</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221115173441665.png" alt="image-20221115173441665">
<figcaption aria-hidden="true">image-20221115173441665</figcaption>
</figure>
<h2 id="lecture-19">Lecture 19</h2>
<h3 id="decision-tree决策树">Decision Tree决策树</h3>
<p>一种通过实现分而治之策略来表示数据的分层数据结构</p>
<ul>
<li>给定一组例子，学习代表它的决策树。</li>
<li>使用这种表示法对新示例进行分类</li>
</ul>
<p>可以作为一种非参数分类和回归方法。</p>
<p>【Example】</p>
<ul>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221121190142816.png" alt="image-20221121190142816" style="zoom:80%;"></li>
<li>决策树是许多的分类器，表示为特征向量</li>
<li>节点都是tests for特征值</li>
<li>每一个枝条是一种特征值</li>
<li>叶节点是一种类别</li>
<li>能将实例分类为多个不相关的类别</li>
<li>输出是一个离散的类别。实值输出是可能的(回归树)</li>
<li>有处理大量数据的有效算法(但没有太多的特征)</li>
<li>有处理噪声数据(分类噪声和属性噪声)和处理缺失属性值的方法。</li>
</ul>
<h3 id="basic-decision-tree-learning-algorithm">Basic Decision Tree
Learning Algorithm</h3>
<ul>
<li>Data是Batch来的</li>
<li>递归构建一个决策树，自顶而下</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">DT(Examples, Attributes)</span><br><span class="line">	If all Examples have same label:</span><br><span class="line">		return a leaf node with Label</span><br><span class="line">	Else</span><br><span class="line">		If Attributes is empty:</span><br><span class="line">			return a leaf with majority Label</span><br><span class="line">		Else</span><br><span class="line">			Pick an attribute A as root</span><br><span class="line">			For each value v of A</span><br><span class="line">				Let Examples(v) be all the examples for which A=v</span><br><span class="line">				Add a branch out of the root for the test A=v</span><br><span class="line">					If Examples(v) is empty</span><br><span class="line">						create a leaf node labeled with the majority label in Examples</span><br><span class="line">					Else</span><br><span class="line">						recursively create subtree by calling DT(Examples(v), Attribute-&#123;A&#125;)</span><br></pre></td></tr></table></figure>
<p>我们希望将示例划分为一个标签中相对纯粹的集合的属性；这样我们就更接近叶节点了。</p>
<ul>
<li>决策树算法中根节点的分类权重最高，向下依次递减；选取分类能力最强的特征作为根节点可以极大的提升分类效率。通过信息增益量化每个特征的分类能力，该特征信息增益越大，分类能力越强，即：计算数据集中各特征点的信息增益，信息增益最大的特征点作为决策树根节点，依次向下递归。</li>
</ul>
<p>最流行的启发式是基于信息增益的启发式，起源于Quinlan的ID3系统。</p>
<h4 id="entropy">Entropy</h4>
<p>数据集总体的熵的计算</p>
<p><span class="math inline">\(Entropy(S)=-P_+logP_--P_-logP_+\)</span></p>
<ul>
<li><span class="math inline">\(P_+\)</span>是集合中正例的百分比</li>
<li><span class="math inline">\(P_-\)</span>是集合中负例的百分比</li>
</ul>
<p><span class="math inline">\(Entropy(S)=-\sum_{i=1}^cP_ilogP_i\)</span></p>
<p><span class="math inline">\(H(D)=-\sum_k^K\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|}\)</span></p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221121194724923.png" alt="image-20221121194724923" style="zoom:77%;"></p>
<h4 id="information-gain">Information Gain</h4>
<p><span class="math inline">\(Gain(S,a)=Entropy(S)-\sum_{v\in
value(a)}\frac{|S_v|}{|S|}Entropy(S_v)\)</span></p>
<p>特征A对数据集D的熵：</p>
<p><span class="math inline">\(H(D|A)=\sum_{v \in
value(a)}\frac{|S_v|}{|S|}Entropy(S_v)=\sum_{v \in
value(a)}\frac{|S_v|}{|S|}\sum_{k=1}^K\frac{|D_{ik}|}{|D_i|}log_2\frac{|D_{ik}|}{|D_i|}\)</span></p>
<p><span class="math inline">\(g(D,A)=H(D)-H(D|A)\)</span></p>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221121194747064.png" alt="image-20221121194747064" style="zoom:80%;"></p>
<h4 id="总结-1">总结</h4>
<p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221121195359980.png" alt="image-20221121195359980" style="zoom:80%;"></p>
<h3 id="avoid-overfitting">Avoid Overfitting</h3>
<p>对于决策树：</p>
<p>避免Overfitting可以通过：</p>
<ul>
<li>Prepruning：当确定没有足够的数据来做出可靠的选择时，在构建过程中的某个点停止种植树</li>
<li>Postpruning：生长完整的树，然后删除似乎没有足够证据的节点。</li>
</ul>
<h3 id="classification-and-regression-trees">Classification and
Regression Trees</h3>
<p>ID3存在的问题：</p>
<ul>
<li>只服务于分类</li>
<li>特征必须要离散</li>
</ul>
<p>假设我们有一个回归问题</p>
<ul>
<li>训练数据<span class="math inline">\(\{x_1,y_1\},...,\{x_n,y_n\}\)</span></li>
<li>一个简单的分类就是划分区域：
<ul>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221121200552186.png" alt="image-20221121200552186">
<figcaption aria-hidden="true">image-20221121200552186</figcaption>
</figure></li>
</ul></li>
<li>在每个区域内，都有一个单独的模型来预测目标变量。例如，在回归中，我们可以简单地预测每个区域的常数，或者在分类中，我们可以将每个区域分配给特定的类。
<ul>
<li><span class="math inline">\(f(x)=\sum_{\tau=1}^Mc_{\tau}I(x\in
R_{\tau})\)</span></li>
</ul></li>
<li>Q 1：
<ul>
<li>什么值我们应该给一个区域赋？</li>
<li>我们想要最小均方差
<ul>
<li><span class="math inline">\(c_{\tau}=\frac{1}{N_{\tau}}\sum_{x_i\in
R_\tau}y_i\)</span></li>
<li><span class="math inline">\(Q_\tau(T)=\sum_{x_i\in
R_{\tau}}(y_i-c_\tau)^2\)</span></li>
</ul></li>
</ul></li>
<li>Q 2：
<ul>
<li>如何建立一棵树？</li>
<li>即使对于树中固定数量的节点，确定最优结构(包括为每次分裂选择输入变量以及相应的阈值)以最小化平方和误差的问题通常是不可计算的，因为可能的解决方案数量很多。</li>
<li>我们使用贪心策略。
<ul>
<li>假设我们对特征<span class="math inline">\(x^{(j)}\)</span>在值s处分为两个区域
<ul>
<li><span class="math inline">\(R_1(j,s)=\{x|x^{(j)}\leq
s\}\)</span></li>
<li><span class="math inline">\(R_1(j,s)=\{x|x^{(j)}\gt
s\}\)</span></li>
</ul></li>
<li>我们选取出使得下式最下的j和s
<ul>
<li><span class="math inline">\(min_{j,s}[min_{c_1}\sum_{x_i\in
R_1(j,s)}(y_i-c_1)^2+min_{c_2}\sum_{x_i\in
R_2(j,s)}(y_i-c_2)^2]\)</span></li>
<li>这就是最佳的(j,s)对</li>
</ul></li>
<li>不短迭代，直到停止</li>
</ul></li>
<li>何时停止？
<ul>
<li>假设我们最后有M个区域我们的树表示为
<ul>
<li><span class="math inline">\(f(x)=\sum_{\tau=1}^Mc_{\tau}I(x\in
R_\tau)\)</span></li>
</ul></li>
<li>可能的方案：残余误差降低到某个阈值以下</li>
<li>然而，它经常被经验发现
<ul>
<li>所有可用的分割都不能显著减少误差</li>
<li>经过多次拆分后，发现误差大大减少了。</li>
</ul></li>
<li>通常的做法是生长一棵大的树，使用基于与叶节点相关的数据点数量的停止准则，然后对生成的树进行修剪。</li>
</ul></li>
<li>如何剪枝？
<ul>
<li>修剪是基于一个标准，平衡残余误差与模型复杂性的衡量。
<ul>
<li><span class="math inline">\(f(x)=\sum_{\tau=1}^Mc_{\tau}I(x\in
R_\tau)\)</span></li>
<li><span class="math inline">\(c_{\tau}=\frac{1}{N_{\tau}}\sum_{x_i\in
R_\tau}y_i\)</span></li>
<li><span class="math inline">\(Q_\tau(T)=\sum_{x_i\in
R_{\tau}}(y_i-c_\tau)^2\)</span></li>
</ul></li>
<li>剪枝准则：
<ul>
<li><span class="math inline">\(C(T)=\sum_{T=1}^{|T|}Q_\tau(T)+\lambda
|T|\)</span></li>
</ul></li>
<li>正则化参数<span class="math inline">\(\lambda\)</span>决定了整体残差平方和误差与以叶节点数目|T|衡量的模型复杂度之间的权衡，其值通过交叉验证选择。</li>
</ul></li>
</ul></li>
<li>CART做Classification
<ul>
<li>对于分类问题，我们只使用熵或Gini index，而不是残差平方和：
<ul>
<li><span class="math inline">\(Q_\tau(T)=-\sum_{k=1}^Kp_{\tau k}log\
p_{\tau k}\)</span></li>
<li><span class="math inline">\(Q_\tau(T)=\sum_{k=1}^Kp_{\tau
k}(1-p_{\tau k})\)</span></li>
</ul></li>
<li>当Ptk = 0和Ptk = 1时，它们都消失，并且在Ptk =
0.5时有最大值。它们鼓励形成一个区域，其中高比例的数据点被分配给一个类别。</li>
</ul></li>
</ul>
<h2 id="lecture-20">Lecture 20</h2>
<h3 id="组合模型-集成方法httpszhuanlan.zhihu.comp355416998">[组合模型-集成方法][https://zhuanlan.zhihu.com/p/355416998]</h3>
<h3 id="bagging">Bagging</h3>
<p>给定包含m
个样本的数据集，我们先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m次随机采样操作，我们得到含m
个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的则从未出现，初始训练集中约有63.2%的样本出现在来样集中.
照这样，我们可采样出T 个含m
个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合.这就是Bagging
的基本流程.在对预测输出进行结合时， Bagging
通常对分类任务使用简单投票法，对回归任务使用简单平均法.若分类预测时出现两个类收到同样票数的情形，则最简单的做法是随机选择一个，也可进一步考察学习器投票的置信度来确定最终胜者.</p>
<h4 id="the-bagging-algorithm">The Bagging Algorithm</h4>
<p>Bagging这个名字来自Bootstrap Aggregating 的缩写[Breiman,
1996d]暗示了的两个关键成分Bagging分为bootstrap和aggregation两种。</p>
<ul>
<li>Bootstrap
Sampling：从D中统一重新抽样N个样本，并进行替换，也可以使用任意N'来代替原来的N</li>
<li>Aggregating：采用最流行的策略聚合基础学习者的输出，即投票分类，平均回归。</li>
</ul>
<h4 id="为什么bagging-works">为什么Bagging Works</h4>
<ul>
<li>当基础学习器不稳定(方差大)时，Bagging带来的性能提升较大。
<ul>
<li>基础学习者应该意识到细微的变化，有时允许过拟合。</li>
</ul></li>
<li>因此，Friedman和Hall[2007]得出结论，Bagging可以减少高阶分量的方差，但不影响线性分量。这意味着Bagging更适用于高度非线性的学习者。</li>
</ul>
<h3 id="基本思想">基本思想</h3>
<ol type="1">
<li>给定一个弱学习算法,和一个训练集;</li>
<li>单个弱学习算法准确率不高;</li>
<li>将该学习算法使用多次,得出预测函数序列,进行投票;</li>
<li>最后结果准确率将得到提高.</li>
</ol>
<p>大致过程如下：</p>
<ol type="1">
<li>对于给定的训练样本S,每轮从训练样本S中采用有放回抽样(Booststraping)的方式抽取M个训练样本,共进行n轮，得到了n个样本集合，需要注意的是这里的n个训练集之间是相互独立的。</li>
<li>在获取了样本集合之后，每次使用一个样本集合得到一个预测模型，对于n个样本集合来说，我们总共可以得到n个预测模型。</li>
<li>如果我们需要解决的是分类问题，那么我们可以对前面得到的n个模型采用投票的方式得到分类的结果，对于回归问题来说，我们可以采用计算模型均值的方法来作为最终预测的结果。</li>
</ol>
<figure>
<img src="https://pic2.zhimg.com/80/v2-3fc8cc39375fb250a53bf3cb88b91fe1_720w.webp" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="random-forset">Random Forset</h3>
<p>使用决策树作为基模型</p>
<p>选择一个特征子集<span class="math inline">\(f\subseteq F\)</span></p>
<ul>
<li>建立决策树：我们选择在f中最优的特征，<span class="math inline">\(size(f)=\sqrt k\)</span>在分类中，k/3在回归中</li>
<li>每一棵树都不如DT，但当它们结合在一起时工作得更好。</li>
</ul>
<p>构建随机森林，以下步骤进行重复</p>
<ol type="1">
<li>从原始训练中选择一个新的引导样本集</li>
<li>建立树</li>
<li>在每个内部节点上，从所有特征中随机选择K个特征，然后，在ONLY
K个特征中确定最佳分割。</li>
<li>不要修剪</li>
<li>直到测试误差从未减少(这里指RF中的验证误差)</li>
</ol>
<p>使得Learners更加Diverse</p>
<ul>
<li>随机森林需要基本的学习者意识到变化很小，有时允许过拟合。</li>
<li>每次，基础学习者不是从所有数据中学习，而是从随机引导采样数据中学习。</li>
<li>基本的学习者不会使用所有的特征，但随机选择一些特征。</li>
</ul>
<h4 id="how-to-generate-m-models">How to Generate M Models</h4>
<ul>
<li>Bagging
<ul>
<li>使用抽样技术生成不同的训练集</li>
<li>每个训练集都可以生成一个模型</li>
<li><strong>平行</strong>集成法</li>
</ul></li>
<li>Boosting
<ul>
<li>修改不同训练样本的<strong>权重</strong></li>
<li>在修改后的训练集上生成模型</li>
<li><strong>顺序</strong>集成法</li>
</ul></li>
</ul>
<h3 id="boosting">Boosting</h3>
<p>训练后的模型，对训练错误的进行权重增大，接着训练，不断重复。</p>
<p>为了提出一个算法，我们需要回答两个基本问题</p>
<ul>
<li>问题1：如何改变样本的权重，使分类错误的样本得到更多的权重</li>
<li>问题2：最后阶段如何结合基础学习者</li>
</ul>
<h3 id="adaboost">AdaBoost</h3>
<ul>
<li>初始化每一个data的权重<span class="math inline">\(w_{n}^{(1)}=1/N\)</span></li>
<li>对于任意的m，分类器<span class="math inline">\(y^{(m)}(x)\)</span>由最小化以下式子而来
<ul>
<li><span class="math inline">\(J_m=\sum_{n=1}^Nw_n^{(m)}I(y^{(m)}(x_n)\neq
t_n)\)</span></li>
</ul></li>
<li>评估Errorrate
<ul>
<li><span class="math inline">\(\epsilon_m=\frac{\sum_{n=1}^Nw_n^{(m)}I(y^{(m)}(x_n)\neq
t_n)}{\sum_{n=1}^N w_n^{(m)}}\)</span></li>
<li><span class="math inline">\(\alpha_m=ln\frac{1-\epsilon_m}{\epsilon_m}\)</span></li>
</ul></li>
<li>数据加权系数
<ul>
<li><span class="math inline">\(w_n^{(m+1)}=w_n^{(m)}exp\{\alpha_mI(y^{(m)}(x_n)\neq
t_n)\}\)</span></li>
<li>即分对了不变，分错了更新<span class="math inline">\(w_n^{(m+1)}=w_n^{(m)}\frac{1-\epsilon_m}{\epsilon_m}\)</span></li>
<li>在指数loss时，更新方式为<span class="math inline">\(w_n^{(m+1)}=w_n^{(m)}exp\{-\frac{1}{2}t_n\alpha_my_m(x_n)\}\)</span></li>
</ul></li>
<li>使用最后的模型进行预测
<ul>
<li>怎么conbine模型？<span class="math inline">\(\alpha_m\)</span>就是模型m的正确率，正确率高的模型权重大，因此我们进行加权。</li>
<li><span class="math inline">\(Y_M(x)=sign(\sum_{m=1}^M\alpha_my^{(m)}(x))\)</span></li>
</ul></li>
</ul>
<h4 id="insights-behing-adaboost">Insights Behing Adaboost</h4>
<p>在每一轮中，算法尝试获得不同的基数学习器，从而实现模型的多样性。学习n个分散的模型，消除过拟合，我们需要diverse的模型，不能是相似的。</p>
<p>Adaboost可以看作是指数误差下加性模型的顺序优化过程。</p>
<h4 id="reweight机制">Reweight机制</h4>
<h4 id="指数的error-function">指数的error function</h4>
<p><span class="math inline">\(E=\sum_{i=1}^Nexp\{-t_nf_m(x_n)\}\)</span></p>
<p>其中<span class="math inline">\(f_m(x)=\frac{1}{2}\sum_{l=1}^m\alpha_l y_l
(x)\)</span></p>
<p>y是预测的值，t是真实值，都是{1,-1}中的。</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221122173240146.png" alt="image-20221122173240146">
<figcaption aria-hidden="true">image-20221122173240146</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221122173642007.png" alt="image-20221122173642007">
<figcaption aria-hidden="true">image-20221122173642007</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221122174335827.png" alt="image-20221122174335827">
<figcaption aria-hidden="true">image-20221122174335827</figcaption>
</figure>
<h3 id="gradient-boosting-decision-tree">Gradient Boosting Decision
Tree</h3>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221122174451437.png" alt="image-20221122174451437">
<figcaption aria-hidden="true">image-20221122174451437</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221122174501650.png" alt="image-20221122174501650">
<figcaption aria-hidden="true">image-20221122174501650</figcaption>
</figure>
<h2 id="lecture-21">Lecture 21</h2>
<h3 id="k-nearest-neighbor-classifier">K Nearest Neighbor
Classifier</h3>
<p>KNN：</p>
<p>基本的思想：</p>
<ul>
<li>如果它像鸭子一样走路，像鸭子一样嘎嘎叫，那它很可能就是一只鸭子</li>
<li>依然要训练模型，我们要找k个点和它比较相近，我们的模型是这个<strong>距离函数</strong></li>
</ul>
<p>要求三件事：</p>
<ol type="1">
<li>存储记录的集合</li>
<li><strong>距离度量</strong>来计算记录之间的距离，学习的就是这个</li>
<li>k的值指的是要检索的最近邻居的数量</li>
</ol>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221128191116753.png" alt="image-20221128191116753">
<figcaption aria-hidden="true">image-20221128191116753</figcaption>
</figure>
<p>unknow数据点并没有Label，我们要根据学习到的距离函数，检索k个最近的邻居，来估计这个标签</p>
<h4 id="knn的参数">KNN的参数</h4>
<p>对于KNN，也有一个决策边界，有N/k个参数。</p>
<h4 id="metric-learning">Metric Learning</h4>
<p>如何计算距离？<span class="math inline">\(ρ(x,y)=\sqrt{(x_1-y_1)^2+...+(x_d-y_d)^2}=\sqrt{(x-y)^T(x-y)}\)</span></p>
<p>但是这样子有一个问题：不是所有的特征都是一样重要的。我们可以加权。</p>
<p><span class="math inline">\(ρ(x,y)=\sqrt{w_1(x_1-y_1)^2+...+w_d(x_d-y_d)^2}\\=\sqrt{(x-y)^T[w^Tw](x-y)}\\=\sqrt{(x-y)^TM(x-y)}\)</span></p>
<p>我们不知道这个M，我们需要学习这个M</p>
<p>对于<span class="math inline">\(x和x&#39;\)</span>不是在同一个集合，我们希望他们的距离尽可能大；反之，在同一个集合，我们就希望距离尽可能小。</p>
<p><span class="math inline">\(L(M)=\sum_{(x,x&#39;)\in
S}ρ^2_M(x_i,x_j)-\lambda\ log\sum_{D}ρ_M(x_i,x_j)\)</span></p>
<p>优化：</p>
<ul>
<li><span class="math inline">\(min_{M\in R^{d\times d},M\geq
0}\sum_{(x_i,x_j)\in S}ρ^2_M(x_i,x_j)\)</span></li>
<li><span class="math inline">\(s.t.\ \sum_{(x_i,x_j)\in
D}ρ_M(x_i,x_j)\geq 1\)</span></li>
</ul>
<p><span class="math inline">\(min_{M\geq 0}F(M)=\sum_{(x,x&#39;)\in
S}ρ^2_M(x_i,x_j)-log(\sum_{(x_i,x_j)\in D}ρ_M(x_i,x_j))\)</span></p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221128193058894.png" alt="image-20221128193058894">
<figcaption aria-hidden="true">image-20221128193058894</figcaption>
</figure>
<h3 id="auto-encoder-ae">Auto-encoder AE</h3>
<ul>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221128195349995.png" alt="image-20221128195349995">
<figcaption aria-hidden="true">image-20221128195349995</figcaption>
</figure></li>
<li>高维到低维的投射，再从低维进行重构</li>
<li>不仅仅是最小化重构误差</li>
<li>更具可解释性的嵌入</li>
</ul>
<h4 id="auto-encoder-minist">Auto Encoder MINIST</h4>
<p>28*28的输入，进入NN
Encoder，输出一个Code是小于784的，即将高维的投射到了低维的语意空间，是一个表示的问题。</p>
<p>低维表示输入NN Decoder重构高维数据，是一个生成的问题。</p>
<ul>
<li>PCA的降维方法：线性的降维和线性的还原</li>
<li>深度的Auto-Encoder</li>
</ul>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221128195806500.png" alt="image-20221128195806500">
<figcaption aria-hidden="true">image-20221128195806500</figcaption>
</figure>
<p>加了很多的层，可以把线性的变成<strong>非线性</strong>的。</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221128195934701.png" alt="image-20221128195934701">
<figcaption aria-hidden="true">image-20221128195934701</figcaption>
</figure>
<h4 id="技巧一去噪auto-encoder">技巧一：去噪Auto-Encoder</h4>
<p>不希望从原始输入中提取特征，我们再原始输入可以加入噪声，再进行特征的抽取。编码器可以学习更加鲁棒的特征。</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221128200607228.png" alt="image-20221128200607228">
<figcaption aria-hidden="true">image-20221128200607228</figcaption>
</figure>
<h4 id="技巧二基于cnn的auto-encoder">技巧二：基于CNN的Auto-Encoder</h4>
<p>将输入进行卷积、池化、激活等，先进行降维再进行特征提取。再进行反卷积、Unpooling等。</p>
<p>Deconvolution：</p>
<p>本质也是一个卷积[参考][https://blog.csdn.net/tfcy694/article/details/89073443]</p>
<h5 id="特征解耦">特征解耦</h5>
<ul>
<li>对象包含多个方面的信息</li>
<li>我们可以将各个特征进行分离和合成</li>
</ul>
<h3 id="离散表示vq-vae">离散表示VQ-VAE</h3>
<h3 id="ae总结">AE总结</h3>
<p>AE是个深度的降维方法，比PCA更好的reconstruction的过程。是PCA的非线性变化。</p>
<p>这是PCA方法：是线性的。</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221129162631813.png" alt="image-20221129162631813">
<figcaption aria-hidden="true">image-20221129162631813</figcaption>
</figure>
<p>这是AE：网络的每一层是线性的，但是又非线性激活</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221129162723610.png" alt="image-20221129162723610">
<figcaption aria-hidden="true">image-20221129162723610</figcaption>
</figure>
<h4 id="ae的问题">AE的问题：</h4>
<ul>
<li>AE通过编码器z=g(x)，将每个图片编码成向量z，它的解码器f(z)利用编码项链z来重构图片。</li>
<li>当<strong>AE作为生成模型</strong>，针对随机生成的编码向量z，f(z)只会生成没有意义的噪声，因为有些z根本就没有对应的x。</li>
<li>原因在于AE没有对z的分布p(z)进行建模，所以不确定哪些z能够生成有用的图片，训练f(z)数据有限，只能对有限的z进行相应。</li>
<li>再AE的基础上，显性对z的分布p(z)进行建模，使得自编码器成为一个合格的生成模型VAE</li>
<li>两者虽然都是X-&gt;Z-&gt;X’的结构，但是AE寻找的是单值映射关系，即：z=f(x)。
而VAE寻找的是分布的映射关系，即：DX→DZ</li>
</ul>
<h3 id="vaehttpsblog.csdn.neta312863063articledetails87953517">[VAE][https://blog.csdn.net/a312863063/article/details/87953517]</h3>
<p>变分自编码器（VAE）解决了自编码器中非正则化潜在空间的问题，并为整个空间提供了生成能力。
AE
中的编码器输出潜在向量。VAE的编码器不输出潜空间中的向量，而是输出每个输入的潜空间中预定义分布的参数。然后VAE对这个潜在分布施加约束，迫使它成为一个正态分布。这个约束确保了潜在空间是<strong>正则化</strong>的。</p>
<p>其基本思路是很容易理解的：把一堆真实样本通过编码器网络变换成一个理想的数据分布，然后这个数据分布再传递给一个解码器网络，得到一堆生成样本，生成样本与真实样本足够接近的话，就训练出了一个自编码器模型。那VAE(变分自编码器)就是在自编码器模型上做进一步变分处理，使得编码器的输出结果能对应到目标分布的均值和方差，如下图所示:</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20190226215129981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EzMTI4NjMwNjM=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">
<figcaption aria-hidden="true">在这里插入图片描述</figcaption>
</figure>
<h4 id="结构img">结构：<img src="https://pic1.zhimg.com/v2-0553e02c66ff356e756891aab0717c0c_r.jpg" alt="img"></h4>
<p>AE是一个向量，一个特征，Latent Representation</p>
<p>VAE是一个高斯分布的两个参数：<span class="math inline">\(\mu,\sigma\)</span>，加入全连接层生成均值和方差，每一个特征都要有一个分布。还原时使用在特征的分布上采样一个点。</p>
<figure>
<img src="https://ucc.alicdn.com/pic/developer-ecology/f0ed90be33fa4034bf840ebbc4e86219.png" alt="image.png">
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在auto-encoder中，编码器是直接产生一个编码的，但是在VAE中，为了给编码添加合适的噪音，编码器会输出两个编码，一个是原有编码(m1,m2,m3)【个人觉得和μ<span class="number">1</span>，μ<span class="number">2</span>一样的】，另外一个是控制噪音干扰程度的编码(σ<span class="number">1</span>,σ<span class="number">2</span>,σ<span class="number">3</span>)，第二个编码其实很好理解，就是为随机噪音码(e1,e2,e3)分配权重，然后加上exp(σi)的目的是为了保证这个分配的权重是个正值，最后将原编码与噪音编码相加，就得到了VAE在<span class="meta">code</span>层的输出结果(<span class="built_in">c1</span>,<span class="built_in">c2</span>,<span class="built_in">c3</span>)。其它网络架构都与Deep Auto-encoder无异。</span><br><span class="line">损失函数方面，除了必要的重构损失外，VAE还增添了一个损失函数（见上图Minimize2内容），这同样是必要的部分，因为如果不加的话，整个模型就会出现问题：为了保证生成图片的质量越高，编码器肯定希望噪音对自身生成图片的干扰越小，于是分配给噪音的权重越小，这样只需要将(σ<span class="number">1</span>,σ<span class="number">2</span>,σ<span class="number">3</span>)赋为接近负无穷大的值就好了。所以，第二个损失函数就有限制编码器走这样极端路径的作用，这也从直观上就能看出来，exp(σi)-(<span class="number">1</span>+σi)在σi<span class="number">=0</span>处取得最小值，于是(σ<span class="number">1</span>,σ<span class="number">2</span>,σ<span class="number">3</span>)就会避免被赋值为负无穷大。</span><br><span class="line">上述我们只是粗略地理解了VAE的构造机理，但是还有一些更深的原理需要挖掘，例如第二个损失函数为何选用这样的表达式，以及VAE是否真的能实现我们的预期设想，即“图片能够编码成易于表示的形态，并且这一形态能够尽可能无损地解码回原真实图像，是否有相应的理论依据。</span><br></pre></td></tr></table></figure>
<h3 id="vae数学原理">VAE数学原理</h3>
<h4 id="encoder-1">Encoder</h4>
<p>学习<span class="math inline">\(q_{\phi}(x|z)\)</span></p>
<h4 id="decoder-1">Decoder</h4>
<p>学习<span class="math inline">\(p_{\theta}(x|z)\)</span></p>
<h4 id="vae图结构模型">VAE图结构模型</h4>
<p>N是N个data，两个变量的依赖关系：参数<span class="math inline">\(\theta\)</span>，N个z</p>
<p><span class="math inline">\(P(x)=\int_z P(x|z)P(z)dz\)</span></p>
<h4 id="映射函数">映射函数</h4>
<ul>
<li><span class="math inline">\(X=g(z)\)</span></li>
<li><span class="math inline">\(g(z)=z/10+z/||z||\)</span></li>
<li>采样高斯模型z可以生成一个x的data的形式。</li>
</ul>
<h4 id="数据生成">数据生成</h4>
<p>z的空间是一个高斯的分布，P(x)是数据空间。</p>
<p>什么是高斯混合模型呢？就是说，任何一个数据的分布，都可以看作是若干高斯分布的叠加。</p>
<figure>
<img src="https://ucc.alicdn.com/pic/developer-ecology/57b1b1aa7a364eb6b8510d3335b835a1.png" alt="image.png">
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>如图所示，如果P(X)代表一种分布的话，存在一种拆分方法能让它表示成图中若干浅蓝色曲线对应的高斯分布的叠加。有意思的是，这种拆分方法已经证明出，当拆分的数量达到512时，其叠加的分布相对于原始分布而言，误差是非常非常小的了。</p>
<p>于是我们可以利用这一理论模型去考虑如何给数据进行编码。一种最直接的思路是，<strong>直接用每一组高斯分布的参数</strong>作为一个编码值实现编码。</p>
<p>如上图所示，m代表着编码维度上的编号，譬如实现一个512维的编码，m的取值范围就是1,2,3……512。<strong>m会服从于一个概率分布P(m)</strong>（多项式分布）。现在编码的对应关系是，每采样一个m，其对应到一个小的高斯分布N(μm,∑m)，P(X)就可以等价为所有的这些高斯分布的叠加，即：</p>
<p><span class="math inline">\(P(x)=\sum_m P(m)P(x|m)\)</span></p>
<p><span class="math inline">\(x|m\)</span>~<span class="math inline">\(N(\mu^m,\Sigma^m)\)</span></p>
<p>上述的这种编码方式是非常简单粗暴的，它对应的是我们之前提到的离散的、有大量失真区域的编码方式。于是我们需要对目前的编码方式进行改进，使得它成为连续有效的编码。</p>
<figure>
<img src="https://ucc.alicdn.com/pic/developer-ecology/d876160d7c8f47dbb64ac450638ddf02.png" alt="image.png">
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>现在我们的编码换成一个<strong>连续变量z</strong>，我们规定<strong>z服从正态分布</strong>N(0,1)（实际上并不一定要选N(0,1)用，其他的连续分布都是可行的）。<strong>每对于一个采样z，会有两个函数μ和σ</strong>，分别决定z对应到的高斯分布的均值和方差，然后在积分域上所有的高斯分布的累加就成为了原始分布P(X)。</p>
<p><span class="math inline">\(P(x)=\int_z P(z)P(x|z)dz\)</span></p>
<p><span class="math inline">\(P(x|z)\)</span>~<span class="math inline">\(N(\mu(z),\sigma(z))\)</span></p>
<ul>
<li>那么我们知道P(z)是已知的，是一个正态分布</li>
<li><span class="math inline">\(P(x|z)\)</span>是和<span class="math inline">\(\mu(z),\sigma(z)\)</span>有关的</li>
<li>那么P(x)通常是复杂的，因此我们用神经网络计算这个<span class="math inline">\(\mu,\sigma\)</span></li>
</ul>
<h4 id="decoder关于decoder和encoder的理解httpszhuanlan.zhihu.comp55557709">Decoder[关于Decoder和Encoder的理解][https://zhuanlan.zhihu.com/p/55557709]</h4>
<p>Decoder做的事情就是计算这个<span class="math inline">\(\mu(z),\sigma(z)\)</span></p>
<p>等价于求解<span class="math inline">\(P(x|z)\)</span>，就是求解了<span class="math inline">\(P(x)\)</span></p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221129201341997.png" alt="image-20221129201341997">
<figcaption aria-hidden="true">image-20221129201341997</figcaption>
</figure>
<h4 id="encoder-2">Encoder</h4>
<p>Encoder做的事情是求解<span class="math inline">\(q(z|x)\)</span>，q可以是任何分布，将x编码为隐变量z</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221129201536712.png" alt="image-20221129201536712">
<figcaption aria-hidden="true">image-20221129201536712</figcaption>
</figure>
<p>回到我们要求解的目标式子：</p>
<p><span class="math inline">\(P(x)=\int_z P(z)P(x|z)dz\)</span></p>
<p>我们希望这个P(x)越大越好，就是求解<span class="math inline">\(log
P(x)\)</span>的最大</p>
<p>我们想要最大化P(x)</p>
<ul>
<li><span class="math inline">\(logP(x)=\int_zq(z|x)logP(x)dz\)</span></li>
<li><span class="math inline">\(=\int_z
q(z|x)log(\frac{P(z,x)}{P(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int
_zq(z|x)log(\frac{P(z,x)}{q(z|x)}\frac{q(z,x)}{P(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int_z
q(z|x)log(\frac{P(z,x)}{q(z|x)})dz+\int_z
q(z|x)log(\frac{q(z,x)}{P(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int_z
q(z|x)log(\frac{P(z,x)}{P(z|x)})dz+D_{KL}(q(z|x)||P(z|x))\)</span>
<ul>
<li>这个第二项是KL散度，是一个非负的值</li>
<li><span class="math inline">\(D_{KL}(p||q)=p(x_i)[log(p(x_i))-log(q(x_i))]\)</span></li>
</ul></li>
</ul>
<p>那么一个P(x)的下界就有了</p>
<p><span class="math inline">\(log(P(x))\geq \int_z
q(z|x)log(\frac{P(z,x)}{P(z|x)})dz\)</span></p>
<p>记作<span class="math inline">\(L_b=\int_z
q(z|x)log(\frac{P(x|z)P(z)}{q(z|x)})dz\)</span></p>
<p>于是<span class="math inline">\(logP(x)=L_b+D_{KL}(q(z|x)||P(z|x))\)</span></p>
<p>VAE的精妙之处来了：</p>
<p>原本，我们要P(x|z)使得<span class="math inline">\(log
P(x)\)</span>最大，现在引入了一个<span class="math inline">\(q(z|x)\)</span>，变成了同时求<span class="math inline">\(P(x|z),q(z|x)\)</span>使得<span class="math inline">\(logP(x)\)</span>最大，那么<span class="math inline">\(L_b,logP(x)\)</span>的关系是什么？</p>
<p>很显然，<span class="math inline">\(logP(x)\)</span>和<span class="math inline">\(q(z|x)\)</span>是无关的。</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221129202447653.png" alt="image-20221129202447653">
<figcaption aria-hidden="true">image-20221129202447653</figcaption>
</figure>
<p>调节这个<span class="math inline">\(q(z|x)\)</span>可以使得KL散度变小，当<span class="math inline">\(q(z|x)\)</span>和<span class="math inline">\(P(z|x)\)</span>一致时，KL散度为0。</p>
<p>同时<span class="math inline">\(L_b=logP(x)\)</span>。无论这个<span class="math inline">\(logP(x)\)</span>值如何，我们可以调节使得<span class="math inline">\(L_b=logP(x)\)</span>，又同时正好是下界，最大化<span class="math inline">\(logP(x)\)</span>我们就直接求<span class="math inline">\(Max\ L_b\)</span>即可。</p>
<p>调节<span class="math inline">\(P(x|z)\)</span>就是调节Decoder，调节<span class="math inline">\(q(z|x)\)</span>解释调节Encoder。VAE的训练逻辑就是Decoder向前一步，Encoder就调节与其一致，并且Decoder无法后退。</p>
<p>那么我们来<span class="math inline">\(Max\ L_b\)</span></p>
<ul>
<li><span class="math inline">\(L_b=\int_z
q(z|x)log(\frac{P(z,x)}{q(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int_z
q(z|x)log(\frac{P(x|z)P(z)}{q(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int
q(z|x)log(\frac{P(z)}{q(z|x)})+\int q(z|x)logP(x|z)dz\)</span></li>
<li><span class="math inline">\(=-D_{KL}(q(z|x)||P(z))+\int
q(z|x)logP(x|z)dz\)</span></li>
<li>即求解<span class="math inline">\(D_{KL}(q(z|x)||P(z))\)</span>最小值，<span class="math inline">\(\int q(z|x)logP(x|z)dz\)</span>最大值</li>
</ul>
<p><span class="math inline">\(D_{KL}(q(z|x)||P(z))\)</span>展开式为<span class="math inline">\(\sum_{i=1}^J(exp(\sigma_i)-(1+\sigma_i)+m_i^2)\)</span></p>
<p><span class="math inline">\(max\ \int q(z|x)logP(x|z)dz=max\
E_{q(z|x)}[logP(x|z)]\)</span></p>
<p>这个期望就是一个损失函数。</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221129204037390.png" alt="image-20221129204037390">
<figcaption aria-hidden="true">image-20221129204037390</figcaption>
</figure>
<h2 id="lecture-22">Lecture 22</h2>
<h3 id="vae-review">VAE Review</h3>
<ul>
<li>AE：INPUT、ENCODER、LATENT FEATURE、DECODER、RECONSTRUCTED INPUT
<ul>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205185723281.png" alt="image-20221205185723281">
<figcaption aria-hidden="true">image-20221205185723281</figcaption>
</figure></li>
</ul></li>
<li>VAE
<ul>
<li><span class="math inline">\(z_i=\mu_i+\sigma_i·\epsilon
_i\)</span>，Reparameterization Trick</li>
</ul></li>
</ul>
<h3 id="c-vae">C-VAE</h3>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205201108446.png" alt="image-20221205201108446">
<figcaption aria-hidden="true">image-20221205201108446</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205201116654.png" alt="image-20221205201116654">
<figcaption aria-hidden="true">image-20221205201116654</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205201124986.png" alt="image-20221205201124986">
<figcaption aria-hidden="true">image-20221205201124986</figcaption>
</figure>
<h3 id="vq-vaehttpszhuanlan.zhihu.comp91434658">[VQ-VAE][https://zhuanlan.zhihu.com/p/91434658]</h3>
<p>VAE和VE的不同之处在与，VAE不再去学习一个连续的表征，而
是直接学习一个分布，然后通过这个分布采样得到中间表征去 重建原图。</p>
<p>VAE使用了固定的正态分布先验，以及连续的中间表征，导致
图片生成的多样性弱和可控性差。</p>
<p>前面看到, VAE的隐变量 z 的每一维都是一个连续的值,
而VQ-VAE最大的特点就是, z的每一维都是离散的整数.
这样做符合一些自然界的模态 (a more natural fit for many of the
modalities). 比如Language是a sequence of symbols, 或者reasoning,
planning and predictive learning. 因此, VQ-VAE可以successfully model
important features that span many dimensions in data space,
比如图片里某个object会覆盖很多pixel,
音频中一个phoneme会持续很多samples/frames,
而不会去学一些特别细节的东西.</p>
<p>将 z 离散化的关键就是VQ, 即vector quatization. 简单来说,
就是要先有一个codebook, 这个codebook是一个embedding table.
我们在这个table中找到和vector最接近(比如欧氏距离最近)的一个embedding,
用这个embedding的index来代表这个vector.</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205201447823.png" alt="image-20221205201447823">
<figcaption aria-hidden="true">image-20221205201447823</figcaption>
</figure>
<ol type="1">
<li>自动编码：将input输入，获得Latent
Variable，设隐变量的维度为D，输入的size为H *W，则feature
map大小为H*W*D</li>
<li>降维离散化，学习到一个codebook，codebook中有K个D维度的离散向量<span class="math inline">\(e_1,...e_K\)</span></li>
<li>最近邻重构，每一个Latent Variable找一个离最近的codebook中的向量<span class="math inline">\(e_i\)</span>，用index i表示，获得了<span class="math inline">\(q(z|x)\)</span>.
<ol type="1">
<li><span class="math inline">\(z=encoder(x)\)</span></li>
<li><span class="math inline">\(E=[e_1,e_2,...,e_K]\)</span></li>
<li><span class="math inline">\(z\rarr
e_k,k=argmin_j||z-e_j||^2\)</span></li>
<li><span class="math inline">\(x\rarr_{encoder}z\rarr_{最近邻}\rarr
z_q\rarr_{decoder}\rarr \hat x\)</span></li>
</ol></li>
<li>把绿色的<span class="math inline">\(z_e(x)\)</span>
用codebook里最近的 <span class="math inline">\(e_i\)</span>替换后可以得到紫色的 <span class="math inline">\(z_q(x)\)</span> , 这是decoder的输入,
然后reconstruct得到图片.</li>
</ol>
<h4 id="后验分布qzx">后验分布<span class="math inline">\(q(z|x)\)</span></h4>
<ul>
<li>后验分布<span class="math inline">\(q(z|x)\)</span>是一个多类分布，为one-hot型
<ul>
<li><span class="math inline">\(q(z=k|x)=\begin{cases}1\
k=argmin_i||z_e(x)-e_i||_2\\0\ otherwise\end{cases}\)</span></li>
</ul></li>
<li>基确定分布<span class="math inline">\(q(z|x)\)</span>, 后验分布<span class="math inline">\(q(z|x)\)</span>和先验分布<span class="math inline">\(p(z)\)</span>的KL散度为
<ul>
<li><span class="math inline">\(KL(q(z|x)||p(z))=\sum q(z|x)log\
\frac{q(z|x)}{p(z)}=log\frac{1}{1/K}+0=logK\)</span></li>
</ul></li>
<li>给定KL散度为一个常量，VQ-VAE的训练损失项为重建误差 log p(x|z)。</li>
</ul>
<h4 id="vq-vae目标函数">VQ-VAE目标函数</h4>
<ol type="1">
<li>Reconstruction Loss</li>
<li>VQ Loss</li>
<li>commitment loss</li>
</ol>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205203921059.png" alt="image-20221205203921059">
<figcaption aria-hidden="true">image-20221205203921059</figcaption>
</figure>
<p>其中，reconstruction loss作用在encoder和decoder上，VQ loss用
来更新embedding空间（EMA方式），commitment loss用来约
束encoder。系数beta默认设置为0.25。</p>
<h4 id="straight-through-estimator">Straight-through Estimator</h4>
<p>由于argmin操作不可导，重建误差的梯度无法传导到encoder, 采
用straight-through
estimator来采用上游得到的梯度。基于Straight-Through的思想，前项传播的时候可以用想要的变量，而反向传播的时候，用所涉及的梯度。其目标函数为<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205204328311.png" alt="image-20221205204328311"></p>
<p>其中，前向传播计算为：<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221205204338862.png" alt="image-20221205204338862"></p>
<h2 id="lecture-23">Lecture 23</h2>
<h3 id="gangenerative-adverasrial-network">GAN：Generative Adverasrial
Network</h3>
<ul>
<li>生成式对抗网络一种深度学习模型，通过生成模型和判别模型进行互相博弈产生相当好的输出。</li>
<li>通过对抗过程同时训练两个模型，生成器学会创造看起来真实的图像，鉴别器学会区分生成图片和真实图片。</li>
<li>训练期间，生成器变得更好创建看起来真实的图像，鉴别器更好区分它们。当鉴别器不能区分，过程达到平衡。</li>
</ul>
<h3 id="gan训练">GAN训练</h3>
<ul>
<li>输入一个初始噪声z，然后通过生成器G得到一个伪造的数据G(z)</li>
<li>从真实数据中取一部分即真实数据x，将两者混合丢到判别器D，由判别器做这些图像是真是假的二分类，得到概率D(x)，计算出loss并且回传。</li>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221206172019029.png" alt="image-20221206172019029">
<figcaption aria-hidden="true">image-20221206172019029</figcaption>
</figure></li>
</ul>
<h4 id="gan损失价值函数ganhttpszhuanlan.zhihu.comp34287744">GAN损失价值函数[GAN][https://zhuanlan.zhihu.com/p/34287744]</h4>
<p>在训练过程中，生成网络的目标就是尽量生成真实的图片去欺骗判别网络D。而网络D的目标就是尽量把网络G生成的图片和真实的图片分别开来。这样，G和D构成了一个动态的“博弈过程”。这个博弈过程具体是怎么样的呢？</p>
<ul>
<li>根据交叉熵损失的价值函数<span class="math inline">\(V(D,G)\)</span>
<ul>
<li><span class="math inline">\(min_Gmax_DV(D,G)=E_{x～p_{data}(x)}[log\
D(x)]+E_{z～p_{z}(z)}[1-log\ D(G(z))]\)</span></li>
<li>其中真实数据的x服从<span class="math inline">\(p_{data}\)</span>分布，<span class="math inline">\(p_z(z)\)</span>是噪声z的分布</li>
<li><span class="math inline">\(G(z)\)</span>将z映射到数据空间，拟合真实数据的分布，而D(x)得到真实数据的概率</li>
<li>为了学习生成器在数据x上的分布p，训练时自然使D判断x是p中取出的期望E最大化，同时最小化伪造的概率<span class="math inline">\(log\ ( 1-D(G(z)))\)</span></li>
</ul></li>
<li>在这里，训练网络D使得最大概率地分对训练样本的标签（最大化log D(x)和
log(1−D(G(z))) ），训练网络G最小化log(1 –
D(G(z)))，即最大化D的损失。而训练过程中固定一方，更新另一个网络的参数，交替迭代，使得对方的错误最大化，最终，G
能估测出样本数据的分布，也就是生成的样本更加的真实。</li>
</ul>
<blockquote>
<p>或者我们可以直接理解G网络的loss是<span class="math inline">\(log(1−D(G(z))\)</span>，而D的loss是<span class="math inline">\(-(log(D(x))+log(1−D(G(z)))\)</span></p>
</blockquote>
<ul>
<li>G的训练目标就是让<span class="math inline">\(D(G(z))\)</span>趋近于1，即让D判别G(z)是正例</li>
<li>D网络的训练就是一个2分类，目标是分清楚真实数据和生成数据，也就是希望真实数据的<span class="math inline">\(D(x)\)</span>输出趋近于1，而生成数据的输出即<span class="math inline">\(D(G(z))\)</span>趋近于0，或是负类。这里就是体现了对抗的思想。</li>
</ul>
<h4 id="算法层面">算法层面</h4>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221206173842654.png" alt="image-20221206173842654">
<figcaption aria-hidden="true">image-20221206173842654</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221206174346717.png" alt="image-20221206174346717">
<figcaption aria-hidden="true">image-20221206174346717</figcaption>
</figure>
<h2 id="lecture-24">Lecture 24</h2>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221212191526445.png" alt="image-20221212191526445">
<figcaption aria-hidden="true">image-20221212191526445</figcaption>
</figure>
<h3 id="dcgan">DCGAN</h3>
<p>Deep Convolution GAN，判别器是一种ConvNet，接受图像输出预测向量。</p>
<h3 id="progan">ProGAN</h3>
<p>渐进式生成的方式是先训练出低分辨率的图片，再逐步增加网络结构提升图片质量。</p>
<p>图片进行下采样，可以获得低分辨率图片从而进行低分辨率的训练。比如我们有1024*1024的图片，我们先下采样获得4*4的图片，进行低分辨率的训练。在逐步增加分辨率。</p>
<p>在加倍分辨率训练的时候，加入平滑转换过程，增加模型训练的稳定程度。</p>
<ul>
<li><span class="math inline">\(X=X_{16pixel}*(1-\alpha)+X_{32pixel}*\alpha\)</span></li>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221212192114669.png" alt="image-20221212192114669">
<figcaption aria-hidden="true">image-20221212192114669</figcaption>
</figure></li>
</ul>
<h3 id="cgan">CGAN</h3>
<p>生成器和判别器都已额外信息y为条件，GAN模型可以拓展为一个条件模型。</p>
<p><span class="math inline">\(min_Dmax_GV(D,G)=E_{x}[logD(x|y)]+E_{z}[log(1-D(G(z|y)))]\)</span></p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221212192405497.png" alt="image-20221212192405497">
<figcaption aria-hidden="true">image-20221212192405497</figcaption>
</figure>
<h3 id="stackgan">StackGAN</h3>
<ul>
<li>什么是StackGAN，怎么提出来的？</li>
<li>根据文字描述，人工生成高质量图片的任务是计算机视觉领域一个挑战，并且有很多应用场景。现有的文字转图像方式很难表现文字的含义，并且细节部分缺失严重，不够生动具体。</li>
<li>现有的模型（如 <code>Vanilla GAN</code>）只是简单的添加
<code>upsampling</code>
层来生成高分辨率的图，这会导致训练不稳定，且生成无用的图片</li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221212195840262.png" alt="image-20221212195840262" style="zoom:50%;"></li>
</ul>
<h4 id="stackgan的模型结构httpszhuanlan.zhihu.comp78102953">[StackGAN的模型结构][https://zhuanlan.zhihu.com/p/78102953]</h4>
<p>StackGAN是分段式结构</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221212200042597.png" alt="image-20221212200042597">
<figcaption aria-hidden="true">image-20221212200042597</figcaption>
</figure>
<h4 id="conditioning-augmentation">Conditioning Augmentation</h4>
<p>根据给定的文字描述，勾勒初始的形状和色彩，生成低分辨率的图像。</p>
<ul>
<li><p>TEXT输入，经过pretrained-Text-encoder再经过Embedding获得编码，输入Generator。</p></li>
<li><p>描述文字首先被预训练好的编码器编码为词嵌入向量 <span class="math inline">\(\phi_t\)</span></p>
<ul>
<li><pre><code>  在前人的研究中，词嵌入向量被非线性的转换为生成条件隐含变量，并作为生成器的输入。然而，词嵌入的隐含空间维度维度一般很高（&gt; 100）。当输入数据量很少的时候，通常会导致隐含变量分布空间不连续(大部分值为 0，太过稀疏)，这对生成器的训练不利。</code></pre></li>
</ul></li>
<li><p>因此，我们引入条件增强 <code>(Conditioning Augmentation)</code>
来产生额外的条件变量 <span class="math inline">\(\hat c\)</span>
。我们不是选定固定的<span class="math inline">\(\hat c\)</span>
，而是从独立高斯分布<span class="math inline">\(N(\mu(\phi_t),\Sigma(\phi_t))\)</span>中随机采样。其中，均值
<span class="math inline">\(\mu(\phi_t)\)</span> 和对角方差矩阵<span class="math inline">\(\Sigma(\phi_t)\)</span>是关于词嵌入向量<span class="math inline">\(\phi_t\)</span>的函数（全连接层子网络）。<strong>上面一段话，换言之就是，将原始词向量分布映射到一个高斯分布中，均值和方差不变。</strong></p></li>
<li><p>给定较少的 <code>text-image</code>
对，通过该手段，也能够生成更多的训练样本，并且对于条件空间的微小扰动，其稳健型也更好。为了进一步增强条件分布的平滑性，以及避免过拟合(引入噪声相当于数据增强)，我们使用
<code>KL</code> 散度对其正则化</p>
<ul>
<li><span class="math inline">\(D_{KL}(N(\mu(\phi_t),\Sigma(\phi_t))||N(0,I))\)</span></li>
</ul></li>
</ul>
<h4 id="stage-1">Stage-1</h4>
<p>第一阶段主要用于生成粗略的形状和颜色等。先从<span class="math inline">\(N(\mu(\phi_t),\Sigma(\phi_t))\)</span>中随机采样出
<span class="math inline">\(\hat c_0\)</span> ，并随机采样的高斯噪声
<code>z</code>，将它们进行 <code>concatenate</code> ，然后作为
<code>Stage-I</code> 的输入，来训练判别器 <span class="math inline">\(D_0\)</span> 和 生成器<span class="math inline">\(G_0\)</span> ，分别对应如下目标函数：</p>
<ul>
<li><span class="math inline">\(max
L_{D_0}=E_{(I_0,t)～p_{data}}[log(D_0(I_0,\phi_t))]+E_{z～p_z,t～p_{data}}[log(1-D_0(G_0(z,\hat
c_0),\phi_t))]\)</span></li>
<li><span class="math inline">\(min
L_{G_0}=E_{z～p_z,t～p_{data}}[log(1-D_0(G_0(z,\hat
c_0),\phi_t))]+D_{KL}(N(\mu(\phi_t),\Sigma(\phi_t))||N(0,I))\)</span></li>
<li>其中，真实图像<span class="math inline">\(I_0\)</span>和文本描述<span class="math inline">\(t\)</span>源自于实际数据分布<span class="math inline">\(p_{data}\)</span> 。 <span class="math inline">\(z\)</span>表示从高斯分布分布<span class="math inline">\(p_{data}\)</span> 中随机提取的噪声向量。 λ
为正则化参数，用于平衡公式中的两项。</li>
<li><strong>其中，</strong> <span class="math inline">\(μ_0(φ_t),Σ_0(φ_t)\)</span>
<strong>是与网络剩余部分一起学习</strong></li>
</ul>
<h5 id="stage-2">Stage-2</h5>
<p><code>Stage-1</code>
阶段生成的低分辨率图像通常缺乏鲜明的目标特征，并且可能包含一些变形。同时，文本描述中的部分信息可能也未体现出来。所以，通过
<code>Stage-2</code> 可以在 <code>Stage-1</code>
生成的低分辨率图像和文本描述的基础上，生成高分辨率图片，其修正了
<code>Stage-1</code>的缺陷，并完善了被忽略的文本信息细节。</p>
<p><code>Stage-2</code> 以高斯隐含变量<span class="math inline">\(\hat
c\)</span>以及 <code>Stage-1</code> 的生成器的输出 <span class="math inline">\(s_0=G_0(z,\hat c_0)\)</span> 为输入，来训练生成器
<code>G</code> 和判别器 <code>D</code>，其目标函数分别为：</p>
<ul>
<li><span class="math inline">\(max
L_{D}=E_{(I,t)～p_{data}}[log(D(I,\phi_t))]+E_{s_0～p_{G_0},t～p_{data}}[log(1-D(G(s,\hat
c),\phi_t))]\)</span><br>
</li>
<li><span class="math inline">\(min
L_{G}=E_{s_0～p_{G_0},t～p_{data}}[log(1-D(G(s_0,\hat
c),\phi_t))]+D_{KL}(N(\mu(\phi_t),\Sigma(\phi_t))||N(0,I))\)</span></li>
</ul>
<h3 id="pix2pixgan">Pix2PixGAN</h3>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221212201859333.png" alt="image-20221212201859333">
<figcaption aria-hidden="true">image-20221212201859333</figcaption>
</figure>
<h4 id="u-net">U-Net</h4>
<p>U-Net是编码解码结构，编码负责特征提取，解码负责恢复原
始分辨率（上采样和拼接操作）</p>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221212201927427.png" alt="image-20221212201927427">
<figcaption aria-hidden="true">image-20221212201927427</figcaption>
</figure>
<p><span class="math inline">\(L_{cGAN}(G,D)=E_{x,y}[log\
D(x,y)]+E_{x,z}[log(1-D(x,G(x,z)))]\)</span></p>
<p><span class="math inline">\(L_{L_1(G)}=E_{x,y,z}[||y-G(x,z)||_1]\)</span></p>
<p><span class="math inline">\(G^*=argmin_Gmax_DL_{cGAN}(G,D)+\lambda
L_{L_1}(G)\)</span></p>
<h3 id="cyclegan">CycleGAN</h3>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221213161739391.png" alt="image-20221213161739391">
<figcaption aria-hidden="true">image-20221213161739391</figcaption>
</figure>
<figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221213161747709.png" alt="image-20221213161747709">
<figcaption aria-hidden="true">image-20221213161747709</figcaption>
</figure>
<h3 id="stylegan">StyleGAN</h3>
<h2 id="lecture-25">Lecture 25</h2>
<h3 id="diffusion-modelhttpszhuanlan.zhihu.comp525106459">[Diffusion
Model][https://zhuanlan.zhihu.com/p/525106459]</h3>
<figure>
<img src="https://pic3.zhimg.com/v2-42181e6098a90635a05cfeb1c1091afe_r.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>diffusion model和其他模型最大的区别是它的latent
code(z)和原图是同尺寸大小的，当然最近也有基于压缩的latent diffusion
model，不过是后话了。一句话概括diffusion model，即存在一系列高斯噪声（ T
轮），将输入图片 x0 变为纯高斯噪声 xT 。而我们的模型则负责将 xT
复原回图片 x0 。这样一来其实diffusion model和GAN很像，都是给定噪声
xT生成图片 x0 ，但是要强调的是，这里噪声 xT
与图片x0是<strong>同维度</strong>的。</p>
<h4 id="ddpm">DDPM</h4>
<ul>
<li>线性组合：<span class="math inline">\(\overline
x_t=(1-\lambda)x_0+\lambda x_0&#39;\)</span></li>
<li>前向加噪：<span class="math inline">\(x&#39;_t～q(x_t|x_0)\)</span></li>
<li>逆向合成：<span class="math inline">\(\overline x_0～p(x_0|\overline
x_t)\)</span></li>
</ul>
<p><span class="math inline">\(x_t\)</span>是噪声符合高斯分布，<span class="math inline">\(x_0\)</span>是原始数据。前向不断加噪声获得<span class="math inline">\(x_t\)</span>，反向不断去噪还原<span class="math inline">\(x_0\)</span></p>
<ul>
<li>反向去噪需要学习参数<span class="math inline">\(\theta\)</span></li>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221213163243548.png" alt="image-20221213163243548">
<figcaption aria-hidden="true">image-20221213163243548</figcaption>
</figure></li>
<li>ELBO：Evidence Lower Bound
<ul>
<li>想要最大化P(x)
<ul>
<li><span class="math inline">\(logP(x)=\int_zq_{\phi}(z|x)logP(x)dz\)</span></li>
<li><span class="math inline">\(=\int_z
q_{\phi}(z|x)log(\frac{P(z,x)}{P(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int
_zq_{\phi}(z|x)log(\frac{P(z,x)}{q_{\phi}(z|x)}\frac{q_{\phi}(z,x)}{P(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int_z
q_{\phi}(z|x)log(\frac{P(z,x)}{q_{\phi}(z|x)})dz+\int_z
q_{\phi}(z|x)log(\frac{q_{\phi}(z,x)}{P(z|x)})dz\)</span></li>
<li><span class="math inline">\(=\int_z
q_{\phi}(z|x)log(\frac{P(z,x)}{q_{\phi}(z|x)})dz+D_{KL}(q_{\phi}(z|x)||P(z|x))\)</span></li>
<li><span class="math inline">\(log(P(x))\geq \int_z
q_{\phi}(z|x)log(\frac{P(z,x)}{q_{\phi}(z|x)})dz=E_{q_{\phi}(z|x)}[log\frac{p(x,z)}{q_{\phi}(z|x)}]\)</span></li>
</ul></li>
</ul></li>
<li>VAE
<ul>
<li><span class="math inline">\(E_{q_{\phi}(z|x)}[log\frac{p(x,z)}{q_{\phi}(z|x)}]=E_{q_{\phi}(z|x)}[log\
p_{\theta}(x|z)]+E_{q_{\phi}(z|x)}[log\
\frac{p(z)}{q_{\phi}(z|x)}]\)</span></li>
<li><span class="math inline">\(=E_{q_{\phi}(z|x)}[log\
p_{\theta}(x|z)]-D_{KL}(q_{\phi}(z|x)||p(z))\)</span></li>
<li><span class="math inline">\(q_{\phi}(z|x)=N(z;\mu_{\phi}(x),\sigma^2_{\phi}(x)I)\)</span></li>
<li><span class="math inline">\(p(z)=N(z;0,I)\)</span></li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221213164608297.png" alt="image-20221213164608297" style="zoom:50%;"></li>
</ul></li>
<li>HVAE
<ul>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221213170018873.png" alt="image-20221213170018873" style="zoom:50%;"></li>
<li><span class="math inline">\(p(x,z_{1:T})=p(z_T)p_{\theta}(x|z_1)\prod_{t=2}^Tp_{\theta}(z_{t-1}|z_t)\)</span></li>
<li><span class="math inline">\(q_{\phi}(z_{1:T}|x)=q_{\phi}(z_1|x)\prod_{t=2}^Tq_{\phi}(z_t|z_{t-1})\)</span></li>
<li><span class="math inline">\(log\ p(x)=log \int
p(x,z_{1:T})dz_{1:T}\)</span>
<ul>
<li><span class="math inline">\(=log \int
\frac{p(x,z_{1:T})q_{\phi}(z_{1:T}|x)}{q_{\phi}(z_{1:T}|x)}dz_{1:T}\)</span></li>
<li><span class="math inline">\(=log\
E_{q_{\phi}(z_{1:T}|x)}[\frac{p(x,z_{1:T})}{q_{\phi}(z_{1:T}|x)}]\)</span></li>
<li><span class="math inline">\(\geq E_{q_{\phi}(z_{1:T}|x)}[log\
\frac{p(x,z_{1:T})}{q_{\phi}(z_{1:T}|x)}]\)</span></li>
<li><span class="math inline">\(=E_{q_{\phi}(z_{1:T}|x)}[log\
\frac{p(z_T)p_{\theta}(x|z_1)\prod_{t=2}^Tp_{\theta}(z_{t-1}|z_t)}{q_{\phi}(z_1|x)\prod_{t=2}^Tq_{\phi}(z_t|z_{t-1})}]\)</span></li>
</ul></li>
<li>即多次迭代VAE的操作</li>
</ul></li>
<li>Variational Diffusion Models
<ul>
<li><span class="math inline">\(q(x_{1:T}|x_0)=\prod_{t=1}^Tq(x_t|x_{t-1})\)</span></li>
<li><span class="math inline">\(q(x_t|x_{t-1})=N(x_t;\sqrt\alpha_t
x_{t-1},(1-\alpha_t)I)\)</span></li>
<li><span class="math inline">\(p(x_{0:T})=p(x_T)\prod_{t=1}^Tp_{\theta}(x_{t-1}|x_t)\)</span></li>
<li><span class="math inline">\(p(x_T)=N(x_T;0,I)\)</span></li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221213170834508.png" alt="image-20221213170834508" style="zoom:67%;"></li>
</ul></li>
<li>Diffusion模型的ELBO
<ul>
<li><figure>
<img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/image-20221213170922263.png" alt="image-20221213170922263">
<figcaption aria-hidden="true">image-20221213170922263</figcaption>
</figure></li>
</ul></li>
</ul>
<p>[参考blog2][https://blog.csdn.net/Little_White_9/article/details/124435560]</p>
<h4 id="diffusion扩散过程">Diffusion扩散过程</h4>
<p>所谓前向过程，即往图片上加噪声的过程。虽然这个步骤无法做到图片生成，但是这是理解diffusion
model以及<strong>构建训练样本GT</strong>至关重要的一步。</p>
<p>给定真实图片 <span class="math inline">\(x_0∼q(x)\)</span>
,diffusion前向过程通过 T 次累计对其添加高斯噪声，得到 <span class="math inline">\(x_1,x_2,...,x_T\)</span>
，如下图的q过程。这里需要给定一系列的高斯分布方差的超参数$
{<em>t∈(0,1)}</em>{t=1}^T$ .前向过程由于每个时刻 t 只与 t−1
时刻有关，所以也可以看做马尔科夫过程：</p>
<ul>
<li><span class="math inline">\(q(x_t|x_{t-1})=N(x_t;\sqrt\alpha_t
x_{t-1},(1-\alpha_t)I)\)</span></li>
<li><span class="math inline">\(\beta+\alpha = 1\)</span></li>
<li><span class="math inline">\(q(x_{1:T}|x_0)=\prod_{t=1}^Tq(x_t|x_{t-1})\)</span></li>
</ul>
<p>这个过程中，随着 <span class="math inline">\(t\)</span> 的增大，$ x_t
$越来越接近纯噪声。当 $T→∞ <span class="math inline">\(，\)</span> x_T$
是完全的高斯噪声（下面会证明，且与均值系数<span class="math inline">\(1−β_t\)</span> 的选择有关）。且实际中 βt
随着t增大是递增的，即 $β_1&lt;β_2&lt;...&lt;β_T $。在GLIDE的code中，
$β_t $是由0.0001 到0.02线性插值（以 T=1000 为基准， T 增加，
β对应降低）。</p>
<h5 id="重参数reparameterization-trick">重参数（reparameterization
trick）</h5>
<p>重参数技巧在很多工作（gumbel softmax,
VAE）中有所引用。如果我们要从某个分布中随机采样(高斯分布)一个样本，这个过程是无法反传梯度的。而这个通过高斯噪声采样得到
<span class="math inline">\(x_t\)</span>
的过程在diffusion中到处都是，因此我们需要通过重参数技巧来使得他可微。最通常的做法是吧随机性通过一个独立的随机变量(
ϵ )引导过去。</p>
<p>举个例子，如果要从高斯分布 $z∼N(z;μ_θ,σ_θ^2I)
$采样一个z，我们可以写成:</p>
<ul>
<li><span class="math inline">\(z=\mu_\theta+\sigma_\theta·\epsilon\)</span></li>
<li><span class="math inline">\(\epsilon～N(0,I)\)</span></li>
</ul>
<p>上式的z依旧是有随机性的， 且满足均值为 <span class="math inline">\(μ_θ\)</span> 方差为 <span class="math inline">\(σ_θ^2\)</span> 的高斯分布。这里的<span class="math inline">\(μ_θ,σ_θ^2\)</span>可以是由参数 θ
的神经网络推断得到的。整个“采样”过程依旧梯度可导，随机性被转嫁到了ϵ上。</p>
<h5 id="任意时刻的-x_t-可以由-x_0-和-β-表示">任意时刻的 <span class="math inline">\(x_t\)</span> 可以由 <span class="math inline">\(x_0\)</span> 和 β 表示</h5>
<p>用重参数化技巧表示 <span class="math inline">\(x_{t}\)</span></p>
<p><span class="math inline">\(x_t=\sqrt\alpha_t
x_{t-1}+\sqrt{(1-\alpha_t)}z_{t-1}\)</span></p>
<p><span class="math inline">\(z_t～N(0,I)\)</span></p>
<p>那么令<span class="math inline">\(\overline
\alpha_t=\prod_{i=1}^t\alpha_i\)</span></p>
<p><span class="math inline">\(x_t=\sqrt{\overline{\alpha_t}}x_0+\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_1}}}\sqrt{1-\alpha_1}z_0+\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_2}}}\sqrt{1-\alpha_2}z_1+\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_3}}}\sqrt{1-\alpha_3}z_2+...+\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_t}}}\sqrt{1-\alpha_t}z_{t-1}\)</span></p>
<p>设随机变量<span class="math inline">\(\overline Z_{t-1}\)</span></p>
<p><span class="math inline">\(\overline
Z_{t-1}=\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_1}}}\sqrt{1-\alpha_1}z_0+\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_2}}}\sqrt{1-\alpha_2}z_1+\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_3}}}\sqrt{1-\alpha_3}z_2+...+\frac{\sqrt{\overline{\alpha_t}}}{\sqrt{\overline{\alpha_t}}}\sqrt{1-\alpha_t}z_{t-1}\)</span></p>
<ul>
<li><span class="math inline">\(E(\overline Z_{t-1})=0\)</span></li>
<li><span class="math inline">\(D(\overline
Z_{t-1})=1-\overline{\alpha_t}\)</span></li>
</ul>
<p><span class="math inline">\(x_t=\sqrt{\overline{\alpha_t}}x_0+\overline{Z}_{t-1}=\sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}Z\)</span></p>
<ul>
<li><span class="math inline">\(Z～N(0,I)\)</span></li>
<li><span class="math inline">\(q(x_t|x_0)=N(x_t;\sqrt{\overline{\alpha_t}}x_0,\sqrt{1-\overline{\alpha_t}}I)\)</span></li>
</ul>
<p><strong>至此我们推出了</strong></p>
<p><span class="math inline">\(q(x_t|x_{t-1})=N(x_t;\sqrt\alpha_t
x_{t-1},(1-\alpha_t)I)\)</span></p>
<p><span class="math inline">\(q(x_t|x_0)=N(x_t;\sqrt{\overline{\alpha_t}}x_0,\sqrt{1-\overline{\alpha_t}}I)\)</span></p>


        <hr>
        <!-- Pager -->
        <ul class="pager">
          
          <li class="previous">
            <a href="/Learning/CV/" data-toggle="tooltip" data-placement="top" title="CV复习版">&larr; Previous Post</a>
          </li>
          
          
          <li class="next">
            <a href="/Learning/ADS笔记/" data-toggle="tooltip" data-placement="top" title="ADS笔记">Next Post &rarr;</a>
          </li>
          
        </ul>

        
        <!-- tip start -->
        <!-- tip -->
<!-- tip start -->
<div class="tip">
  <p>
    
      如果您喜欢此博客或发现它对您有用，则欢迎对此发表评论。 也欢迎您共享此博客，以便更多人可以参与。 如果博客中使用的图像侵犯了您的版权，请与作者联系以将其删除。 谢谢 ！
    
  </p>
</div>
<!-- tip end -->

        <!-- tip end -->
        

        
        <!-- Sharing Srtart -->
        <!-- Social Social Share Post -->
<!-- Docs:https://github.com/overtrue/share.js -->

<div class="social-share" data-initialized="true" data-disabled="tencent ,douban ,qzone ,linkedin ,facebook ,google ,diandian" data-wechat-qrcode-helper="" align="center">
  <ul class="list-inline text-center social-share-ul">
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon icon-twitter">
        <i class="fa fa-twitter fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a class="social-share-icon icon-wechat">
        <i class="fa fa-weixin fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon icon-weibo">
        <i class="fa fa-weibo fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon icon-qq">
        <i class="fa fa-qq fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon" href="mailto:?subject=机器学习&body=Hi,I found this website and thought you might like it http://Hualingz.cn/Learning/机器学习/">
        <i class="fa fa-envelope fa-1x" aria-hidden="true"></i>
      </a>
    </li>
  </ul>
</div>

<!-- css & js -->
<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css"> -->
<script defer="defer" async="true" src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>

        <!-- Sharing End -->
        
        <hr>

        <!-- comments start -->
        <!-- 1. gitalk comment -->

  <!-- gitalk start -->
  <!-- Docs:https://github.com/gitalk/gitalk/blob/master/readme-cn.md -->

  <div id="gitalk-container"></div>

  
    <!-- <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.js"></script> -->
    <script src="/js/comment/gitalk.js"></script>
  

  <script>
    var gitalk = new Gitalk({
      clientID: '',
      clientSecret: '',
      repo: '',
      owner: '',
      admin: '',
      id: 'Thu Sep 15 2022 15:25:17 GMT+0800', // Ensure uniqueness and length less than 50
      distractionFreeMode: false, // Facebook-like distraction free mode
      perPage: 10,
      pagerDirection: 'last',
      createIssueManually: false,
      language: 'en',
      proxy: 'https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token'
    });
    gitalk.render('gitalk-container');

    var gtFolded = () => {
      setTimeout(function () {
        let markdownBody = document.getElementsByClassName("markdown-body");
        let list = Array.from(markdownBody);
        list.forEach(item => {
          if (item.clientHeight > 250) {
            item.classList.add('gt-comment-body-folded');
            item.style.maxHeight = '250px';
            item.title = 'Click to Expand';
            item.onclick = function () {
              item.classList.remove('gt-comment-body-folded');
              item.style.maxHeight = '';
              item.title = '';
              item.onclick = null;
            };
          }
        })
      }, 800);
    }
  </script>

  <!-- gitalk end -->


<!-- 2. gitment comment -->


<!-- 3. disqus comment -->


        <!-- comments end -->
        <hr>

      </div>

      <!-- Catalog: Tabe of Content -->
      <!-- Table of Contents -->

    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">目录</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">机器学习</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-1"><span class="toc-nav-number">1.1.</span> <span class="toc-nav-text">Lecture 1</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%88%86%E6%95%B0%E7%BB%84%E6%88%90"><span class="toc-nav-number">1.1.1.</span> <span class="toc-nav-text">1.1分数组成</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%AF%BC%E8%AE%BA"><span class="toc-nav-number">1.1.2.</span> <span class="toc-nav-text">1.2导论</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.1.3.</span> <span class="toc-nav-text">1.3监督学习</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.1.4.</span> <span class="toc-nav-text">1.4非监督学习</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.1.5.</span> <span class="toc-nav-text">1.5强化学习</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-2"><span class="toc-nav-number">1.2.</span> <span class="toc-nav-text">Lecture 2</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-1"><span class="toc-nav-number">1.2.1.</span> <span class="toc-nav-text">2.1监督学习</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%85%88%E9%AA%8C"><span class="toc-nav-number">1.2.1.1.</span> <span class="toc-nav-text">先验</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E4%BC%BC%E7%84%B6%E5%BA%A6"><span class="toc-nav-number">1.2.1.2.</span> <span class="toc-nav-text">似然度</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%90%8E%E9%AA%8C"><span class="toc-nav-number">1.2.1.3.</span> <span class="toc-nav-text">后验</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E7%AD%96%E7%95%A5"><span class="toc-nav-number">1.2.1.4.</span> <span class="toc-nav-text">策略</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1"><span class="toc-nav-number">1.2.2.</span> <span class="toc-nav-text">2.2参数估计</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1---%E7%9F%A5%E4%B9%8E-zhihu.com"><span class="toc-nav-number">1.2.2.1.</span> <span class="toc-nav-text">极大似然估计[一文搞懂极大似然估计 - 知乎
(zhihu.com)]</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#mle%E6%96%B9%E6%B3%95"><span class="toc-nav-number">1.2.2.2.</span> <span class="toc-nav-text">MLE方法</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#be%E6%96%B9%E6%B3%95%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1---%E7%9F%A5%E4%B9%8E-zhihu.com"><span class="toc-nav-number">1.2.2.3.</span> <span class="toc-nav-text">BE方法[贝叶斯估计 - 知乎
(zhihu.com)]</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#map%E6%96%B9%E6%B3%95"><span class="toc-nav-number">1.2.2.4.</span> <span class="toc-nav-text">MAP方法</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#discriminant-functions-for-the-normal-density%E5%88%A4%E5%88%AB%E5%87%BD%E6%95%B0"><span class="toc-nav-number">1.2.2.5.</span> <span class="toc-nav-text">Discriminant
Functions for the Normal Density判别函数</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#naive-bayes-classifier%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-nav-number">1.2.3.</span> <span class="toc-nav-text">2.3 Naive Bayes
Classifier朴素贝叶斯</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-3"><span class="toc-nav-number">1.3.</span> <span class="toc-nav-text">Lecture 3</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#linear-method-for-regression"><span class="toc-nav-number">1.3.1.</span> <span class="toc-nav-text">3.1 Linear Method for
Regression</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#linear-model"><span class="toc-nav-number">1.3.1.1.</span> <span class="toc-nav-text">Linear Model</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#polynomial-curve-fitting"><span class="toc-nav-number">1.3.1.2.</span> <span class="toc-nav-text">Polynomial Curve Fitting</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#mse-criterion%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E5%88%A4%E6%8D%AE"><span class="toc-nav-number">1.3.1.3.</span> <span class="toc-nav-text">MSE Criterion均方误差判据</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#linear-regression-model"><span class="toc-nav-number">1.3.2.</span> <span class="toc-nav-text">3.2Linear Regression Model</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#statistical-model-of-regression"><span class="toc-nav-number">1.3.3.</span> <span class="toc-nav-text">3.3 Statistical Model of
Regression</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#overfitting"><span class="toc-nav-number">1.3.3.1.</span> <span class="toc-nav-text">Overfitting</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#ridge-regression"><span class="toc-nav-number">1.3.3.2.</span> <span class="toc-nav-text">Ridge Regression</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#bayesian-linear-regression"><span class="toc-nav-number">1.3.3.3.</span> <span class="toc-nav-text">Bayesian Linear Regression</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#lasso"><span class="toc-nav-number">1.3.4.</span> <span class="toc-nav-text">3.3 LASSO</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#lasso-solution"><span class="toc-nav-number">1.3.4.1.</span> <span class="toc-nav-text">LASSO Solution</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#model-assessment-and-selection"><span class="toc-nav-number">1.3.5.</span> <span class="toc-nav-text">3.4 Model Assessment and
Selection</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#bias-variance-decomposition"><span class="toc-nav-number">1.3.6.</span> <span class="toc-nav-text">3.5 Bias-variance
Decomposition</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-4"><span class="toc-nav-number">1.4.</span> <span class="toc-nav-text">Lecture 4</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#discriminant-functions-and-classifiers"><span class="toc-nav-number">1.4.1.</span> <span class="toc-nav-text">4.1 Discriminant
Functions and Classifiers</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#sigmoid-functionlogistic-function"><span class="toc-nav-number">1.4.1.1.</span> <span class="toc-nav-text">Sigmoid Function(Logistic
Function)</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#logistic-regression"><span class="toc-nav-number">1.4.2.</span> <span class="toc-nav-text">4.2 Logistic Regression</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#gradient-descent"><span class="toc-nav-number">1.4.3.</span> <span class="toc-nav-text">4.3 Gradient Descent</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E4%B8%80%E8%88%AC%E7%9A%84%E6%AD%A5%E9%AA%A4"><span class="toc-nav-number">1.4.3.1.</span> <span class="toc-nav-text">一般的步骤</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E7%BA%BF%E6%80%A7%E8%BF%91%E4%BC%BC"><span class="toc-nav-number">1.4.3.2.</span> <span class="toc-nav-text">线性近似</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-nav-number">1.4.4.</span> <span class="toc-nav-text">4.4 支持向量机</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%87%A0%E4%BD%95%E8%BE%B9%E7%BC%98"><span class="toc-nav-number">1.4.4.1.</span> <span class="toc-nav-text">几何边缘</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%9D%BE%E5%BC%9B%E5%8F%98%E9%87%8F"><span class="toc-nav-number">1.4.4.2.</span> <span class="toc-nav-text">松弛变量</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%B1%82%E8%A7%A3"><span class="toc-nav-number">1.4.4.3.</span> <span class="toc-nav-text">求解</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#general-formulation-of-classifiers%E5%88%86%E7%B1%BB%E8%8C%83%E5%BC%8F"><span class="toc-nav-number">1.4.4.4.</span> <span class="toc-nav-text">General Formulation
of Classifiers分类范式</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-5"><span class="toc-nav-number">1.5.</span> <span class="toc-nav-text">Lecture 5</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#deep-learning-%E6%A6%82%E8%BF%B0"><span class="toc-nav-number">1.5.1.</span> <span class="toc-nav-text">5.1 Deep Learning 概述</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#neural-network"><span class="toc-nav-number">1.5.2.</span> <span class="toc-nav-text">5.2 Neural Network</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#linear-modelclassifier"><span class="toc-nav-number">1.5.2.1.</span> <span class="toc-nav-text">Linear Model(Classifier)</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#perceptron"><span class="toc-nav-number">1.5.2.2.</span> <span class="toc-nav-text">Perceptron</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#backpropagation-algorithm%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95"><span class="toc-nav-number">1.5.2.3.</span> <span class="toc-nav-text">Backpropagation
Algorithm反向传播算法</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#activation-function%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-nav-number">1.5.2.4.</span> <span class="toc-nav-text">Activation Function激活函数</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#convolution%E5%8D%B7%E7%A7%AF"><span class="toc-nav-number">1.5.3.</span> <span class="toc-nav-text">5.3 Convolution卷积</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%9B%BE%E5%83%8F%E7%9A%84%E8%BE%93%E5%85%A5"><span class="toc-nav-number">1.5.3.1.</span> <span class="toc-nav-text">图像的输入</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E4%BD%95%E4%B8%BA%E5%8D%B7%E7%A7%AF"><span class="toc-nav-number">1.5.3.2.</span> <span class="toc-nav-text">何为卷积</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-nav-number">1.5.3.3.</span> <span class="toc-nav-text">卷积层</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="toc-nav-number">1.5.3.4.</span> <span class="toc-nav-text">池化层</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-6"><span class="toc-nav-number">1.6.</span> <span class="toc-nav-text">Lecture 6</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#clustering"><span class="toc-nav-number">1.6.1.</span> <span class="toc-nav-text">6.1 Clustering</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#clustering-1"><span class="toc-nav-number">1.6.1.1.</span> <span class="toc-nav-text">Clustering</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#k-means"><span class="toc-nav-number">1.6.2.</span> <span class="toc-nav-text">6.2 K-Means</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#k-medoids"><span class="toc-nav-number">1.6.2.1.</span> <span class="toc-nav-text">K-Medoids</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#gaussian-mixture-model"><span class="toc-nav-number">1.6.3.</span> <span class="toc-nav-text">6.3 Gaussian Mixture Model</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1-1"><span class="toc-nav-number">1.6.3.1.</span> <span class="toc-nav-text">参数估计</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#e-step-%E6%89%93%E4%BC%AA%E6%A0%87%E7%AD%BE"><span class="toc-nav-number">1.6.3.1.1.</span> <span class="toc-nav-text">E Step 打伪标签</span></a></li><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#m-step-%E6%9B%B4%E6%96%B0%E5%8F%82%E6%95%B0"><span class="toc-nav-number">1.6.3.1.2.</span> <span class="toc-nav-text">M Step 更新参数</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#em"><span class="toc-nav-number">1.6.4.</span> <span class="toc-nav-text">6.4 EM</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#jensen%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-nav-number">1.6.4.1.</span> <span class="toc-nav-text">Jensen不等式</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#problem-description"><span class="toc-nav-number">1.6.5.</span> <span class="toc-nav-text">6.5 Problem Description</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#em%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93"><span class="toc-nav-number">1.6.6.</span> <span class="toc-nav-text">6.6 EM算法总结</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#density-based-clustering-method"><span class="toc-nav-number">1.6.7.</span> <span class="toc-nav-text">6.7 Density-Based Clustering
Method</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-7"><span class="toc-nav-number">1.7.</span> <span class="toc-nav-text">Lecture 7</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#linear-and-nonlinear"><span class="toc-nav-number">1.7.1.</span> <span class="toc-nav-text">Linear and Nonlinear</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#linear-transformation"><span class="toc-nav-number">1.7.1.0.1.</span> <span class="toc-nav-text">Linear Transformation</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#feature-extraction-vs-feature-selection"><span class="toc-nav-number">1.7.1.1.</span> <span class="toc-nav-text">Feature Extraction VS
Feature Selection</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#pca%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90"><span class="toc-nav-number">1.7.2.</span> <span class="toc-nav-text">PCA主成分分析</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%B0%86%E4%BA%8C%E7%BB%B4%E9%99%8D%E5%88%B0%E4%B8%80%E7%BB%B4%E7%9A%84%E4%BB%BB%E5%8A%A1"><span class="toc-nav-number">1.7.2.1.</span> <span class="toc-nav-text">将二维降到一维的任务</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#lda-linear-discriminant-analysis"><span class="toc-nav-number">1.7.3.</span> <span class="toc-nav-text">LDA Linear Discriminant
Analysis</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#lpp-locality-preserving-projection"><span class="toc-nav-number">1.7.4.</span> <span class="toc-nav-text">LPP Locality Preserving
Projection</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-8"><span class="toc-nav-number">1.8.</span> <span class="toc-nav-text">Lecture 8</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-1"><span class="toc-nav-number">1.8.1.</span> <span class="toc-nav-text">非监督学习</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1"><span class="toc-nav-number">1.8.2.</span> <span class="toc-nav-text">主题建模</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B"><span class="toc-nav-number">1.8.2.1.</span> <span class="toc-nav-text">词袋模型</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#document-term-matrix"><span class="toc-nav-number">1.8.2.2.</span> <span class="toc-nav-text">Document-Term Matrix</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#language-model-paradigm-in-ir"><span class="toc-nav-number">1.8.2.3.</span> <span class="toc-nav-text">Language Model Paradigm in
IR</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#plsa"><span class="toc-nav-number">1.8.2.4.</span> <span class="toc-nav-text">PLSA</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-9"><span class="toc-nav-number">1.9.</span> <span class="toc-nav-text">Lecture 9</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#svd%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3"><span class="toc-nav-number">1.9.1.</span> <span class="toc-nav-text">SVD奇异值分解</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="toc-nav-number">1.9.2.</span> <span class="toc-nav-text">矩阵分解</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#nmf%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3"><span class="toc-nav-number">1.9.3.</span> <span class="toc-nav-text">NMF非负矩阵分解</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#cost-function"><span class="toc-nav-number">1.9.3.1.</span> <span class="toc-nav-text">Cost Function</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#nmf-optimization"><span class="toc-nav-number">1.9.3.2.</span> <span class="toc-nav-text">NMF Optimization</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-10"><span class="toc-nav-number">1.10.</span> <span class="toc-nav-text">Lecture 10</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#transformer"><span class="toc-nav-number">1.10.1.</span> <span class="toc-nav-text">Transformer</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#transformer%E7%9A%84%E6%9E%B6%E6%9E%84%E5%9B%BE"><span class="toc-nav-number">1.10.2.</span> <span class="toc-nav-text">Transformer的架构图：</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-nav-number">1.10.2.1.</span> <span class="toc-nav-text">模型结构</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#attention%E6%9C%BA%E5%88%B6"><span class="toc-nav-number">1.10.3.</span> <span class="toc-nav-text">Attention机制</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#qkv%E6%A8%A1%E5%9E%8B"><span class="toc-nav-number">1.10.4.</span> <span class="toc-nav-text">QKV模型</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#self-attention%E8%87%AA%E8%81%9A%E7%84%A6%E6%9C%BA%E5%88%B6"><span class="toc-nav-number">1.10.5.</span> <span class="toc-nav-text">Self-Attention自聚焦机制</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#at%E5%92%8Csa%E7%9A%84%E4%B8%8D%E5%90%8C%E4%B9%8B%E5%A4%84"><span class="toc-nav-number">1.10.5.0.1.</span> <span class="toc-nav-text">AT和SA的不同之处</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#qkv%E8%81%9A%E7%84%A6%E6%9C%BA%E5%88%B6"><span class="toc-nav-number">1.10.6.</span> <span class="toc-nav-text">QKV聚焦机制</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-11"><span class="toc-nav-number">1.11.</span> <span class="toc-nav-text">Lecture 11</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#tokenize"><span class="toc-nav-number">1.11.1.</span> <span class="toc-nav-text">Tokenize</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#input-embeddinghttpswww.jianshu.compe6b5b463cf7b"><span class="toc-nav-number">1.11.2.</span> <span class="toc-nav-text">[Input
Embedding][https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;e6b5b463cf7b]</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#position-encoder"><span class="toc-nav-number">1.11.3.</span> <span class="toc-nav-text">Position Encoder</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#transformer-block"><span class="toc-nav-number">1.11.4.</span> <span class="toc-nav-text">Transformer Block</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-12"><span class="toc-nav-number">1.12.</span> <span class="toc-nav-text">Lecture 12</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#encoder"><span class="toc-nav-number">1.12.1.</span> <span class="toc-nav-text">Encoder</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#decoder"><span class="toc-nav-number">1.12.2.</span> <span class="toc-nav-text">Decoder</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#masked-multi-head-attention"><span class="toc-nav-number">1.12.3.</span> <span class="toc-nav-text">Masked Multi-Head Attention</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#cnn-in-transformer"><span class="toc-nav-number">1.12.4.</span> <span class="toc-nav-text">CNN in Transformer</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#patch-embedding"><span class="toc-nav-number">1.12.4.1.</span> <span class="toc-nav-text">Patch Embedding</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#position-embedding"><span class="toc-nav-number">1.12.4.2.</span> <span class="toc-nav-text">Position Embedding</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#cls-token"><span class="toc-nav-number">1.12.4.3.</span> <span class="toc-nav-text">Cls Token</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-13"><span class="toc-nav-number">1.13.</span> <span class="toc-nav-text">Lecture 13</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#dropout"><span class="toc-nav-number">1.13.1.</span> <span class="toc-nav-text">Dropout</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-14"><span class="toc-nav-number">1.14.</span> <span class="toc-nav-text">Lecture 14</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#batch-normalization-and-layer-normalization"><span class="toc-nav-number">1.14.1.</span> <span class="toc-nav-text">Batch Normalization
and Layer Normalization</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96batch-normalization-bn"><span class="toc-nav-number">1.14.1.1.</span> <span class="toc-nav-text">批归一化Batch Normalization
BN</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#internal-covariate-shift"><span class="toc-nav-number">1.14.1.1.1.</span> <span class="toc-nav-text">Internal Covariate Shift</span></a></li><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%89%B9%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-nav-number">1.14.1.1.2.</span> <span class="toc-nav-text">如何实现批归一化？</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96ln"><span class="toc-nav-number">1.14.1.2.</span> <span class="toc-nav-text">层归一化LN</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-nav-number">1.14.1.3.</span> <span class="toc-nav-text">总结</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-15"><span class="toc-nav-number">1.15.</span> <span class="toc-nav-text">Lecture 15</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#hwn%E9%AB%98%E9%80%9F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%A0%94%E7%A9%B6%E5%8A%A8%E6%9C%BA"><span class="toc-nav-number">1.15.1.</span> <span class="toc-nav-text">HWN高速神经网络的研究动机：</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#hwn%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-nav-number">1.15.1.1.</span> <span class="toc-nav-text">HWN网络架构：</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#drn%E6%AE%8B%E5%B7%AE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%A0%94%E7%A9%B6%E5%8A%A8%E6%9C%BA"><span class="toc-nav-number">1.15.2.</span> <span class="toc-nav-text">DRN残差神经网络的研究动机：</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#drn%E8%A7%A3%E5%86%B3%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E9%97%AE%E9%A2%98"><span class="toc-nav-number">1.15.2.1.</span> <span class="toc-nav-text">DRN解决梯度消失问题</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#densenet"><span class="toc-nav-number">1.15.3.</span> <span class="toc-nav-text">DenseNet</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-16"><span class="toc-nav-number">1.16.</span> <span class="toc-nav-text">Lecture 16</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#berthttpszhuanlan.zhihu.comp98855346"><span class="toc-nav-number">1.16.1.</span> <span class="toc-nav-text">[BERT][https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;98855346]</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-nav-number">1.16.1.1.</span> <span class="toc-nav-text">预训练模型</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#pre-trainfine-tuned"><span class="toc-nav-number">1.16.1.1.1.</span> <span class="toc-nav-text">Pre-Train+Fine-tuned：</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#pre-train"><span class="toc-nav-number">1.16.2.</span> <span class="toc-nav-text">Pre-Train</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#bert%E7%9A%84%E6%80%9D%E6%83%B3"><span class="toc-nav-number">1.16.2.1.</span> <span class="toc-nav-text">BERT的思想</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#bert%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-nav-number">1.16.3.</span> <span class="toc-nav-text">BERT的原理</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#bert%E8%BE%93%E5%85%A5"><span class="toc-nav-number">1.16.4.</span> <span class="toc-nav-text">BERT输入</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#fine-tunning"><span class="toc-nav-number">1.16.4.1.</span> <span class="toc-nav-text">Fine-Tunning</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#bert%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="toc-nav-number">1.16.5.</span> <span class="toc-nav-text">BERT预训练</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-17"><span class="toc-nav-number">1.17.</span> <span class="toc-nav-text">Lecture 17</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E2%85%B1"><span class="toc-nav-number">1.17.1.</span> <span class="toc-nav-text">预训练模型Ⅱ</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#clip%E7%9A%84%E7%A0%94%E7%A9%B6%E5%8A%A8%E6%9C%BA"><span class="toc-nav-number">1.17.2.</span> <span class="toc-nav-text">CLIP的研究动机</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#clip%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-nav-number">1.17.3.</span> <span class="toc-nav-text">CLIP模型训练</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#clip%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB"><span class="toc-nav-number">1.17.4.</span> <span class="toc-nav-text">CLIP模型分类</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#clip%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB%E4%BE%8B%E5%AD%90"><span class="toc-nav-number">1.17.5.</span> <span class="toc-nav-text">CLIP模型分类例子</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#align%E7%9A%84%E7%A0%94%E7%A9%B6%E5%8A%A8%E6%9C%BA"><span class="toc-nav-number">1.17.6.</span> <span class="toc-nav-text">ALIGN的研究动机</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#filip%E7%9A%84%E7%A0%94%E7%A9%B6%E5%8A%A8%E6%9C%BA"><span class="toc-nav-number">1.17.7.</span> <span class="toc-nav-text">FILIP的研究动机</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#filip%E6%A8%A1%E5%9E%8B"><span class="toc-nav-number">1.17.8.</span> <span class="toc-nav-text">FILIP模型</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BAhttpswww.zhihu.comquestion319291048"><span class="toc-nav-number">1.17.9.</span> <span class="toc-nav-text">[数据增强][https:&#x2F;&#x2F;www.zhihu.com&#x2F;question&#x2F;319291048]</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#declip%E7%9A%84%E7%A0%94%E7%A9%B6%E5%8A%A8%E6%9C%BA"><span class="toc-nav-number">1.17.9.1.</span> <span class="toc-nav-text">DECLIP的研究动机</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%9C%80%E8%BF%91%E9%82%BB%E7%9B%91%E7%9D%A3nns"><span class="toc-nav-number">1.17.9.2.</span> <span class="toc-nav-text">最近邻监督NNS</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.17.9.3.</span> <span class="toc-nav-text">自监督学习</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-18"><span class="toc-nav-number">1.18.</span> <span class="toc-nav-text">Lecture 18</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8Fdistilling-knowledge"><span class="toc-nav-number">1.18.1.</span> <span class="toc-nav-text">知识蒸馏Distilling Knowledge</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF"><span class="toc-nav-number">1.18.2.</span> <span class="toc-nav-text">模型背景</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%A1%86%E6%9E%B6"><span class="toc-nav-number">1.18.3.</span> <span class="toc-nav-text">基本框架</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9B%AE%E6%A0%87%E8%92%B8%E9%A6%8F"><span class="toc-nav-number">1.18.4.</span> <span class="toc-nav-text">目标蒸馏</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#soft-target%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8A%BF"><span class="toc-nav-number">1.18.4.1.</span> <span class="toc-nav-text">Soft-target训练优势</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#dark-knowledge%E6%9A%97%E7%9F%A5%E8%AF%86"><span class="toc-nav-number">1.18.4.2.</span> <span class="toc-nav-text">Dark Knowledge暗知识</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9F%A5%E8%AF%86%E5%A6%82%E4%BD%95%E4%BC%A0%E6%8E%88"><span class="toc-nav-number">1.18.5.</span> <span class="toc-nav-text">知识如何传授？</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E7%BB%84%E5%90%88%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96"><span class="toc-nav-number">1.18.5.1.</span> <span class="toc-nav-text">组合目标优化</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-19"><span class="toc-nav-number">1.19.</span> <span class="toc-nav-text">Lecture 19</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#decision-tree%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-nav-number">1.19.1.</span> <span class="toc-nav-text">Decision Tree决策树</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#basic-decision-tree-learning-algorithm"><span class="toc-nav-number">1.19.2.</span> <span class="toc-nav-text">Basic Decision Tree
Learning Algorithm</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#entropy"><span class="toc-nav-number">1.19.2.1.</span> <span class="toc-nav-text">Entropy</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#information-gain"><span class="toc-nav-number">1.19.2.2.</span> <span class="toc-nav-text">Information Gain</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="toc-nav-number">1.19.2.3.</span> <span class="toc-nav-text">总结</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#avoid-overfitting"><span class="toc-nav-number">1.19.3.</span> <span class="toc-nav-text">Avoid Overfitting</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#classification-and-regression-trees"><span class="toc-nav-number">1.19.4.</span> <span class="toc-nav-text">Classification and
Regression Trees</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-20"><span class="toc-nav-number">1.20.</span> <span class="toc-nav-text">Lecture 20</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%BB%84%E5%90%88%E6%A8%A1%E5%9E%8B-%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95httpszhuanlan.zhihu.comp355416998"><span class="toc-nav-number">1.20.1.</span> <span class="toc-nav-text">[组合模型-集成方法][https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;355416998]</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#bagging"><span class="toc-nav-number">1.20.2.</span> <span class="toc-nav-text">Bagging</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#the-bagging-algorithm"><span class="toc-nav-number">1.20.2.1.</span> <span class="toc-nav-text">The Bagging Algorithm</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88bagging-works"><span class="toc-nav-number">1.20.2.2.</span> <span class="toc-nav-text">为什么Bagging Works</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="toc-nav-number">1.20.3.</span> <span class="toc-nav-text">基本思想</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#random-forset"><span class="toc-nav-number">1.20.4.</span> <span class="toc-nav-text">Random Forset</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#how-to-generate-m-models"><span class="toc-nav-number">1.20.4.1.</span> <span class="toc-nav-text">How to Generate M Models</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#boosting"><span class="toc-nav-number">1.20.5.</span> <span class="toc-nav-text">Boosting</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#adaboost"><span class="toc-nav-number">1.20.6.</span> <span class="toc-nav-text">AdaBoost</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#insights-behing-adaboost"><span class="toc-nav-number">1.20.6.1.</span> <span class="toc-nav-text">Insights Behing Adaboost</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#reweight%E6%9C%BA%E5%88%B6"><span class="toc-nav-number">1.20.6.2.</span> <span class="toc-nav-text">Reweight机制</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%8C%87%E6%95%B0%E7%9A%84error-function"><span class="toc-nav-number">1.20.6.3.</span> <span class="toc-nav-text">指数的error function</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#gradient-boosting-decision-tree"><span class="toc-nav-number">1.20.7.</span> <span class="toc-nav-text">Gradient Boosting Decision
Tree</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-21"><span class="toc-nav-number">1.21.</span> <span class="toc-nav-text">Lecture 21</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#k-nearest-neighbor-classifier"><span class="toc-nav-number">1.21.1.</span> <span class="toc-nav-text">K Nearest Neighbor
Classifier</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#knn%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-nav-number">1.21.1.1.</span> <span class="toc-nav-text">KNN的参数</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#metric-learning"><span class="toc-nav-number">1.21.1.2.</span> <span class="toc-nav-text">Metric Learning</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#auto-encoder-ae"><span class="toc-nav-number">1.21.2.</span> <span class="toc-nav-text">Auto-encoder AE</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#auto-encoder-minist"><span class="toc-nav-number">1.21.2.1.</span> <span class="toc-nav-text">Auto Encoder MINIST</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%8A%80%E5%B7%A7%E4%B8%80%E5%8E%BB%E5%99%AAauto-encoder"><span class="toc-nav-number">1.21.2.2.</span> <span class="toc-nav-text">技巧一：去噪Auto-Encoder</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%8A%80%E5%B7%A7%E4%BA%8C%E5%9F%BA%E4%BA%8Ecnn%E7%9A%84auto-encoder"><span class="toc-nav-number">1.21.2.3.</span> <span class="toc-nav-text">技巧二：基于CNN的Auto-Encoder</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#%E7%89%B9%E5%BE%81%E8%A7%A3%E8%80%A6"><span class="toc-nav-number">1.21.2.3.1.</span> <span class="toc-nav-text">特征解耦</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%A6%BB%E6%95%A3%E8%A1%A8%E7%A4%BAvq-vae"><span class="toc-nav-number">1.21.3.</span> <span class="toc-nav-text">离散表示VQ-VAE</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#ae%E6%80%BB%E7%BB%93"><span class="toc-nav-number">1.21.4.</span> <span class="toc-nav-text">AE总结</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#ae%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-nav-number">1.21.4.1.</span> <span class="toc-nav-text">AE的问题：</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#vaehttpsblog.csdn.neta312863063articledetails87953517"><span class="toc-nav-number">1.21.5.</span> <span class="toc-nav-text">[VAE][https:&#x2F;&#x2F;blog.csdn.net&#x2F;a312863063&#x2F;article&#x2F;details&#x2F;87953517]</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E7%BB%93%E6%9E%84img"><span class="toc-nav-number">1.21.5.1.</span> <span class="toc-nav-text">结构：</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#vae%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86"><span class="toc-nav-number">1.21.6.</span> <span class="toc-nav-text">VAE数学原理</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#encoder-1"><span class="toc-nav-number">1.21.6.1.</span> <span class="toc-nav-text">Encoder</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#decoder-1"><span class="toc-nav-number">1.21.6.2.</span> <span class="toc-nav-text">Decoder</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#vae%E5%9B%BE%E7%BB%93%E6%9E%84%E6%A8%A1%E5%9E%8B"><span class="toc-nav-number">1.21.6.3.</span> <span class="toc-nav-text">VAE图结构模型</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%98%A0%E5%B0%84%E5%87%BD%E6%95%B0"><span class="toc-nav-number">1.21.6.4.</span> <span class="toc-nav-text">映射函数</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90"><span class="toc-nav-number">1.21.6.5.</span> <span class="toc-nav-text">数据生成</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#decoder%E5%85%B3%E4%BA%8Edecoder%E5%92%8Cencoder%E7%9A%84%E7%90%86%E8%A7%A3httpszhuanlan.zhihu.comp55557709"><span class="toc-nav-number">1.21.6.6.</span> <span class="toc-nav-text">Decoder[关于Decoder和Encoder的理解][https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;55557709]</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#encoder-2"><span class="toc-nav-number">1.21.6.7.</span> <span class="toc-nav-text">Encoder</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-22"><span class="toc-nav-number">1.22.</span> <span class="toc-nav-text">Lecture 22</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#vae-review"><span class="toc-nav-number">1.22.1.</span> <span class="toc-nav-text">VAE Review</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#c-vae"><span class="toc-nav-number">1.22.2.</span> <span class="toc-nav-text">C-VAE</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#vq-vaehttpszhuanlan.zhihu.comp91434658"><span class="toc-nav-number">1.22.3.</span> <span class="toc-nav-text">[VQ-VAE][https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;91434658]</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%90%8E%E9%AA%8C%E5%88%86%E5%B8%83qzx"><span class="toc-nav-number">1.22.3.1.</span> <span class="toc-nav-text">后验分布\(q(z|x)\)</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#vq-vae%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0"><span class="toc-nav-number">1.22.3.2.</span> <span class="toc-nav-text">VQ-VAE目标函数</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#straight-through-estimator"><span class="toc-nav-number">1.22.3.3.</span> <span class="toc-nav-text">Straight-through Estimator</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-23"><span class="toc-nav-number">1.23.</span> <span class="toc-nav-text">Lecture 23</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#gangenerative-adverasrial-network"><span class="toc-nav-number">1.23.1.</span> <span class="toc-nav-text">GAN：Generative Adverasrial
Network</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#gan%E8%AE%AD%E7%BB%83"><span class="toc-nav-number">1.23.2.</span> <span class="toc-nav-text">GAN训练</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#gan%E6%8D%9F%E5%A4%B1%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0ganhttpszhuanlan.zhihu.comp34287744"><span class="toc-nav-number">1.23.2.1.</span> <span class="toc-nav-text">GAN损失价值函数[GAN][https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;34287744]</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E7%AE%97%E6%B3%95%E5%B1%82%E9%9D%A2"><span class="toc-nav-number">1.23.2.2.</span> <span class="toc-nav-text">算法层面</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-24"><span class="toc-nav-number">1.24.</span> <span class="toc-nav-text">Lecture 24</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#dcgan"><span class="toc-nav-number">1.24.1.</span> <span class="toc-nav-text">DCGAN</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#progan"><span class="toc-nav-number">1.24.2.</span> <span class="toc-nav-text">ProGAN</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#cgan"><span class="toc-nav-number">1.24.3.</span> <span class="toc-nav-text">CGAN</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#stackgan"><span class="toc-nav-number">1.24.4.</span> <span class="toc-nav-text">StackGAN</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#stackgan%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84httpszhuanlan.zhihu.comp78102953"><span class="toc-nav-number">1.24.4.1.</span> <span class="toc-nav-text">[StackGAN的模型结构][https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;78102953]</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#conditioning-augmentation"><span class="toc-nav-number">1.24.4.2.</span> <span class="toc-nav-text">Conditioning Augmentation</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#stage-1"><span class="toc-nav-number">1.24.4.3.</span> <span class="toc-nav-text">Stage-1</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#stage-2"><span class="toc-nav-number">1.24.4.3.1.</span> <span class="toc-nav-text">Stage-2</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#pix2pixgan"><span class="toc-nav-number">1.24.5.</span> <span class="toc-nav-text">Pix2PixGAN</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#u-net"><span class="toc-nav-number">1.24.5.1.</span> <span class="toc-nav-text">U-Net</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#cyclegan"><span class="toc-nav-number">1.24.6.</span> <span class="toc-nav-text">CycleGAN</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#stylegan"><span class="toc-nav-number">1.24.7.</span> <span class="toc-nav-text">StyleGAN</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-25"><span class="toc-nav-number">1.25.</span> <span class="toc-nav-text">Lecture 25</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#diffusion-modelhttpszhuanlan.zhihu.comp525106459"><span class="toc-nav-number">1.25.1.</span> <span class="toc-nav-text">[Diffusion
Model][https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;525106459]</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#ddpm"><span class="toc-nav-number">1.25.1.1.</span> <span class="toc-nav-text">DDPM</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#diffusion%E6%89%A9%E6%95%A3%E8%BF%87%E7%A8%8B"><span class="toc-nav-number">1.25.1.2.</span> <span class="toc-nav-text">Diffusion扩散过程</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#%E9%87%8D%E5%8F%82%E6%95%B0reparameterization-trick"><span class="toc-nav-number">1.25.1.2.1.</span> <span class="toc-nav-text">重参数（reparameterization
trick）</span></a></li><li class="toc-nav-item toc-nav-level-5"><a class="toc-nav-link" href="#%E4%BB%BB%E6%84%8F%E6%97%B6%E5%88%BB%E7%9A%84-x_t-%E5%8F%AF%E4%BB%A5%E7%94%B1-x_0-%E5%92%8C-%CE%B2-%E8%A1%A8%E7%A4%BA"><span class="toc-nav-number">1.25.1.2.2.</span> <span class="toc-nav-text">任意时刻的 \(x_t\) 可以由 \(x_0\) 和 β 表示</span></a></li></ol></li></ol></li></ol></li></ol></li></ol>
        
        </div>
      </aside>
    



      <!-- Sidebar Container -->
      <div class="
                col-lg-8 col-lg-offset-1
                col-md-10 col-md-offset-1
                sidebar-container">

        <!-- Featured Tags -->
        
        <section>
          <!-- no hr -->
          <h5>
            <a href="/tags/">特色标签</a>
          </h5>
          <div class="tags">
            
            <a class="tag" href="/tags/#浙江大学" title="浙江大学">浙江大学</a>
            
            <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
            
          </div>
        </section>
        

        <!-- Friends Blog -->
        
        <hr>
        <h5>链友</h5>
        <ul class="list-inline">

          
        </ul>
        
      </div>
    </div>
  </div>
</article>



<!-- anchorjs start -->
<!-- async load function -->
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script type="text/javascript">
  // async load function
  function async (u, c) {
    var d = document,
      t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) {
      o.addEventListener('load', function(e) {
        c(null, e);
      }, false);
    }
    s.parentNode.insertBefore(o, s);
  };
</script>
<script type="text/javascript">
  //anchor-js, Doc:http://bryanbraun.github.io/anchorjs/
  async ("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js", function() {
    anchors.options = {
      visible: 'hover',
      placement: 'left',
      // icon: 'ℬ'
      icon: '❡'
    };
    anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
  });
</script>
<style>
  /* place left on bigger screen */
  @media all and (min-width: 800px) {
    .anchorjs-link {
      position: absolute;
      left: -0.75em;
      font-size: 1.1em;
      margin-top: -0.1em;
    }
  }
</style>

<!-- anchorjs end -->



		<!-- Footer (contains ThemeColor、viewer) -->
		<!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center">
          

          
            <li>
              <a target="_blank" href="https://github.com/Hualeez">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          

          

          

          

          

          

          

        </ul>
        <p class="copyright text-muted">
          Copyright &copy;
          Hualingz
          2023
          <br>
          Theme by
          <a target="_blank" rel="noopener" href="http://beantech.org">BeanTech</a>
          <span style="display: inline-block; margin: 0 5px;">
            <i class="fa fa-heart"></i>
          </span>
          re-Ported by
          <a target="_blank" rel="noopener" href="https://v-vincen.life/">Live My Life</a>
          |
          <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://ghbtns.com/github-btn.html?user=V-Vincen&repo=V-Vincen.github.io&type=star&count=true"></iframe>
        </p>
      </div>
    </div>
  </div>
</footer>

<a id="rocket" href="#top" class=""></a>


  <!-- jQuery -->
  <script type="text/javascript" src="/js/jquery.min.js"></script>
  <!-- Bootstrap Core JavaScript -->
  <script type="text/javascript" src="/js/bootstrap.min.js"></script>
  <!-- Custom Theme JavaScript -->
  <script type="text/javascript" src="/js/hux-blog.min.js"></script>
  <!-- catalog -->
  <script async="true" type="text/javascript" src="/js/catalog.js"></script>
  <!-- totop(rocket) -->
  <script async="true" type="text/javascript" src="/js/totop.js"></script>

  
    <!-- Busuanzi JavaScript -->
    <script async="async" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  

  
    <!-- Scroll start -->
    <script async="async" type="text/javascript" src="/js/scroll.js"></script>
    <!-- Scroll end -->
  

  
    <!-- LangSelect start -->
    <script type="text/javascript" src="/js/langselect.js"></script>
    <!-- LangSelect end -->
  

  
    <!-- Mouseclick -->
    <script type="text/javascript" src="/js/mouseclick.js" content='The first step is as good as half over...,Laugh and grow fat...,Man proposes God disposes...,When all else is lost the future still remains...,Wasting time is robbing oneself...,Sharp tools make good work...,Cease to struggle and you cease to live...,A friend in need is a friend indeed...,Faith can move mountains...' color='#9933CC,#339933,#66CCCC,#FF99CC,#CCCCFF,#6666CC,#663399,#66CC99,#FF0033'></script>
  

  
    <!-- ribbon -->
    <script type="text/javascript" src="/js/ribbonDynamic.js"></script>
  

  






  <!-- viewer start -->
  <!-- viewer start (Picture preview) -->
  
    <script async="async" type="text/javascript" src="/js/viewer/viewer.min.js"></script>
    <script async="async" type="text/javascript" src="/js/viewer/pic-viewer.js"></script>
  

  <!-- viewer end -->


<script>
  // async load function
  function async (u, c) {
    var d = document,
      t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) {
      o.addEventListener('load', function (e) {
        c(null, e);
      }, false);
    }
    s.parentNode.insertBefore(o, s);
  }

  // fastClick.js
  async ("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function () {
    var $nav = document.querySelector("nav");
    if ($nav)
      FastClick.attach($nav);
    }
  )
</script>

<!-- Because of the native support for backtick-style fenced code blocks right within the Markdown is landed in Github Pages, From V1.6, There is no need for Highlight.js, so Huxblog drops it officially. -
https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0 - https://help.github.com/articles/creating-and-highlighting-code-blocks/ -->
<!-- <script> async ("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function () { hljs.initHighlightingOnLoad(); }) </script> <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet"> -->

<!-- jquery.tagcloud.js -->
<!-- <script> // only load tagcloud.js in tag.html if ($('#tag_cloud').length !== 0) { async ("http://Hualingz.cn/js/jquery.tagcloud.js", function () { $.fn.tagcloud.defaults = { // size: { start: 1, end: 1, unit: 'em' }, color: {
start: '#bbbbee', end: '#0085a1' } }; $('#tag_cloud a').tagcloud(); }) } </script> -->


		<!-- Search -->
		
		<div class="popup search-popup local-search-popup">
  <span class="popup-btn-close">
    ESC
  </span>
  <div class="container">
    <div class="row">
      <!-- <div class="col-md-9 col-md-offset-1"> -->
      <div class="col-lg-9 col-lg-offset-1 col-md-10 col-md-offset-1 local-search-content">

        <div class="local-search-header clearfix">

          <div class="local-search-input-wrapper">
            <span class="search-icon">
              <i class="fa fa-search fa-lg" style="margin: 25px 10px 25px 20px;"></i>
            </span>
            <input autocomplete="off" placeholder="搜索..." type="text" id="local-search-input">
          </div>
        </div>
        <div id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>


  
    <script src="/js/ziploader.js"></script>
  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    // monitor main search box;
    var onPopupClose = function (e) {
      $('.popup').fadeOut(300);
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $('.popup').fadeIn(300);
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }
    // get search zip version
    $.get('/searchVersion.json?t=' + (+new Date()), function (res) {
      if (localStorage.getItem('searchVersion') !== res) {
        localStorage.setItem('searchVersion', res);
        initSearchJson();
      }
    });

    function initSearchJson() {
      initLoad(['/search.flv'], {
        loadOptions: {
          success: function (obj) {
            localStorage.setItem('searchJson', obj['search.json'])
          },
          error: function (e) {
            return console.log(e)
          }
        },
        returnOptions: {
          'json': TYPE_TEXT
        },
        mimeOptions: {
          'json': 'application/json'
        }
      })
    }
    // search function;
    var searchFunc = function (search_id, content_id) {
      'use strict';
      isfetched = true;
      var datas = JSON.parse(localStorage.getItem('searchJson'));
      // console.log(search_id)
      var input = document.getElementById(search_id);
      var resultContent = document.getElementById(content_id);
      var inputEventFunction = function () {
        var searchText = input.value.trim().toLowerCase();
        var keywords = searchText.split(/[\s\-]+/);
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        var resultItems = [];
        if (searchText.length > 0) {
          // perform local searching
          datas.forEach(function (data) {
            var isMatch = false;
            var hitCount = 0;
            var searchTextCount = 0;
            var title = data.title
              ? data.title.trim()
              : '';
            var titleInLowerCase = title.toLowerCase();
            var content = data.content
              ? data.content.trim().replace(/<[^>]+>/g, "")
              : '';
            var contentInLowerCase = content.toLowerCase();
            var articleUrl = decodeURIComponent(data.url);

            var date = data.date;
            var dateTime = date.replace(/T/, " ").replace(/.000Z/, "");
            var imgUrl = data.header_img;
            


            var indexOfTitle = [];
            var indexOfContent = [];
            // only match articles with not empty titles
            keywords.forEach(function (keyword) {
              function getIndexByWord(word, text, caseSensitive) {
                var wordLen = word.length;
                if (wordLen === 0) {
                  return [];
                }
                var startPosition = 0,
                  position = [],
                  index = [];
                if (!caseSensitive) {
                  text = text.toLowerCase();
                  word = word.toLowerCase();
                }
                while ((position = text.indexOf(word, startPosition)) > -1) {
                  index.push({position: position, word: word});
                  startPosition = position + wordLen;
                }
                return index;
              }
              indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
              indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
            });
            if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
              isMatch = true;
              hitCount = indexOfTitle.length + indexOfContent.length;
            }
            // show search results
            if (isMatch) {
              // sort index by position of keyword
              [indexOfTitle, indexOfContent].forEach(function (index) {
                index.sort(function (itemLeft, itemRight) {
                  if (itemRight.position !== itemLeft.position) {
                    return itemRight.position - itemLeft.position;
                  } else {
                    return itemLeft.word.length - itemRight.word.length;
                  }
                });
              });
              // merge hits into slices
              function mergeIntoSlice(text, start, end, index) {
                var item = index[index.length - 1];
                var position = item.position;
                var word = item.word;
                var hits = [];
                var searchTextCountInSlice = 0;
                while (position + word.length <= end && index.length != 0) {
                  if (word === searchText) {
                    searchTextCountInSlice++;
                  }
                  hits.push({position: position, length: word.length});
                  var wordEnd = position + word.length;
                  // move to next position of hit
                  index.pop();
                  while (index.length != 0) {
                    item = index[index.length - 1];
                    position = item.position;
                    word = item.word;
                    if (wordEnd > position) {
                      index.pop();
                    } else {
                      break;
                    }
                  }
                }
                searchTextCount += searchTextCountInSlice;
                return {hits: hits, start: start, end: end, searchTextCount: searchTextCountInSlice};
              }
              var slicesOfTitle = [];
              if (indexOfTitle.length != 0) {
                slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
              }
              var slicesOfContent = [];
              while (indexOfContent.length != 0) {
                var item = indexOfContent[indexOfContent.length - 1];
                var position = item.position;
                var word = item.word;
                // cut out 100 characters
                var start = position - 20;
                var end = position + 80;
                if (start < 0) {
                  start = 0;
                }
                if (end < position + word.length) {
                  end = position + word.length;
                }
                if (end > content.length) {
                  end = content.length;
                }
                slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
              }
              // sort slices in content by search text's count and hits' count
              slicesOfContent.sort(function (sliceLeft, sliceRight) {
                if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                  return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                  return sliceRight.hits.length - sliceLeft.hits.length;
                } else {
                  return sliceLeft.start - sliceRight.start;
                }
              });
              // select top N slices in content
              var upperBound = parseInt('1');
              if (upperBound >= 0) {
                slicesOfContent = slicesOfContent.slice(0, upperBound);
              }
              // highlight title and content
              function highlightKeyword(text, slice) {
                var result = '';
                var prevEnd = slice.start;
                slice.hits.forEach(function (hit) {
                  result += text.substring(prevEnd, hit.position);
                  var end = hit.position + hit.length;
                  result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                  prevEnd = end;
                });
                result += text.substring(prevEnd, slice.end);
                return result;
              }
              var resultItem = '';

              // if (slicesOfTitle.length != 0) {   resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>"; } else {   resultItem += "<li><a target='_blank' href='" +
              // articleUrl + "' class='search-result-title'>" + title + "</a>"; } slicesOfContent.forEach(function (slice) {   resultItem += "<a target='_blank' href='" + articleUrl + "'><p class=\"search-result\">" + highlightKeyword(content, slice) +
              // "...</p></a>"; }); resultItem += "</li>";

              if (slicesOfTitle.length != 0) {
                resultItem += "<a target='_blank' href='" + articleUrl + "' class='search-result'><div class='search-result-left'><div class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</div><time class='search-result-date'>" + dateTime + "</time>";
              } else {
                resultItem += "<a target='_blank' href='" + articleUrl + "' class='search-result'><div class='search-result-left'><div class='search-result-title'>" + title + "</div><time class='search-result-date'>" + dateTime + "</time>";
              }
              slicesOfContent.forEach(function (slice) {
                resultItem += "<p class=\"search-result-content\">" + highlightKeyword(content, slice) + "...</p>";
              });
              resultItem += "</div><div class='search-result-right'><img class='media-image' src='" + imgUrl + "' width='64px' height='48px'></img></div></a>";

              resultItems.push({item: resultItem, searchTextCount: searchTextCount, hitCount: hitCount, id: resultItems.length});
            }
          })
        };

        if (keywords.length === 1 && keywords[0] === "") {
          resultContent.innerHTML = '<div id="no-result"></div>'
        } else if (resultItems.length === 0) {
          resultContent.innerHTML = '<div id="no-result"></div>'
        } else {
          resultItems.sort(function (resultLeft, resultRight) {
            if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
              return resultRight.searchTextCount - resultLeft.searchTextCount;
            } else if (resultLeft.hitCount !== resultRight.hitCount) {
              return resultRight.hitCount - resultLeft.hitCount;
            } else {
              return resultRight.id - resultLeft.id;
            }
          });
          var searchResultList = '<div class=\"search-result-list\">';
          resultItems.forEach(function (result) {
            searchResultList += result.item;
          })
          searchResultList += "</div>";
          resultContent.innerHTML = searchResultList;
        }
      }
      if ('auto' === 'auto') {
        input.addEventListener('input', inputEventFunction);
      } else {
        $('.search-icon').click(inputEventFunction);
        input.addEventListener('keypress', function (event) {
          if (event.keyCode === 13) {
            inputEventFunction();
          }
        });
      }
      // remove loading animation
      $('body').css('overflow', '');
      proceedsearch();
    }
    // handle and trigger popup window;
    $('.popup-trigger').click(function (e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc('local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });
    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function (e) {
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 && $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });

    document.addEventListener('mouseup', (e) => {
      var _con = document.querySelector(".local-search-content");
      if (_con) {
        if (!_con.contains(e.target)) {
          onPopupClose();
        }
      }
    });
  </script>


		
	<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
