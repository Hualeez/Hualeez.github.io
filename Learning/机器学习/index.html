<!DOCTYPE html>
<html lang="en">

<!-- Head tag (contains Google-Analytics、Baidu-Tongji)-->
<head>
  <!-- Google Analytics -->
  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-xxxxxx-xx"></script>
    <script type="text/javascript">
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }
      gtag('js', new Date());

      gtag('config', 'UA-xxxxxx-xx');
    </script>
  

  <!-- Baidu Tongji -->
  
    <script type="text/javascript">
      // Originial
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  <!-- Baidu Push -->
  
    <script>
      (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
      })();
    </script>
  

  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge"/>

  <meta name="google-site-verification" content="lxDfCplOZbIzjhG34NuQBgu2gdyRlAtMB4utP5AgEBc"/>
  <meta name="baidu-site-verification" content="PpzM9WxOJU"/>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="description" content="这里是Hualingz，一个乐观主义者"/>
  <meta name="keyword" content="Hualingz,hualeez,hualingz,cyc"/>
  <link rel="shortcut icon" href="/img/avatar/fin_32.png"/>

  <!-- Place this tag in your head or just before your close body tag. -->
  <script async="async" defer="defer" src="https://buttons.github.io/buttons.js"></script>

  
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css"/>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/beantech.min.css"/>

    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css"/>
    <link rel="stylesheet" href="/css/widget.css"/>
    <link rel="stylesheet" href="/css/rocket.css"/>
    <link rel="stylesheet" href="/css/signature.css"/>
    <link rel="stylesheet" href="/css/catalog.css"/>
    <link rel="stylesheet" href="/css/livemylife.css"/>

    
      <!-- wave start -->
      <link rel="stylesheet" href="/css/wave.css"/>
      <!-- wave end -->
    

    
      <!-- top start (article top hot config) -->
      <link rel="stylesheet" href="/css/top.css"/>
      <!-- top end -->
    

    
      <!-- ThemeColor start -->
      <link rel="stylesheet" href="/css/scroll.css"/>
      <!-- ThemeColor end -->
    

    
      <!-- viewer start (Picture preview) -->
      <link rel="stylesheet" href="/css/viewer.min.css"/>
      <!-- viewer end -->
    

    
      <!-- Search start -->
      <link rel="stylesheet" href="/css/search.css"/>
      <!-- Search end -->
    

    
      <!-- ThemeColor start -->
      <link rel="stylesheet" href="/css/themecolor.css"/>
      <!-- ThemeColor end -->
    

    

    
      <!-- gitalk start -->
      <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"> -->
      <link rel="stylesheet" href="/css/gitalk.css"/>
      <!-- gitalk end -->
    
  

  <!-- Custom Fonts -->
  <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
  <!-- Hux change font-awesome CDN to qiniu -->
  <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" type="text/css">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <!-- Hux Delete, sad but pending in China <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'> <link
  href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/ css'> -->

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]> <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script> <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script> <![endif]-->

  <!-- ga & ba script hoook -->
  <link rel="canonical" href="http://Hualingz.cn/Learning/机器学习/">
  <title>
    
      机器学习 - Hualingz_Channel
    
  </title>
<meta name="generator" content="Hexo 5.4.2"></head>


<!-- hack iOS CSS :active style -->

	<body ontouchstart="" class="body--light body--dark">


		<!-- ThemeColor -->
		
		<!-- ThemeColor -->
<style type="text/css">
  .body--light {
    --light-mode: none;
    --dark-mode: block;
  }
  .body--dark {
    --light-mode: block;
    --dark-mode: none;
  }
  i.mdui-icon.material-icons.light-mode {
    display: var(--light-mode);
  }
  i.mdui-icon.material-icons.dark-mode {
    display: var(--dark-mode);
  }
</style>
<div class="toggle" onclick="document.body.classList.toggle('body--dark')">
  <i class="mdui-icon material-icons light-mode"></i>
  <i class="mdui-icon material-icons dark-mode"></i>
</div>
<script>
  //getCookieValue
  function getCookieValue(a) {
    var b = document.cookie.match('(^|[^;]+)\\s*' + a + '\\s*=\\s*([^;]+)');
    return b
      ? b.pop()
      : '';
  }
  let themeMode = 'dark';
  if (getCookieValue('sb-color-mode') && (getCookieValue('sb-color-mode') !== themeMode)) {
    let dbody = document.body.classList;
    themeMode === 'dark' ? dbody.remove('body--dark') : dbody.add('body--dark');
  }

  //setCookieValue
  var toggleBtn = document.querySelector(".toggle");
  toggleBtn.addEventListener("click", function () {
    var e = document.body.classList.contains("body--dark");
    var cookieString = e
      ? "dark"
      : "light";
    var exp = new Date();
    exp.setTime(exp.getTime() + 3 * 24 * 60 * 60 * 1000); //3天过期
    document.cookie = "sb-color-mode=" + cookieString + ";expires=" + exp.toGMTString() + ";path=/";
  });
</script>

		

		<!-- Gitter -->
		
		<!-- Gitter -->
<!-- Docs:https://gitter.im/?utm_source=left-menu-logo -->
<script>
  ((window.gitter = {}).chat = {}).options = {
    room: 'your-community/your-room'
  };
</script>
<script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>

		

		<!-- Navigation (contains search)-->
		<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header page-scroll">
      <button type="button" class="navbar-toggle">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Hualingz_Channel</a>
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <!-- Known Issue, found by Hux: <nav>'s height woule be hold on by its content. so, when navbar scale out, the <nav> will cover tags. also mask any touch event of tags, unfortunately. -->
    <div id="huxblog_navbar">
      <div class="navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a href="/">首页</a>
          </li>

          
          
          
          
          <li>
            <a href="/about/">
              
              关于
              
              
            </a>
          </li>
          
          
          
          
          
          <li>
            <a href="/categories/">
              
              分类
              
              
            </a>
          </li>
          
          
          
          <li>
            <a href="/tags/">
              
              标签
              
              
            </a>
          </li>
          
          

          
          <li>
            <a class="popup-trigger">
              <span class="search-icon"></span>搜索</a>
          </li>
          

          <!-- LangSelect -->
          
          
          
          
          
        </ul>
      </div>
    </div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container -->
</nav>
<!-- progress -->
<div id="progress">
  <div class="line" style="width: 0%;"></div>
</div>

<script>
  // Drop Bootstarp low-performance Navbar Use customize navbar with high-quality material design animation in high-perf jank-free CSS3 implementation
  var $body = document.body;
  var $toggle = document.querySelector('.navbar-toggle');
  var $navbar = document.querySelector('#huxblog_navbar');
  var $collapse = document.querySelector('.navbar-collapse');

  $toggle.addEventListener('click', handleMagic)

  function handleMagic(e) {
    if ($navbar.className.indexOf('in') > 0) {
      // CLOSE
      $navbar.className = " ";
      // wait until animation end.
      setTimeout(function() {
        // prevent frequently toggle
        if ($navbar.className.indexOf('in') < 0) {
          $collapse.style.height = "0px"
        }
      }, 400)
    } else {
      // OPEN
      $collapse.style.height = "auto"
      $navbar.className += " in";
    }
  }
</script>


		<!-- Post Header (contains intro-header、signature、wordcount、busuanzi、waveoverlay) -->
		<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->

  <style type="text/css">
    .body--light {
      /* intro-header */
      --intro-header-background-image-url-home: url('/img/header_img/newhome_bg.jpg');
      --intro-header-background-image-url-post: url('');
      --intro-header-background-image-url-page: url('/img/header_img/archive_bg2.jpg');
    }
    .body--dark {
      --intro-header-background-image-url-home: linear-gradient(rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.2)), url('/img/header_img/newhome_bg.jpg');
      --intro-header-background-image-url-post: linear-gradient(rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.2)), url('');
      --intro-header-background-image-url-page: linear-gradient(rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.2)), url('/img/header_img/archive_bg2.jpg');
    }

    header.intro-header {
       /*post*/
        background-image: var(--intro-header-background-image-url-post);
        /* background-image: url(''); */
      
    }

    
      #signature {/*signature*/
        background-image: url('/img/signature/vincent-white.png');
      }
    
  </style>





<header class="intro-header">
  <!-- Signature -->
  <div id="signature">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
          
          <div class="post-heading">
            <div class="tags">
              
              <a class="tag" href="/tags/#浙江大学" title="浙江大学">浙江大学</a>
              
              <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
              
            </div>
            <h1>机器学习</h1>
            <h2 class="subheading">Hualingz</h2>
            <span class="meta">
              Posted by Hualingz on
              2022-09-15
            </span>


            
            <!-- WordCount start -->
            <div class="blank_box"></div>
            <span class="meta">
              Estimated Reading Time <span class="post-count">27</span> Minutes
            </span>
            <div class="blank_box"></div>
            <span class="meta">
              Words <span class="post-count">5.9k</span> In Total
            </span>
            <div class="blank_box"></div>
            <!-- WordCount end -->
            
            
            <!-- 不蒜子统计 start -->
            <span class="meta" id="busuanzi_container_page_pv">
              Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
            </span>
            <!-- 不蒜子统计 end -->
            


          </div>
          
        </div>
      </div>
    </div>
  </div>

  
  <!-- waveoverlay start -->
  <div class="preview-overlay">
    <svg class="preview-waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
      <defs>
        <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path>
      </defs>
      <g class="preview-parallax">
        <use xlink:href="#gentle-wave" x="48" y="0" fill=var(--gentle-wave1)></use>
        <use xlink:href="#gentle-wave" x="48" y="3" fill=var(--gentle-wave2)></use>
        <use xlink:href="#gentle-wave" x="48" y="5" fill=var(--gentle-wave3)></use>
        <use xlink:href="#gentle-wave" x="48" y="7" fill=var(--gentle-wave)></use>
      </g>
    </svg>
  </div>
  <!-- waveoverlay end -->
  

</header>



		<!-- Main Content (Post contains
	Pager、
	tip、
	socialshare、
	gitalk、gitment、disqus-comment、
	Catalog、
	Sidebar、
	Featured-Tags、
	Friends Blog、
	anchorjs、
	) -->
		<!-- Modify by Yu-Hsuan Yen -->
<!-- Post Content -->
<article>
  <div class="container">
    <div class="row">
      <!-- Post Container -->
      <div class="col-lg-8 col-lg-offset-1 col-md-10 col-md-offset-1 post-container">

        <h1 id="机器学习">机器学习</h1>
<h2 id="lecture-1">Lecture 1</h2>
<p>赵洲，zhaozhou@zju.edu.cn，曹主415</p>
<h3 id="分数组成">1.1分数组成</h3>
<ul>
<li>大作业（图片分类）：70%
<ul>
<li>http://yann.lecun.com/exdb/mnist</li>
<li>思路PPT讲解：10</li>
<li>作业报告：30</li>
<li>编程代码：30</li>
<li>DDL：15周周五晚上12点</li>
</ul></li>
<li>小作业
<ul>
<li>阅读SVM开源算法报告：10
<ul>
<li>DDL：8周周五晚上12点</li>
</ul></li>
<li>阅读Transformer开源算法报告：10
<ul>
<li>DDL：15周周五晚上12点</li>
</ul></li>
</ul></li>
<li>课堂参与：10
<ul>
<li>签到20次，每次0.5%</li>
</ul></li>
</ul>
<h3 id="导论">1.2导论</h3>
<ul>
<li>Machine Learning：经验驱动的性能提升的计算机系统
<ul>
<li>Supervised监督学习：回归、分类</li>
<li>Unsupervised非监督学习：聚类</li>
<li>Reinforcement强化学习：游戏与控制</li>
</ul></li>
</ul>
<h3 id="监督学习">1.3监督学习</h3>
<ul>
<li>Goal： 学习一个映射从输入x到输出y</li>
<li>Training Data： labeled data有标签的输入输出对x，y</li>
<li>分类：离散的标签</li>
<li>回归：连续的标签</li>
</ul>
<h3 id="非监督学习">1.4非监督学习</h3>
<ul>
<li>只有输入，没有label</li>
<li>Goal： find “interesting pattern”</li>
<li>隐因子：
<ul>
<li>降维</li>
<li>矩阵分解</li>
<li>Topic Modeling</li>
</ul></li>
</ul>
<h3 id="强化学习">1.5强化学习</h3>
<ul>
<li>是延时的一个监督学习</li>
<li>这里的label是环境作用于机器的，是有延迟的reward</li>
</ul>
<h2 id="lecture-2">Lecture 2</h2>
<h3 id="监督学习-1">2.1监督学习</h3>
<p>【贝叶斯定理】<span class="math inline">\(P(A|B)=\frac{P(B|A)·P(A)}{P(B)}\)</span></p>
<ul>
<li><span class="math inline">\(P(A|B)\)</span>为后验概率，posterior</li>
<li><span class="math inline">\(P(B|A)\)</span>为似然度，likelihood来自于model</li>
<li><span class="math inline">\(P(A)\)</span>为先验Prior，来自label的比例</li>
</ul>
<p>【Example】</p>
<table>
<thead>
<tr class="header">
<th>A</th>
<th>0</th>
<th>0</th>
<th>1</th>
<th>1</th>
<th>1</th>
<th>0</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<h4 id="先验">先验</h4>
<p>先验一般有两种情况：</p>
<ol type="1">
<li>Uniform的情况<span class="math inline">\(P(w_1)=P(w_2)\)</span></li>
<li><span class="math inline">\(P(w_1)+P(w_2)=1\)</span></li>
</ol>
<p>只根据先验的决策：</p>
<ul>
<li>如果池塘里A鱼多，B鱼少，我们就猜测为A鱼</li>
</ul>
<h4 id="似然度">似然度</h4>
<p>只根据likelihood的决策：</p>
<ul>
<li>likelihood从观测中的data中来</li>
<li>如果<span class="math inline">\(P(x|w_1)&gt;P(x|w_2)\)</span>，预测为w1，x为一个特征</li>
</ul>
<h4 id="后验">后验</h4>
<p>贝叶斯公式<span class="math inline">\(P(w_i|x)=\frac{P(x|w_i)·P(w_i)}{P(x)}\)</span></p>
<p>概率公式<span class="math inline">\(P(x)=\sum_{i=1}^{k}P(x|w_i)P(w_i)\)</span></p>
<p>可以看到后验和先验×似然度成正比<code>Posterior = likelihood×Prior</code></p>
<h4 id="策略">策略</h4>
<p>选择后验概率最高，意味着错误率最小，即有最小错误率分类</p>
<ul>
<li>Decide <span class="math inline">\(w_i\)</span>，if <span class="math inline">\(P(w_i|x)&gt;P(w_j|x)\)</span></li>
<li>在使用贝叶斯公式根据已知的先验和似然度来决策</li>
<li>可以加上ln便于计算</li>
</ul>
<h3 id="参数估计">2.2参数估计</h3>
<h4 id="极大似然估计一文搞懂极大似然估计---知乎-zhihu.com">极大似然估计[<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26614750">一文搞懂极大似然估计 - 知乎 (zhihu.com)</a>]</h4>
<ul>
<li><p>极大似然估计，通俗理解来说，<strong>就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！</strong></p></li>
<li><p><strong>换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。</strong></p></li>
<li><p>对于分类器只能做参数估计，不能做模型估计，在参数估计中主要估计参数，模型是假定好的，比如假定是一个高斯模型，我们做的是估计高斯模型的一个参数，一个参数是<span class="math inline">\(μ\)</span>一个是Σ，我们要估计的就是这两个参数。</p></li>
<li><p>似然函数<span class="math inline">\(p(x|\theta)\)</span>：</p>
<ul>
<li>输入x为一个具体的数据，θ是模型的参数，</li>
<li>如果θ是已知的，x是变量那么这个函数是一个概率函数，它描述对于不同的样本点x，其出现概率是多少。</li>
<li>如果x是已知确定的， θ是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现 x 这个样本点的概率是多少。</li>
</ul></li>
</ul>
<p><strong>Example</strong></p>
<p>假如有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。我 们想知道罐中白球和黑球的比例，但我们不能把罐中的球全部拿出来数。现在我们可以每次任意从已经摇匀的罐中拿一个球出来，记录球的颜色，然后把拿出来的球 再放回罐中。这个过程可以重复，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少？</p>
<p><strong>很多人马上就有答案了：70%。而其后的理论支撑是什么呢？</strong></p>
<p>我们假设罐中白球的比例是p，那么黑球的比例就是1-p。因为每抽一个球出来，在记录颜色之后，我们把抽出的球放回了罐中并摇匀，<strong>所以每次抽出来的球的颜 色服从同一独立分布。</strong></p>
<p>这里我们把一次抽出来球的颜色称为一次抽样。题目中在一百次抽样中，七十次是白球的,三十次为黑球事件的概率是P(样本结果|Model)。</p>
<p>如果第一次抽象的结果记为x1,第二次抽样的结果记为x2....那么样本结果为(x1,x2.....,x100)。这样，我们可以得到如下表达式： <span class="math display">\[
p(x_1,x_2,...,x_{100}|Model)
\\=p(x_1|Model)p(x_2|Model)...p(x_{100}|Model)
\\=p^{70}(1-p)^{30}
\]</span> 我们已经有了观察样本结果出现的概率表达式了。那么我们要求的模型的参数，也就是求的式中的p。那么我们怎么来求这个p呢？不同的p，直接导致P（样本结果|Model）的不同。</p>
<p><strong>极大似然估计应该按照什么原则去选取这个分布呢？</strong></p>
<ul>
<li><strong>采取的方法是让这个样本结果出现的可能性最大，也就是使得<span class="math inline">\(p^{70} (1-p)^{30}\)</span>值最大，那么我们就可以看成是p的方程，求导即可！</strong></li>
<li>求出p=70</li>
</ul>
<h4 id="mle方法">MLE方法</h4>
<ul>
<li>MLE即Maximum Likelihood Estimation</li>
<li>定义何为最优参数？观测到的sample出现的概率最大的参数
<ul>
<li>假设我们有c个training set，c个class</li>
<li>每一个class需要学习一个model，model参数为<span class="math inline">\(\theta_c\)</span></li>
<li>MLE就是估计这个参数θ，要估计likelihood</li>
</ul></li>
<li>就是说所有sample的概率乘起来最大，即似然函数
<ul>
<li><span class="math inline">\(P(D_c|\theta_c)=\prod_{x\in D_c}P(x|\theta_c)\)</span></li>
<li>其中Dc为c类样本组成的集合，参数θc对于数据集Dc的最大似然估计，就是寻找使得这个表达式最大的参数θ值。</li>
</ul></li>
<li>假设我们模型是高斯模型，那么首先样本独立同分布
<ul>
<li><span class="math inline">\(p(x|w_i)=p(x|w_i,\theta_i)\)</span></li>
<li>likelihood服从高斯分布<span class="math inline">\(p(x|w_i)\)</span>~<span class="math inline">\(N(\mu_i,\Sigma_i)\)</span></li>
<li>似然函数<span class="math inline">\(P(D|\theta)=\prod_{k=1}^np(x_k|\theta)\)</span>
<ul>
<li><span class="math inline">\(\theta=(\theta_1,...,\theta_c)\)</span></li>
<li>评估的θ需要最大化这个似然值</li>
<li>乘法难以评估，求导困难，取log</li>
<li>对于单个θ就是<span class="math inline">\(P(D_c|\theta_c)=\prod_{x\in D_c}P(x|\theta_c)\)</span></li>
</ul></li>
<li><span class="math inline">\(l(\theta)=lnP(D|\theta)=\sum_{k=1}^nln\ p(x_k|\theta)\)</span></li>
<li>最后所求<span class="math inline">\(\theta^*={argmax}_{\theta}\ l(\theta)\)</span></li>
<li><span class="math inline">\(\nabla_{\theta}l(\theta)=[\frac{\part}{\part \theta_1},...,\frac{\part}{\part \theta_c}]^T=\sum_{k=1}^n\nabla_{\theta}ln\ p(x_k|\theta)\)</span></li>
<li>其中的<span class="math inline">\(p(x_k|\theta)\)</span>是服从高斯分布的
<ul>
<li>Σ固定，评估θ
<ul>
<li><span class="math inline">\(P(x)=-\frac{1}{\sqrt{2\pi \sigma}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}\)</span></li>
<li><span class="math inline">\(\mu=x的均值\)</span></li>
<li><span class="math inline">\(\sigma^2=x的方差\)</span></li>
</ul></li>
<li>高维的高斯
<ul>
<li><span class="math inline">\(P(x)=\frac{1}{(2\pi)^{\frac{d}{2}} |\Sigma|^\frac{1}{2}}exp[{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}]\)</span></li>
<li>d是维度</li>
<li><span class="math inline">\(\mu=\frac{1}{|D_c|}\sum_{x\in D_c}x\)</span></li>
<li><span class="math inline">\(\Sigma=\frac{1}{|D_c|}\sum_{x\in D_c}(x-\mu)(x-\mu)^T\)</span></li>
</ul></li>
</ul></li>
<li>令<span class="math inline">\(\nabla_{\theta}l(\theta)=0\)</span></li>
</ul></li>
<li>【Example】固定Σ估计μ的高斯模型
<ul>
<li><span class="math inline">\(P(x|\mu)\)</span>~<span class="math inline">\(N(\mu,\Sigma)\)</span></li>
<li><span class="math inline">\(ln\ p(x_k|\mu)=-\frac{1}{2}ln[(2\pi)^d|\Sigma|]-\frac{1}{2}(x_k-\mu)^T\Sigma^{-1}(x_k-\mu)\)</span></li>
<li>对参数μ求导</li>
<li><span class="math inline">\(\nabla_{\mu}ln\ p(x_k|\mu)=\Sigma^{-1}(x_k-\mu)\)</span></li>
<li>则<span class="math inline">\(\sum_{k=1}^n\Sigma^{-1}(x_k-\mu)=0\)</span></li>
<li>解出μ即可<span class="math inline">\(\mu^*=\frac{1}{n}\sum_{k=1}^nx_k\)</span></li>
<li>可以看到这个μ其实就是sample的均值</li>
</ul></li>
<li>【Example】估计μ、Σ的高斯模型
<ul>
<li><span class="math inline">\(P(x|\theta)\)</span>~<span class="math inline">\(N(\mu,\sigma^2)\)</span></li>
<li><span class="math inline">\(ln\ p(x_k|\theta)=-\frac{1}{2}ln(2\pi\sigma^2)-\frac{1}{2\sigma^2}(x_k-\mu)^2\)</span></li>
<li>对参数θ求导</li>
<li><span class="math inline">\(\nabla_{\theta}ln\ p(x_k|\theta)=\begin{bmatrix}\frac{\part ln\ p(x_k|\theta)}{\part\mu}\\\frac{\part ln\ p(x_k|\theta)}{\part\sigma^2}\end{bmatrix}=\begin{bmatrix}\frac{1}{\sigma^2}(x_k-\mu)\\ -\frac{1}{2\sigma^2}+\frac{(x_k-\mu)^2}{2\sigma^4}\end{bmatrix}=0\)</span></li>
<li><span class="math inline">\(\mu=\frac{1}{n}\sum x_k\)</span></li>
<li><span class="math inline">\(\sigma^2=\frac{1}{n}\sum(x_k-\mu)^2\)</span></li>
<li>令<span class="math inline">\(\overline{X}=[x_1-\mu,...,x_n-\mu]\)</span></li>
<li>则一般形式如下
<ul>
<li><span class="math inline">\(\mu=\frac{1}{n}\sum x_k\)</span></li>
<li><span class="math inline">\(\Sigma=\frac{1}{n}\overline{X}\overline{X}^T\)</span></li>
</ul></li>
</ul></li>
<li>【Example】</li>
</ul>
<h4 id="be方法贝叶斯估计---知乎-zhihu.com">BE方法[<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/72506771">贝叶斯估计 - 知乎 (zhihu.com)</a>]</h4>
<ul>
<li><p>贝叶斯评估方法：</p>
<ul>
<li>在MLE中，<span class="math inline">\(\theta_i\)</span>是可以计算出一个固定的值的
<ul>
<li>极大似然估计是典型的频率学派观点，它的基本思想是：待估计参数 θ 是客观存在的，只是未知而已，当 <span class="math inline">\(θ^{mle}\)</span> 满足“ <span class="math inline">\(θ=θ^{mle}\)</span> 时，该组观测样本 (X1,X2,…,Xn)=(x1,x2,…,xn) 更容易被观测到“，我们就说 <span class="math inline">\(θ^{mle}\)</span> 是 θ 的极大似然估计值。也即，估计值 <span class="math inline">\(θ^{mle}\)</span> 使得事件发生的可能性最大。</li>
</ul></li>
<li>在BE中，<span class="math inline">\(\theta_i\)</span>是一个随机的变量
<ul>
<li>贝叶斯估计是典型的贝叶斯学派观点，它的基本思想是：待估计参数 θ 也是随机的，和一般随机变量没有本质区别，因此只能根据观测样本估计参数 θ 的分布。贝叶斯派的人认为，被估计的参数同样服从一种分布，即参数也为一个随机变量。他们在估计参数前会先带来先验知识，例如参数在 [0.5,0.6] 的区域内出现的概率最大，在引入了先验知识后在数据量小的情况下估计出来的结果往往会更合理。</li>
<li>我们需要计算<strong>后验概率分布</strong><span class="math inline">\(P(\theta|D)\)</span></li>
</ul></li>
</ul></li>
<li><p>为了计算后验概率分布，我们首先看到贝叶斯公式<span class="math inline">\(P(\theta|D)=\frac{P(D|\theta)P(\theta)}{P(D)}\)</span></p>
<ul>
<li>那么有<span class="math inline">\(P(\theta|D)与P(D|\theta)P(\theta)\)</span>成正比</li>
<li>其中<span class="math inline">\(P(\theta)\)</span>为参数服从分布，即先验知识</li>
<li><span class="math inline">\(p(x|D)=\int p(x,\theta|D)d\theta=\int p(x|\theta,D)p(\theta|D)d\theta=\int p(x|\theta)p(\theta|D)d\theta\)</span></li>
<li>为什么要求<span class="math inline">\(p(x|D)\)</span>?</li>
</ul></li>
<li><p>【Example】未知μ的高斯分布<strong>generate出x的分布</strong></p>
<ul>
<li><span class="math inline">\(p(x|\mu)\)</span>~<span class="math inline">\(N(\mu,\sigma^2)\)</span></li>
<li>假设<span class="math inline">\(p(u)\)</span>~<span class="math inline">\(N(\mu_0,\sigma_0^2)\)</span></li>
<li>先求<span class="math inline">\(p(\mu|D)\)</span>
<ul>
<li><span class="math inline">\(p(\mu|D)=\frac{p(D|\mu)p(\mu)}{\int p(D|\mu)p(\mu)d\mu}=\alpha\prod p(x_k|\mu)p(\mu)\\=\alpha&#39;exp[-\frac{1}{2}(\sum(\frac{\mu-x_k}{\sigma})^2+(\frac{\mu-\mu_0}{\sigma_0})^2)]\\=\alpha&#39;&#39;exp[-\frac{1}{2}[(\frac{n}{\sigma^2}+\frac{1}{\sigma_0^2})\mu^2-2(\frac{1}{\sigma^2}\sum x_k+\frac{\mu_0}{\sigma_0^2})\mu]]\)</span></li>
<li>这就求出了后验概率分布</li>
<li>并且之前假设的
<ul>
<li><span class="math inline">\(\mu_n=(\frac{n\sigma_0^2}{n\sigma_0^2+\sigma^2})\hat{x_n}+\frac{\sigma^2}{n\sigma_0^2+\sigma^2}\mu_0\)</span></li>
<li><span class="math inline">\(\sigma_n^2=\frac{\sigma_0^2\sigma^2}{n\sigma_0^2+\sigma^2}\)</span></li>
</ul></li>
</ul></li>
<li>再求<span class="math inline">\(p(x|D)\)</span>后验密度即类条件概率密度
<ul>
<li>如上所述</li>
<li><span class="math inline">\(p(x|D)=\int p(x|\mu)p(\mu|D)d\mu\\=\frac{1}{2\pi \sigma \sigma_0}exp[-\frac{1}{2}\frac{(x-\mu_n)^2}{\sigma ^2+\sigma_0^2}]f(\sigma,\sigma_0)\)</span></li>
<li>其中<span class="math inline">\(f(\sigma,\sigma_0)=\int exp[-\frac{1}{2}\frac{\sigma^2+\sigma_0^2}{\sigma^2\sigma_0^2}(\mu-\frac{\sigma_n^2x+\sigma^2\mu_n}{\sigma^2+\sigma_n^2})^2]d\mu\)</span></li>
<li>得出结论为<span class="math inline">\(p(x|D)\)</span>~<span class="math inline">\(N(\mu_n,\sigma^2+\sigma_0^2)\)</span></li>
</ul></li>
</ul></li>
</ul>
<h4 id="map方法">MAP方法</h4>
<ul>
<li><p>密度估计(Density Estimation)</p>
<p>怎么去给一个观测到的数据集估计出一个联合概率分布是比较常见的问题。比如说，给定一系列的观测值<span class="math inline">\(X=(x_1,x_2,...,x_n)\)</span> , 每一个观测值都彼此独立的情况下，密度估计要选择一个概率分布模型，以及选择对应的最能够表达出X的联合概率的参数。最常见的两种方法有MAP和MLE（最大似然估计）。两种方法都要求找到并且优化一个模型以及它的参数来表达已知观测值。</p></li>
<li><p>在MAP中，在已知的概率分布模型和参数下，我们希望能够最大化观测到数据的可能性:<span class="math inline">\(P(X;\theta)=P(x_1,x_2,...,x_n;\theta)\)</span> 所以我们要找到一组参数<span class="math inline">\(\theta\)</span>，让上面的式子的结果最大。</p></li>
<li><p>那么我们只需要<span class="math inline">\(max(P(X|\theta)P(\theta))\)</span></p></li>
</ul>
<h4 id="discriminant-functions-for-the-normal-density判别函数">Discriminant Functions for the Normal Density判别函数</h4>
<p>在分类器中，我们需要依据概率分类，而这个判断的一句就是根据判别函数获得的</p>
<ul>
<li>一般形式
<ul>
<li>假设有c个类<span class="math inline">\(w_1,w_2,...,w_c\)</span></li>
<li>那么根据一个特征x，来查看<span class="math inline">\(p(w_i|x)\)</span>的大小，取最大的为最后预测的类
<ul>
<li>即判别函数<span class="math inline">\(g(x)=p(w_i|x)\)</span></li>
</ul></li>
<li>由贝叶斯公式知，<span class="math inline">\(p(w_i|x)\)</span>~<span class="math inline">\(p(x|w_i)p(w_i)\)</span>
<ul>
<li><span class="math inline">\(g(x)=p(x|w_i)p(w_i)\)</span></li>
</ul></li>
<li>取对数
<ul>
<li><span class="math inline">\(g(x)=ln\ p(x|w_i)+ln\ p(w_i)\)</span></li>
</ul></li>
</ul></li>
<li>一般而言只要<span class="math inline">\(g(x)\)</span>能够正确分类都可以作为判别函数
<ul>
<li>g(x)不一定要计算出来，只要能够纵向比较大小即可</li>
</ul></li>
<li>【Example】高斯分布下的一般形式的g(x)
<ul>
<li>判别函数<span class="math inline">\(g_i(x)=ln\ p(x|w_i)+ln\ p(w_i)\)</span></li>
<li><span class="math inline">\(p(x|w_i)=\frac{1}{(2\pi)^{\frac{d}{2}}|\Sigma_i|^\frac{1}{2}}exp[-\frac{1}{2}(x-\mu_i)^T\Sigma_i^{-1}(x-\mu_i)]\)</span></li>
<li><span class="math inline">\(g_i(x)=-\frac{1}{2}(x-\mu_i)^T\Sigma_i^{-1}(x-\mu_i)-\frac{d}{2}ln\ 2\pi-\frac{1}{2}ln|\Sigma_i|+ln\ p(w_i)\)</span>
<ul>
<li>Case1：<span class="math inline">\(\Sigma_i=\sigma^2I\)</span>
<ul>
<li><span class="math inline">\(g_i(x)=-\frac{(x-\mu_i)^T(x-\mu_i)}{2\sigma^2}+ln\ p(w_i)\)</span></li>
<li><span class="math inline">\(=-\frac{1}{2\sigma^2}(x^Tx-2\mu_i^Tx+\mu_i^T\mu_i)+ln\ p(w_i)\)</span></li>
<li>因为<span class="math inline">\(x^Tx\)</span>对于所有的class都是相等的，等价于<span class="math inline">\(g(x)=w_i^Tx+w_{i0}\)</span>
<ul>
<li><span class="math inline">\(w_i=\frac{\mu_i}{\sigma^2}\)</span></li>
<li><span class="math inline">\(w_{i0}=-\frac{\mu_i^T\mu_i}{2\sigma^2}+ln\ p(w_i)\)</span></li>
</ul></li>
<li>这是一个线性的函数</li>
<li>最后来查看两个类的输出相等的情况
<ul>
<li><span class="math inline">\(g_i(x)=g_j(x)\)</span></li>
<li><span class="math inline">\(0=(\frac{\mu_i-\mu_j}{\sigma^2})^Tx-\frac{\mu_i^T\mu_i-\mu_j^T\mu_j}{2\sigma^2}+ln\frac{p(w_i)}{p(w_j)}\)</span></li>
<li>假设<span class="math inline">\(p(w_i)=p(w_j)\)</span></li>
<li><span class="math inline">\(x_0=\frac{1}{2}(\mu_i+\mu_j)\)</span></li>
</ul></li>
</ul></li>
<li>Case2：<span class="math inline">\(\Sigma_i=\Sigma\)</span>
<ul>
<li><span class="math inline">\(g(x)=-\frac{1}{2}(x^T\Sigma^{-1}x-2\mu_i^T\Sigma^{-1}x+\mu_i^T\Sigma^{-1}\mu_i)+ln\ p(w_i)\)</span></li>
<li>因为<span class="math inline">\(x^T\Sigma^{-1}x\)</span>对所有的类都是一样的，等价于<span class="math inline">\(g_i(x)=\mu_i^T\Sigma^{-1}x-\frac{1}{2}\mu_i^T\Sigma^{-1}\mu_i+ln\ p(w_i)\)</span>
<ul>
<li><span class="math inline">\(g_i(x)=w_i^Tx+w_{i0}\)</span></li>
</ul></li>
<li>分界线
<ul>
<li><span class="math inline">\(g_i(x)=g_j(x)\)</span></li>
<li><span class="math inline">\(0=(\mu_i-\mu_j)^T\Sigma^{-1}x-\frac{\mu_i^T\Sigma^{-1}\mu_i-\mu_j^T\Sigma^{-1}\mu_j}{2}+ln\ \frac{p(w_i)}{p(w_j)}\)</span></li>
</ul></li>
<li>参数估计
<ul>
<li><span class="math inline">\(\mu_i=\frac{1}{N_i}\sum_{j\in w_i}x_j\)</span></li>
<li><span class="math inline">\(P(w_i)=\frac{N_i}{N}\)</span></li>
<li><span class="math inline">\(\Sigma=\sum_{i=1}^c\sum_{j\in w_i}\frac{(x_j-\mu_i)(x_j-u_i)^T}{N_i}\)</span></li>
</ul></li>
</ul></li>
<li>Case3：<span class="math inline">\(\Sigma_i=Arbitrary\)</span>
<ul>
<li><span class="math inline">\(g_i(x)=-\frac{1}{2}(x^T\Sigma_i^{-1}x-2\mu_i^T\Sigma_i^{-1}x+\mu_i^T\Sigma_i^{-1}\mu_i)-\frac{1}{2}ln\ |\Sigma_i|+ln\ P(w_i)\)</span></li>
<li><span class="math inline">\(g_i(x)=x^TW_ix+w_i^Tx+w_{i0}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="naive-bayes-classifier朴素贝叶斯">2.3 Naive Bayes Classifier朴素贝叶斯</h3>
<p>给出<span class="math inline">\(x=(x_1,x_2,...,x_p)^T\)</span></p>
<ul>
<li><p>给出一系列特征，我们希望找到这些特征最可能出现的类</p></li>
<li><p>即<span class="math inline">\(P(w|x)=P(w|x_1,...,x_p)\)</span></p>
<ul>
<li>又<span class="math inline">\(P(w|x)\)</span>~<span class="math inline">\(P(x_1,...,x_p|w)P(w)\)</span></li>
<li><strong>特征独立</strong></li>
<li><span class="math inline">\(P(x_1,...,x_p|w)=P(x_1|w)...P(x_p|w)\)</span></li>
<li>那么我们只需要找到最大的概率进行预测即可</li>
</ul></li>
<li><p>【Example】</p>
<ul>
<li><p><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Datas\TyporaImg\image-20220915095523325.png" alt="image-20220915095523325" style="zoom:50%;"></p></li>
<li><p>现在我们给出一个记录X=(Refund=No,Married,Income=120K)，使用朴素贝叶斯预测其类别</p></li>
<li><p>首先，类别只有两个：Yes，No</p>
<ul>
<li><p><span class="math inline">\(P(w_k)=\frac{N_k}{N}\)</span>每个类别的先验概率</p>
<ul>
<li><span class="math inline">\(P(NO)=\frac{7}{10}\)</span></li>
<li><span class="math inline">\(P(YES)=\frac{3}{10}\)</span></li>
</ul></li>
<li><p><span class="math inline">\(P(x_i|w_k)=\frac{|x_i|}{N_k}\)</span>每个类别中特征出现的概率</p>
<ul>
<li><p><span class="math display">\[
P(Refund=YES|NO)=\frac{3}{7}\\
P(Refund=NO|NO)=\frac{4}{7}\\
P(Refund=YES|YES)=0\\
P(Refund=NO|YES)=1
\]</span></p></li>
<li></li>
<li><p>$$ P(Married|YES)=0\ P(Divorced|YES)=\ P(Single|YES)=\</p>
<p>P(Married|NO)=\ P(Divorced|YES)=\ P(Single|YES)=\ $$</p></li>
<li><p>工资是高斯分布的，我们首先估计参数</p>
<ul>
<li><span class="math inline">\(P(x|w_i)\)</span>~<span class="math inline">\(N(\mu,\sigma^2)\)</span></li>
<li><span class="math inline">\(\mu=\frac{1}{n_x}\sum x_i=110\)</span></li>
<li><span class="math inline">\(\sigma^2=\frac{1}{n_x}\sum(x_i-\mu)^2=2975\)</span></li>
</ul></li>
<li><p><span class="math inline">\(P(X|NO)=P(x_1|NO)P(x_2|NO)P(x_3|NO)=0.0024\)</span></p></li>
<li><p><span class="math inline">\(P(X|YES)=0\)</span></p></li>
<li><p><span class="math inline">\(P(X|NO)P(NO)&gt;P(X|YES)P(YES)\)</span></p></li>
<li><p>Class=NO</p></li>
</ul></li>
</ul></li>
</ul></li>
<li><p>Laplace smoothing</p>
<ul>
<li><span class="math inline">\(P(x_i|w_k)=\frac{|x_{ik}|+1}{N_{w_k}+K}\)</span></li>
</ul></li>
</ul>
<h2 id="lecture-3">Lecture 3</h2>
<h3 id="linear-method-for-regression">3.1 Linear Method for Regression</h3>
<h4 id="linear-model">Linear Model</h4>
<ul>
<li>目标是学习一个从输入x到输出y的一个映射
<ul>
<li>y是离散的，分类</li>
<li>y是实数值，回归</li>
</ul></li>
<li>【Example】
<ul>
<li>设<span class="math inline">\(x\in R^d,x=[x_1,...,x_d]^T\)</span></li>
<li>参数<span class="math inline">\(w=[w_1,...,w_d]^T\in R^d,b\)</span></li>
<li>那么我们可以写出方程<span class="math inline">\(f(x)=w^Tx+b\)</span>
<ul>
<li>进一步令<span class="math inline">\(x=[x_1,..,x_d,1]^T\)</span></li>
<li><span class="math inline">\(w=[w_1,...,w_d,b]^T\)</span></li>
</ul></li>
<li><span class="math inline">\(f(x)=w^Tx\)</span></li>
</ul></li>
</ul>
<h4 id="polynomial-curve-fitting">Polynomial Curve Fitting</h4>
<ul>
<li>用多项式拟合数据参数为<span class="math inline">\(a=(a_0,a_1,...,a_m)\)</span>
<ul>
<li><span class="math inline">\(f(x,a)=a_0+a_1x_1+...+a_mx^m\)</span></li>
</ul></li>
<li>Zero Order Polynomial
<ul>
<li>是一个constant</li>
<li>其实就是均值</li>
</ul></li>
<li>First Order Polynomial
<ul>
<li>用一条直线拟合</li>
</ul></li>
<li>Third Order Polynomial
<ul>
<li>用三次函数的拟合</li>
</ul></li>
<li>次数越高越复杂，精度高，容易过拟合</li>
</ul>
<h4 id="mse-criterion均方误差判据">MSE Criterion均方误差判据</h4>
<ul>
<li>考察一个函数拟合是否好，我们用误差函数来判断
<ul>
<li>需要拟合的训练数据为<span class="math inline">\((x_1,y_1),...,(x_n,y_n)\)</span></li>
<li>学习到的函数为<span class="math inline">\(f(x,a)\)</span></li>
</ul></li>
<li><span class="math inline">\(MSE(a)=\frac{1}{n}\sum_{i=1}^n(y_i-f(x_i,a))^2\)</span></li>
<li>最小化MSE，即最小化标签<span class="math inline">\(y_i\)</span>和输出预期<span class="math inline">\(f(x_i)\)</span>方差，这里的f被参数a决定
<ul>
<li><span class="math inline">\(J_n(a)=\sum_{i=1}^n(y_i-a^Tx_i)^2\)</span></li>
<li>最小化<span class="math inline">\(a^Tx_i\)</span>和<span class="math inline">\(y_i\)</span>的均方误差</li>
<li>使用矩阵表示
<ul>
<li><span class="math inline">\(X=[x_1,x_2,...,x_n]\)</span></li>
<li><span class="math inline">\(y=[y_1,y_2,...,y_n]^T\)</span></li>
<li><span class="math inline">\(J_n(a)=(y-X^Ta)^T(y-X^Ta)\)</span></li>
</ul></li>
</ul></li>
</ul>
<h3 id="linear-regression-model">3.2Linear Regression Model</h3>
<ul>
<li>训练数据为<span class="math inline">\((x_i,y_i)\)</span>，标签为<span class="math inline">\(y_i\)</span></li>
<li>学得的模型为<span class="math inline">\(f(x)=a_0+\sum_{i=1}^pa_ix_i=a_0+a^Tx\)</span></li>
<li><span class="math inline">\(a=[a_1,...,a_p]^T,x\)</span>为特征向量</li>
<li>接下来我们要最小化误差
<ul>
<li>MSE均方误差
<ul>
<li><span class="math inline">\(J_n=\frac{1}{n}\sum_{i=1}^n(y_i-f(x_i))^2\)</span></li>
</ul></li>
<li>RSS残差平方和
<ul>
<li><span class="math inline">\(RSS(f)=\sum_{i=1}^n(y_i-f(x_i))^2\)</span></li>
</ul></li>
</ul></li>
<li>以MSE均方误差为例，如何最小化？
<ul>
<li>使用矩阵表示
<ul>
<li><span class="math inline">\(X=[x_1,x_2,...,x_n]\)</span></li>
<li><span class="math inline">\(y=[y_1,y_2,...,y_n]^T\)</span></li>
<li><span class="math inline">\(J_n(a)=(y-X^Ta)^T(y-X^Ta)\)</span></li>
<li>对a求导
<ul>
<li><span class="math inline">\(\frac{dAX}{dX}=A^T\)</span></li>
<li><span class="math inline">\(\frac{dx^Tx}{dx}=2x\)</span></li>
</ul></li>
<li><span class="math inline">\(\nabla J_n=-2X(y-X^Ta)\)</span></li>
<li><span class="math inline">\(a=(XX^T)^{-1}Xy\)</span></li>
</ul></li>
</ul></li>
<li>则我们就求出了使得MSE最小化的a
<ul>
<li><span class="math inline">\(\hat y=X^Ta=X^T(XX^T)^{-1}Xy\)</span></li>
</ul></li>
</ul>
<h3 id="statistical-model-of-regression">3.3 Statistical Model of Regression</h3>
<ul>
<li>生成的模型：<span class="math inline">\(y=f(x,a)+\epsilon\)</span>
<ul>
<li><span class="math inline">\(f(x,a)\)</span>是一个确定性函数</li>
<li><span class="math inline">\(\epsilon\)</span>是一个随机的噪声，它可以有一个概率分布，比如<span class="math inline">\(\epsilon\)</span>~<span class="math inline">\(N(0,\sigma^2)\)</span></li>
</ul></li>
<li>【Example】
<ul>
<li><span class="math inline">\(y=f(x,a)+\epsilon\)</span></li>
<li><span class="math inline">\(\epsilon\)</span>~<span class="math inline">\(N(0,\sigma^2)\)</span></li>
<li>给定<span class="math inline">\(a,X,\sigma\)</span>的条件下，输出y的概率</li>
<li>即<span class="math inline">\(y-f(x,a)\)</span>的概率，因为<span class="math inline">\(f(x,a)\)</span>是给定的</li>
<li><span class="math inline">\(p(y|x,a,\sigma)=\frac{1}{\sigma \sqrt{2\pi}}exp[-\frac{1}{2\sigma^2}(y-f(x,a))^2]\)</span></li>
<li>接下来使用最大似然估计MLE求a</li>
<li><span class="math inline">\(L(D,a,\sigma)=\prod_{i=1}^n p(y_i|x_1,a,\sigma)\)</span></li>
<li><span class="math inline">\(a^*=argmax\prod_{i=1}^np(y_i|x_i,a,\sigma)\)</span></li>
<li>使用对数似然函数</li>
<li><span class="math inline">\(l(D,a,\sigma)=log(L(D,a,\sigma))=log\prod p(y_i|x_i,a,\sigma)=\sum_{i=1}^nlog\ p(y_i|x_i,a,\sigma)\)</span></li>
<li><span class="math inline">\(l(D,a,\sigma)=-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-f(x_i,a))^2+c(\sigma)\)</span></li>
<li>到最后还是最小化<span class="math inline">\(RSS(f)\)</span></li>
</ul></li>
</ul>
<h4 id="overfitting">Overfitting</h4>
<ul>
<li>model不能过于简单也不能过于复杂，即参数的复杂度
<ul>
<li>过简单，欠拟合，在训练集上就表现不好</li>
<li>过复杂，过拟合，在训练集上良好，在测试集上表现差</li>
<li>我们可以对参数的限制放入损失函数中，作为正则函数项</li>
</ul></li>
</ul>
<h4 id="ridge-regression">Ridge Regression</h4>
<ul>
<li>使用损失函数+正则项</li>
<li><span class="math inline">\(a^*=argmin_{a}\sum_{i=1}^n(y_i-x_i^Ta)^2+\lambda\sum_{j=1}^p a_j^2\)</span></li>
<li>需要挑选合适的<span class="math inline">\(\lambda\)</span></li>
<li>等价形式
<ul>
<li><span class="math inline">\(a^*=argmin_{a}\sum(y_i-x_i^Ta)^2\)</span></li>
<li>Subject to <span class="math inline">\(\sum_{i=1}^n a_j^2≤t\)</span></li>
</ul></li>
<li>L2正则化
<ul>
<li><span class="math inline">\(C=C_0+\frac{\lambda}{2n}\sum_ww^2\)</span></li>
</ul></li>
<li>L1正则化
<ul>
<li><span class="math inline">\(C=C_0+\frac{\lambda}{n}\sum|w|\)</span></li>
<li>L1比L2更加sparse</li>
</ul></li>
<li>求解以<span class="math inline">\(a^*=argmin_{a}\sum_{i=1}^n(y_i-x_i^Ta)^2+\lambda\sum_{j=1}^p a_j^2\)</span>为例
<ul>
<li>矩阵表示<span class="math inline">\((y-X^Ta)^T(y-X^Ta)+\lambda a^Ta\)</span></li>
<li>求导<span class="math inline">\(-2X(y-X^Ta)+2\lambda a\)</span></li>
<li>求解<span class="math inline">\(a^*=(XX^T+\lambda I)^{-1}Xy\)</span></li>
</ul></li>
</ul>
<h4 id="bayesian-linear-regression">Bayesian Linear Regression</h4>
<ul>
<li><span class="math inline">\(P(a|D)=\frac{P(D|a)P(a)}{P(D)}\)</span></li>
<li>假设a是高斯分布
<ul>
<li><span class="math inline">\(p(a)=N(a|0,\lambda^{-1}I)\)</span></li>
<li><span class="math inline">\(ln(p(a))=-\frac{\lambda}{2}a^Ta+c\)</span></li>
<li>那么计算Posterior时我们可以先计算出likelihood
<ul>
<li><span class="math inline">\(l(D,a,\sigma)=-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-f(x_i,a))^2+c(\sigma)\)</span></li>
<li><span class="math inline">\(ln(p(a))=-\frac{\lambda}{2}a^Ta+c\)</span></li>
</ul></li>
<li>那么后验是正比于likelihood×prior的，在log下就是相加</li>
<li>相当于多了一个正则项</li>
</ul></li>
</ul>
<h3 id="lasso">3.3 LASSO</h3>
<ul>
<li>Least Absolute Selection and Shrinkage Operator</li>
<li><span class="math inline">\(\hat \beta=argmin\frac{1}{2n}\sum (y_i-x_i^T\beta)^2\)</span>
<ul>
<li>subject to <span class="math inline">\(\sum_{j=1}^p|\beta_j|≤t\)</span>【L1】</li>
<li>subject to <span class="math inline">\(\sum_{j=1}^p\beta_j^2≤t\)</span>【L2】</li>
</ul></li>
<li><img src="/Learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Datas\TyporaImg\image-20220920112506418.png" title="fig:" alt="image-20220920112506418"></li>
</ul>
<h4 id="lasso-solution">LASSO Solution</h4>
<ul>
<li><span class="math inline">\(\hat \beta=argmin\frac{1}{2n}\sum (y_i-z_i\beta)^2\)</span></li>
<li>这里的z是x经过归一化的，y也是归一化的
<ul>
<li><span class="math inline">\(\sum y_i=0\)</span></li>
<li><span class="math inline">\(\sum z_i=0\)</span></li>
<li><span class="math inline">\(\frac{1}{n}\sum_iz_{ij}^2=1\)</span></li>
</ul></li>
<li><span class="math inline">\(f(\beta)=\frac{1}{2n}(y-\beta z)^T(y-\beta z)+\lambda|\beta|\)</span></li>
<li><span class="math inline">\(f(\beta)=\frac{1}{2n}z^Tz\beta^2-\frac{1}{n}&lt;z,y&gt;\beta+\frac{1}{2n}y^Ty+\lambda |\beta|\)</span></li>
<li><span class="math inline">\(2&lt;z,y&gt;=y^Tz+z^Ty\)</span></li>
<li>且<span class="math inline">\(\hat \beta=argmin\frac{1}{2n}\sum (y_i-x_i^T\beta)^2\)</span></li>
<li>去除与<span class="math inline">\(\beta\)</span>无关项，<span class="math inline">\(f(\beta)=\frac{1}{2}\beta^2-\frac{1}{n}&lt;z,y&gt;\beta+\lambda |\beta|\)</span></li>
<li><span class="math display">\[ f(\beta)= \begin{cases} \frac{1}{2}\beta^2-(\frac{1}{n}&lt;z,y&gt;-\lambda)\beta,\quad \beta\geq 0\\ \frac{1}{2}\beta^2-(\frac{1}{n}&lt;z,y&gt;+\lambda)\beta, \quad \beta\lt 0 \end{cases} \tag{1} \]</span></li>
<li><span class="math inline">\(\beta^*=\begin{cases}\frac{1}{n}&lt;z,y&gt;-\lambda,\quad \frac{1}{n}&lt;z,y&gt;\gt \lambda\\ 0,\quad|\frac{1}{n}&lt;z,y&gt;|\leq\lambda\\\frac{1}{n}&lt;z,y&gt;+\lambda,\quad \frac{1}{n}&lt;z,y&gt;&lt;-\lambda\end{cases}\)</span></li>
</ul>
<h3 id="model-assessment-and-selection">3.4 Model Assessment and Selection</h3>
<ul>
<li>模型的评估和模型的选择：
<ul>
<li>泛化性、准确度</li>
<li>在新的data上测试集上进行测试</li>
</ul></li>
</ul>
<h3 id="bias-variance-decomposition">3.5 Bias-variance Decomposition</h3>
<ul>
<li>偏差-方差分解(Bias-Variance Decomposition)是统计学派看待模型复杂度的观点。Bias-variance分解是机器学习中一种重要的分析技术。给定学习目标和训练集规模，它可以把一种学习算法的期望误差分解为三个非负项的和，即样本真实噪音noise、bias和 variance。</li>
<li>noise 样本真实噪音是任何学习算法在该学习目标上的期望误差的下界；( 任何方法都克服不了的误差)</li>
<li>bias 度量了某种学习算法的平均估计结果所能逼近学习目标的程度；（独立于训练样本的误差，刻画了匹配的准确性和质量：一个高的偏差意味着一个坏的匹配）</li>
<li>variance 则度量了在面对同样规模的不同训练集时，学习算法的估计结果发生变动的程度。（相关于观测样本的误差，刻画了一个学习算法的精确性和特定性：一个高的方差意味着一个不稳定的匹配）。</li>
</ul>
<p>【Example】</p>
<ul>
<li>给出标签数据<span class="math inline">\((x_i,y_i)\)</span></li>
<li>学到一个函数<span class="math inline">\(f(x)=y\)</span></li>
<li>Loss：<span class="math inline">\(L(y,f(x))\)</span></li>
<li>期望误差：
<ul>
<li><span class="math inline">\(E(L)=\int\int L(y,f(x))p(x,y)dxdy\)</span></li>
</ul></li>
<li>若将平方误差用于Loss
<ul>
<li><span class="math inline">\(L(y,f(x))=(y-f(x))^2\)</span></li>
<li>获得EPE（Expected Prediction Error）
<ul>
<li><span class="math inline">\(EPE(f)=\int \int (y-f(x))^2p(x,y)dxdy\)</span></li>
</ul></li>
</ul></li>
<li>那么我们获得了平方误差下的期望误差即EPE
<ul>
<li>又<span class="math inline">\((y-f(x))^2=(y-E(y|x)+E(y|x)-f(x))^2\)</span></li>
<li><span class="math inline">\(=(y-E(y|x))^2+(E(y|x)-f(x))^2+2(y-E(y|x))(E(y|x)-f(x))\)</span>**&lt;*&gt;**</li>
<li>则<span class="math inline">\(\int\int (y-E(y|x))^2p(x,y)dxdy=\int_x\int_y(y-E(y|x))^2p(y|x)\ dy\ p(x)dx=\int_xvar(y|x)p(x)dx\)</span>
<ul>
<li>运用公式<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/e4c0a6db8a86">01 条件期望与条件方差 - 简书 (jianshu.com)</a>：
<ul>
<li><span class="math inline">\(E(y|x)=\int y\ p(y|x)dy\)</span></li>
<li><span class="math inline">\(var(y|x)=\int (y-E(y|x))p(y|x)dy\)</span></li>
</ul></li>
</ul></li>
<li>则<span class="math inline">\(\int \int (E(y|x)-f(x))^2p(x,y)dxdy=\int_yp(y|x)dy\int_x(E(y|x)-f(x))^2p(x)dx=\int(E(y|x)-f(x))^2p(x)dx\)</span>
<ul>
<li>运用公式
<ul>
<li><span class="math inline">\(\int p(y|x)dy=1\)</span></li>
<li><span class="math inline">\(E(y|x)\)</span>与y无关</li>
</ul></li>
</ul></li>
<li>则<span class="math inline">\(\int \int (y-E(y|x))(E(y|x)-f(x))p(x,y)dxdy=0\)</span>
<ul>
<li><span class="math inline">\(\int \int yE(y|x)p(x,y)dxdy=\int_x\int_yy\ p(y|x)dy\ E(y|x)p(x)dx=\int_xE(y|x)^2p(x)dx\)</span></li>
<li><span class="math inline">\(\int \int yf(x)p(x,y)dxdy\)</span></li>
<li><span class="math inline">\(\int \int E(y|x)^2p(x,y)dxdy=\int_yp(y|x)dy\int_xE(y|x)^2p(x)dx=\int_xE(y|x)^2p(x)dx\)</span></li>
<li><span class="math inline">\(\int\int E(y|x)f(x)p(x,y)dxdy=\int_yp(y|x)dy\int _xE(y|x)f(x)p(x)dx=\int_x\int_yy\ p(y|x)dyf(x)p(x)dx=\int \int yf(x)p(x,y)dxdy\)</span></li>
</ul></li>
</ul></li>
<li><span class="math inline">\(EPE(f)=\int(E(y|x)-f(x))^2p(x)dx+\int var(y|x)p(x)dx\)</span></li>
<li>在实际中，往往会给数据集D
<ul>
<li><span class="math inline">\(f(x)=f(x;D)\)</span></li>
<li><span class="math inline">\(EPE(f)=\int(f(x;D)-E(y|x))^2p(x)dx+\int var(y|x)p(x)dx\)</span></li>
<li>其中的<span class="math inline">\((f(x;D)-E(y|x))^2\)</span>可以如上一样分解
<ul>
<li><span class="math inline">\((f(x;D)-E(y|x))^2=E_D\{[f(x;D)-E_D(f(x;D))]^2\}+\{E_D(f(x;D))-E(y|x)\}^2\)</span></li>
</ul></li>
<li><span class="math inline">\(bias^2=\int\{E_D(f(x;D))-E(y|x)\}^2p(x)dx\)</span></li>
<li><span class="math inline">\(variance=\int E_D\{[f(x;D)-E_D(f(x;D))]^2\}p(x)dx\)</span></li>
<li><span class="math inline">\(noise=\int var(y|x)p(x)dx\)</span></li>
</ul></li>
</ul>


        <hr>
        <!-- Pager -->
        <ul class="pager">
          
          
          <li class="next">
            <a href="/Learning/ADS笔记/" data-toggle="tooltip" data-placement="top" title="ADS笔记">Next Post &rarr;</a>
          </li>
          
        </ul>

        
        <!-- tip start -->
        <!-- tip -->
<!-- tip start -->
<div class="tip">
  <p>
    
      如果您喜欢此博客或发现它对您有用，则欢迎对此发表评论。 也欢迎您共享此博客，以便更多人可以参与。 如果博客中使用的图像侵犯了您的版权，请与作者联系以将其删除。 谢谢 ！
    
  </p>
</div>
<!-- tip end -->

        <!-- tip end -->
        

        
        <!-- Sharing Srtart -->
        <!-- Social Social Share Post -->
<!-- Docs:https://github.com/overtrue/share.js -->

<div class="social-share" data-initialized="true" data-disabled="tencent ,douban ,qzone ,linkedin ,facebook ,google ,diandian" data-wechat-qrcode-helper="" align="center">
  <ul class="list-inline text-center social-share-ul">
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon icon-twitter">
        <i class="fa fa-twitter fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a class="social-share-icon icon-wechat">
        <i class="fa fa-weixin fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon icon-weibo">
        <i class="fa fa-weibo fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon icon-qq">
        <i class="fa fa-qq fa-1x" aria-hidden="true"></i>
      </a>
    </li>
    <li class="social-share-li">
      <a target="_blank" class="social-share-icon" href="mailto:?subject=机器学习&body=Hi,I found this website and thought you might like it http://Hualingz.cn/Learning/机器学习/">
        <i class="fa fa-envelope fa-1x" aria-hidden="true"></i>
      </a>
    </li>
  </ul>
</div>

<!-- css & js -->
<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css"> -->
<script defer="defer" async="true" src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>

        <!-- Sharing End -->
        
        <hr>

        <!-- comments start -->
        <!-- 1. gitalk comment -->

  <!-- gitalk start -->
  <!-- Docs:https://github.com/gitalk/gitalk/blob/master/readme-cn.md -->

  <div id="gitalk-container"></div>

  
    <!-- <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.js"></script> -->
    <script src="/js/comment/gitalk.js"></script>
  

  <script>
    var gitalk = new Gitalk({
      clientID: '',
      clientSecret: '',
      repo: '',
      owner: '',
      admin: '',
      id: 'Thu Sep 15 2022 15:25:17 GMT+0800', // Ensure uniqueness and length less than 50
      distractionFreeMode: false, // Facebook-like distraction free mode
      perPage: 10,
      pagerDirection: 'last',
      createIssueManually: false,
      language: 'en',
      proxy: 'https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token'
    });
    gitalk.render('gitalk-container');

    var gtFolded = () => {
      setTimeout(function () {
        let markdownBody = document.getElementsByClassName("markdown-body");
        let list = Array.from(markdownBody);
        list.forEach(item => {
          if (item.clientHeight > 250) {
            item.classList.add('gt-comment-body-folded');
            item.style.maxHeight = '250px';
            item.title = 'Click to Expand';
            item.onclick = function () {
              item.classList.remove('gt-comment-body-folded');
              item.style.maxHeight = '';
              item.title = '';
              item.onclick = null;
            };
          }
        })
      }, 800);
    }
  </script>

  <!-- gitalk end -->


<!-- 2. gitment comment -->


<!-- 3. disqus comment -->


        <!-- comments end -->
        <hr>

      </div>

      <!-- Catalog: Tabe of Content -->
      <!-- Table of Contents -->

    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">目录</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">机器学习</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-1"><span class="toc-nav-number">1.1.</span> <span class="toc-nav-text">Lecture 1</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%88%86%E6%95%B0%E7%BB%84%E6%88%90"><span class="toc-nav-number">1.1.1.</span> <span class="toc-nav-text">1.1分数组成</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%AF%BC%E8%AE%BA"><span class="toc-nav-number">1.1.2.</span> <span class="toc-nav-text">1.2导论</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.1.3.</span> <span class="toc-nav-text">1.3监督学习</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.1.4.</span> <span class="toc-nav-text">1.4非监督学习</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-nav-number">1.1.5.</span> <span class="toc-nav-text">1.5强化学习</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-2"><span class="toc-nav-number">1.2.</span> <span class="toc-nav-text">Lecture 2</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-1"><span class="toc-nav-number">1.2.1.</span> <span class="toc-nav-text">2.1监督学习</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%85%88%E9%AA%8C"><span class="toc-nav-number">1.2.1.1.</span> <span class="toc-nav-text">先验</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E4%BC%BC%E7%84%B6%E5%BA%A6"><span class="toc-nav-number">1.2.1.2.</span> <span class="toc-nav-text">似然度</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E5%90%8E%E9%AA%8C"><span class="toc-nav-number">1.2.1.3.</span> <span class="toc-nav-text">后验</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E7%AD%96%E7%95%A5"><span class="toc-nav-number">1.2.1.4.</span> <span class="toc-nav-text">策略</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1"><span class="toc-nav-number">1.2.2.</span> <span class="toc-nav-text">2.2参数估计</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1---%E7%9F%A5%E4%B9%8E-zhihu.com"><span class="toc-nav-number">1.2.2.1.</span> <span class="toc-nav-text">极大似然估计[一文搞懂极大似然估计 - 知乎 (zhihu.com)]</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#mle%E6%96%B9%E6%B3%95"><span class="toc-nav-number">1.2.2.2.</span> <span class="toc-nav-text">MLE方法</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#be%E6%96%B9%E6%B3%95%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1---%E7%9F%A5%E4%B9%8E-zhihu.com"><span class="toc-nav-number">1.2.2.3.</span> <span class="toc-nav-text">BE方法[贝叶斯估计 - 知乎 (zhihu.com)]</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#map%E6%96%B9%E6%B3%95"><span class="toc-nav-number">1.2.2.4.</span> <span class="toc-nav-text">MAP方法</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#discriminant-functions-for-the-normal-density%E5%88%A4%E5%88%AB%E5%87%BD%E6%95%B0"><span class="toc-nav-number">1.2.2.5.</span> <span class="toc-nav-text">Discriminant Functions for the Normal Density判别函数</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#naive-bayes-classifier%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-nav-number">1.2.3.</span> <span class="toc-nav-text">2.3 Naive Bayes Classifier朴素贝叶斯</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#lecture-3"><span class="toc-nav-number">1.3.</span> <span class="toc-nav-text">Lecture 3</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#linear-method-for-regression"><span class="toc-nav-number">1.3.1.</span> <span class="toc-nav-text">3.1 Linear Method for Regression</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#linear-model"><span class="toc-nav-number">1.3.1.1.</span> <span class="toc-nav-text">Linear Model</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#polynomial-curve-fitting"><span class="toc-nav-number">1.3.1.2.</span> <span class="toc-nav-text">Polynomial Curve Fitting</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#mse-criterion%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E5%88%A4%E6%8D%AE"><span class="toc-nav-number">1.3.1.3.</span> <span class="toc-nav-text">MSE Criterion均方误差判据</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#linear-regression-model"><span class="toc-nav-number">1.3.2.</span> <span class="toc-nav-text">3.2Linear Regression Model</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#statistical-model-of-regression"><span class="toc-nav-number">1.3.3.</span> <span class="toc-nav-text">3.3 Statistical Model of Regression</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#overfitting"><span class="toc-nav-number">1.3.3.1.</span> <span class="toc-nav-text">Overfitting</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#ridge-regression"><span class="toc-nav-number">1.3.3.2.</span> <span class="toc-nav-text">Ridge Regression</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#bayesian-linear-regression"><span class="toc-nav-number">1.3.3.3.</span> <span class="toc-nav-text">Bayesian Linear Regression</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#lasso"><span class="toc-nav-number">1.3.4.</span> <span class="toc-nav-text">3.3 LASSO</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#lasso-solution"><span class="toc-nav-number">1.3.4.1.</span> <span class="toc-nav-text">LASSO Solution</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#model-assessment-and-selection"><span class="toc-nav-number">1.3.5.</span> <span class="toc-nav-text">3.4 Model Assessment and Selection</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#bias-variance-decomposition"><span class="toc-nav-number">1.3.6.</span> <span class="toc-nav-text">3.5 Bias-variance Decomposition</span></a></li></ol></li></ol></li></ol>
        
        </div>
      </aside>
    



      <!-- Sidebar Container -->
      <div class="
                col-lg-8 col-lg-offset-1
                col-md-10 col-md-offset-1
                sidebar-container">

        <!-- Featured Tags -->
        
        <section>
          <!-- no hr -->
          <h5>
            <a href="/tags/">特色标签</a>
          </h5>
          <div class="tags">
            
            <a class="tag" href="/tags/#浙江大学" title="浙江大学">浙江大学</a>
            
            <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
            
          </div>
        </section>
        

        <!-- Friends Blog -->
        
        <hr>
        <h5>链友</h5>
        <ul class="list-inline">

          
        </ul>
        
      </div>
    </div>
  </div>
</article>



<!-- anchorjs start -->
<!-- async load function -->
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script type="text/javascript">
  // async load function
  function async (u, c) {
    var d = document,
      t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) {
      o.addEventListener('load', function(e) {
        c(null, e);
      }, false);
    }
    s.parentNode.insertBefore(o, s);
  };
</script>
<script type="text/javascript">
  //anchor-js, Doc:http://bryanbraun.github.io/anchorjs/
  async ("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js", function() {
    anchors.options = {
      visible: 'hover',
      placement: 'left',
      // icon: 'ℬ'
      icon: '❡'
    };
    anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
  });
</script>
<style>
  /* place left on bigger screen */
  @media all and (min-width: 800px) {
    .anchorjs-link {
      position: absolute;
      left: -0.75em;
      font-size: 1.1em;
      margin-top: -0.1em;
    }
  }
</style>

<!-- anchorjs end -->



		<!-- Footer (contains ThemeColor、viewer) -->
		<!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center">
          

          
            <li>
              <a target="_blank" href="https://github.com/Hualeez">
                <span class="fa-stack fa-lg">
                  <i class="fa fa-circle fa-stack-2x"></i>
                  <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          

          

          

          

          

          

          

        </ul>
        <p class="copyright text-muted">
          Copyright &copy;
          Hualingz
          2022
          <br>
          Theme by
          <a target="_blank" rel="noopener" href="http://beantech.org">BeanTech</a>
          <span style="display: inline-block; margin: 0 5px;">
            <i class="fa fa-heart"></i>
          </span>
          re-Ported by
          <a target="_blank" rel="noopener" href="https://v-vincen.life/">Live My Life</a>
          |
          <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://ghbtns.com/github-btn.html?user=V-Vincen&repo=V-Vincen.github.io&type=star&count=true"></iframe>
        </p>
      </div>
    </div>
  </div>
</footer>

<a id="rocket" href="#top" class=""></a>


  <!-- jQuery -->
  <script type="text/javascript" src="/js/jquery.min.js"></script>
  <!-- Bootstrap Core JavaScript -->
  <script type="text/javascript" src="/js/bootstrap.min.js"></script>
  <!-- Custom Theme JavaScript -->
  <script type="text/javascript" src="/js/hux-blog.min.js"></script>
  <!-- catalog -->
  <script async="true" type="text/javascript" src="/js/catalog.js"></script>
  <!-- totop(rocket) -->
  <script async="true" type="text/javascript" src="/js/totop.js"></script>

  
    <!-- Busuanzi JavaScript -->
    <script async="async" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  

  
    <!-- Scroll start -->
    <script async="async" type="text/javascript" src="/js/scroll.js"></script>
    <!-- Scroll end -->
  

  
    <!-- LangSelect start -->
    <script type="text/javascript" src="/js/langselect.js"></script>
    <!-- LangSelect end -->
  

  
    <!-- Mouseclick -->
    <script type="text/javascript" src="/js/mouseclick.js" content='The first step is as good as half over...,Laugh and grow fat...,Man proposes God disposes...,When all else is lost the future still remains...,Wasting time is robbing oneself...,Sharp tools make good work...,Cease to struggle and you cease to live...,A friend in need is a friend indeed...,Faith can move mountains...' color='#9933CC,#339933,#66CCCC,#FF99CC,#CCCCFF,#6666CC,#663399,#66CC99,#FF0033'></script>
  

  
    <!-- ribbon -->
    <script type="text/javascript" src="/js/ribbonDynamic.js"></script>
  

  






  <!-- viewer start -->
  <!-- viewer start (Picture preview) -->
  
    <script async="async" type="text/javascript" src="/js/viewer/viewer.min.js"></script>
    <script async="async" type="text/javascript" src="/js/viewer/pic-viewer.js"></script>
  

  <!-- viewer end -->


<script>
  // async load function
  function async (u, c) {
    var d = document,
      t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (c) {
      o.addEventListener('load', function (e) {
        c(null, e);
      }, false);
    }
    s.parentNode.insertBefore(o, s);
  }

  // fastClick.js
  async ("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function () {
    var $nav = document.querySelector("nav");
    if ($nav)
      FastClick.attach($nav);
    }
  )
</script>

<!-- Because of the native support for backtick-style fenced code blocks right within the Markdown is landed in Github Pages, From V1.6, There is no need for Highlight.js, so Huxblog drops it officially. -
https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0 - https://help.github.com/articles/creating-and-highlighting-code-blocks/ -->
<!-- <script> async ("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function () { hljs.initHighlightingOnLoad(); }) </script> <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet"> -->

<!-- jquery.tagcloud.js -->
<!-- <script> // only load tagcloud.js in tag.html if ($('#tag_cloud').length !== 0) { async ("http://Hualingz.cn/js/jquery.tagcloud.js", function () { $.fn.tagcloud.defaults = { // size: { start: 1, end: 1, unit: 'em' }, color: {
start: '#bbbbee', end: '#0085a1' } }; $('#tag_cloud a').tagcloud(); }) } </script> -->


		<!-- Search -->
		
		<div class="popup search-popup local-search-popup">
  <span class="popup-btn-close">
    ESC
  </span>
  <div class="container">
    <div class="row">
      <!-- <div class="col-md-9 col-md-offset-1"> -->
      <div class="col-lg-9 col-lg-offset-1 col-md-10 col-md-offset-1 local-search-content">

        <div class="local-search-header clearfix">

          <div class="local-search-input-wrapper">
            <span class="search-icon">
              <i class="fa fa-search fa-lg" style="margin: 25px 10px 25px 20px;"></i>
            </span>
            <input autocomplete="off" placeholder="搜索..." type="text" id="local-search-input">
          </div>
        </div>
        <div id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>


  
    <script src="/js/ziploader.js"></script>
  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    // monitor main search box;
    var onPopupClose = function (e) {
      $('.popup').fadeOut(300);
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $('.popup').fadeIn(300);
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }
    // get search zip version
    $.get('/searchVersion.json?t=' + (+new Date()), function (res) {
      if (localStorage.getItem('searchVersion') !== res) {
        localStorage.setItem('searchVersion', res);
        initSearchJson();
      }
    });

    function initSearchJson() {
      initLoad(['/search.flv'], {
        loadOptions: {
          success: function (obj) {
            localStorage.setItem('searchJson', obj['search.json'])
          },
          error: function (e) {
            return console.log(e)
          }
        },
        returnOptions: {
          'json': TYPE_TEXT
        },
        mimeOptions: {
          'json': 'application/json'
        }
      })
    }
    // search function;
    var searchFunc = function (search_id, content_id) {
      'use strict';
      isfetched = true;
      var datas = JSON.parse(localStorage.getItem('searchJson'));
      // console.log(search_id)
      var input = document.getElementById(search_id);
      var resultContent = document.getElementById(content_id);
      var inputEventFunction = function () {
        var searchText = input.value.trim().toLowerCase();
        var keywords = searchText.split(/[\s\-]+/);
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        var resultItems = [];
        if (searchText.length > 0) {
          // perform local searching
          datas.forEach(function (data) {
            var isMatch = false;
            var hitCount = 0;
            var searchTextCount = 0;
            var title = data.title
              ? data.title.trim()
              : '';
            var titleInLowerCase = title.toLowerCase();
            var content = data.content
              ? data.content.trim().replace(/<[^>]+>/g, "")
              : '';
            var contentInLowerCase = content.toLowerCase();
            var articleUrl = decodeURIComponent(data.url);

            var date = data.date;
            var dateTime = date.replace(/T/, " ").replace(/.000Z/, "");
            var imgUrl = data.header_img;
            


            var indexOfTitle = [];
            var indexOfContent = [];
            // only match articles with not empty titles
            keywords.forEach(function (keyword) {
              function getIndexByWord(word, text, caseSensitive) {
                var wordLen = word.length;
                if (wordLen === 0) {
                  return [];
                }
                var startPosition = 0,
                  position = [],
                  index = [];
                if (!caseSensitive) {
                  text = text.toLowerCase();
                  word = word.toLowerCase();
                }
                while ((position = text.indexOf(word, startPosition)) > -1) {
                  index.push({position: position, word: word});
                  startPosition = position + wordLen;
                }
                return index;
              }
              indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
              indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
            });
            if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
              isMatch = true;
              hitCount = indexOfTitle.length + indexOfContent.length;
            }
            // show search results
            if (isMatch) {
              // sort index by position of keyword
              [indexOfTitle, indexOfContent].forEach(function (index) {
                index.sort(function (itemLeft, itemRight) {
                  if (itemRight.position !== itemLeft.position) {
                    return itemRight.position - itemLeft.position;
                  } else {
                    return itemLeft.word.length - itemRight.word.length;
                  }
                });
              });
              // merge hits into slices
              function mergeIntoSlice(text, start, end, index) {
                var item = index[index.length - 1];
                var position = item.position;
                var word = item.word;
                var hits = [];
                var searchTextCountInSlice = 0;
                while (position + word.length <= end && index.length != 0) {
                  if (word === searchText) {
                    searchTextCountInSlice++;
                  }
                  hits.push({position: position, length: word.length});
                  var wordEnd = position + word.length;
                  // move to next position of hit
                  index.pop();
                  while (index.length != 0) {
                    item = index[index.length - 1];
                    position = item.position;
                    word = item.word;
                    if (wordEnd > position) {
                      index.pop();
                    } else {
                      break;
                    }
                  }
                }
                searchTextCount += searchTextCountInSlice;
                return {hits: hits, start: start, end: end, searchTextCount: searchTextCountInSlice};
              }
              var slicesOfTitle = [];
              if (indexOfTitle.length != 0) {
                slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
              }
              var slicesOfContent = [];
              while (indexOfContent.length != 0) {
                var item = indexOfContent[indexOfContent.length - 1];
                var position = item.position;
                var word = item.word;
                // cut out 100 characters
                var start = position - 20;
                var end = position + 80;
                if (start < 0) {
                  start = 0;
                }
                if (end < position + word.length) {
                  end = position + word.length;
                }
                if (end > content.length) {
                  end = content.length;
                }
                slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
              }
              // sort slices in content by search text's count and hits' count
              slicesOfContent.sort(function (sliceLeft, sliceRight) {
                if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                  return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                  return sliceRight.hits.length - sliceLeft.hits.length;
                } else {
                  return sliceLeft.start - sliceRight.start;
                }
              });
              // select top N slices in content
              var upperBound = parseInt('1');
              if (upperBound >= 0) {
                slicesOfContent = slicesOfContent.slice(0, upperBound);
              }
              // highlight title and content
              function highlightKeyword(text, slice) {
                var result = '';
                var prevEnd = slice.start;
                slice.hits.forEach(function (hit) {
                  result += text.substring(prevEnd, hit.position);
                  var end = hit.position + hit.length;
                  result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                  prevEnd = end;
                });
                result += text.substring(prevEnd, slice.end);
                return result;
              }
              var resultItem = '';

              // if (slicesOfTitle.length != 0) {   resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>"; } else {   resultItem += "<li><a target='_blank' href='" +
              // articleUrl + "' class='search-result-title'>" + title + "</a>"; } slicesOfContent.forEach(function (slice) {   resultItem += "<a target='_blank' href='" + articleUrl + "'><p class=\"search-result\">" + highlightKeyword(content, slice) +
              // "...</p></a>"; }); resultItem += "</li>";

              if (slicesOfTitle.length != 0) {
                resultItem += "<a target='_blank' href='" + articleUrl + "' class='search-result'><div class='search-result-left'><div class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</div><time class='search-result-date'>" + dateTime + "</time>";
              } else {
                resultItem += "<a target='_blank' href='" + articleUrl + "' class='search-result'><div class='search-result-left'><div class='search-result-title'>" + title + "</div><time class='search-result-date'>" + dateTime + "</time>";
              }
              slicesOfContent.forEach(function (slice) {
                resultItem += "<p class=\"search-result-content\">" + highlightKeyword(content, slice) + "...</p>";
              });
              resultItem += "</div><div class='search-result-right'><img class='media-image' src='" + imgUrl + "' width='64px' height='48px'></img></div></a>";

              resultItems.push({item: resultItem, searchTextCount: searchTextCount, hitCount: hitCount, id: resultItems.length});
            }
          })
        };

        if (keywords.length === 1 && keywords[0] === "") {
          resultContent.innerHTML = '<div id="no-result"></div>'
        } else if (resultItems.length === 0) {
          resultContent.innerHTML = '<div id="no-result"></div>'
        } else {
          resultItems.sort(function (resultLeft, resultRight) {
            if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
              return resultRight.searchTextCount - resultLeft.searchTextCount;
            } else if (resultLeft.hitCount !== resultRight.hitCount) {
              return resultRight.hitCount - resultLeft.hitCount;
            } else {
              return resultRight.id - resultLeft.id;
            }
          });
          var searchResultList = '<div class=\"search-result-list\">';
          resultItems.forEach(function (result) {
            searchResultList += result.item;
          })
          searchResultList += "</div>";
          resultContent.innerHTML = searchResultList;
        }
      }
      if ('auto' === 'auto') {
        input.addEventListener('input', inputEventFunction);
      } else {
        $('.search-icon').click(inputEventFunction);
        input.addEventListener('keypress', function (event) {
          if (event.keyCode === 13) {
            inputEventFunction();
          }
        });
      }
      // remove loading animation
      $('body').css('overflow', '');
      proceedsearch();
    }
    // handle and trigger popup window;
    $('.popup-trigger').click(function (e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc('local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });
    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function (e) {
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 && $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });

    document.addEventListener('mouseup', (e) => {
      var _con = document.querySelector(".local-search-content");
      if (_con) {
        if (!_con.contains(e.target)) {
          onPopupClose();
        }
      }
    });
  </script>


		
	<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
